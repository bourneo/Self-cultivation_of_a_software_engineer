

大型分布式网站的架构演进


	大型分布式网站的架构演进 ------单一应用架构

		从一个简单的电商网站说起，它可能包含如下的几个模块和功能，如首页、 detail页、 list页、下单页、支付页以及后台管理等页面和功能。

	大型分布式网站的架构演进 ------垂直应用架构

		随着业务的发展，单一应用架构带来的问题是：
		1.代码越来庞大，业务越来越复杂，多个团队开发同一个应用，难以维护
		2.业务复杂，占用的系统资源越来越多，流量越来越大，不方便扩展

		垂直应用架构解决了单一应用架构所面临的扩容问题，流量能够分散到各个子系统当中，且系统的体积可控，一定程度上降低了开发人员之间协同以及维护的成本，提升了开发效率。

	大型分布式网站的架构演进 ------分布式应用架构

		垂直应用体系带来的缺陷是，相同逻辑的代码在不同的垂直应用中复制，不能复用，难以维护和升级。
		将公共的业务逻辑提取出来，形成服务，对外提供，避免重复造轮子，相同的逻辑维护一份，也便于升级改造，
		原本需要一个大团队维护的系统，也可以切分成一个个子系统，分配给一个个固定小团队来维护，降低了系统发布的风险，提高了系统的稳定性，
		并且也可以让前端业务系统与底层数据访问分离，团队分工更为明确。

	分布式系统的中间件及基础设施

		在系统逐步服务化的同时，一个大型、稳健、成熟的分布式系统背后，往往会涉及众多的中间件，以及一系列的支撑系统，我们将这些中间件和支撑系统称为分布式系统的基础设施。

		分布式系统所依赖的基础设施包括：
			服务框架、消息中间件、数据访问中间件、配置中心、分布式缓存系统、持久化存储(关系数据库、 nosql数据库)、搜索引擎、 CDN网络、负载均衡系统、
			运维自动化系统、硬件虚拟化及镜像管理系统、分布式文件系统、日志收集系统、监控系统、离线计算、实时计算、数据仓库等等。

			
SOA体系架构------通信协议和远程调用
			
			
	面向服务的体系架构------SOA

		随着服务化的进一步发展，服务越来越多，服务之间的调用和依赖关系也越来越复杂，诞生了面向服务的架构体系(SOA)，也因此衍生出了一系列相应的技术，
		如对服务提供、服务调用、连接处理、通信协议、序列化方式、服务发现、服务路由、日志输出等行为进行封装的服务框架，以及为大规模的服务化应用保驾护航的服务治理系统。

	RPC远程调用

		RPC的全称是Remote Process Call，即远程过程调用，它应用广泛，实现方式也很多，
		拥有包括RMI、 WebService等等诸多成熟的方案，在业界得到了广泛的使用。
		RPC的实现包括客户端和服务端，即服务的调用方以及服务的提供方，服务调用方发送；
		RPC请求到服务提供方，服务提供方根据调用方提供的参数执行请求方法，将执行结果返回给调用方，一次RPC调用完成。

	通信协议---协议栈

		协议是通信的规范，根据TCP/IP协议模型，HTTP协议属于应用层协议，它构建在TCP和IP协议之上，处于TCP/IP体系架构中的最顶端，
		这样一来，它便不需要处理下层协议间诸如丢包补发，握手以及数据的分段和重新组装等等繁琐的细节，从而使开发人员可以专注于上层应用的设计。

	RPC通信协议的选择-TCP协议

		基于TCP协议实现的RPC，由于处于协议栈的下层，能够更灵活的对协议字段进行定制，减少网络传输字节数，降低网络开销，提高性能，达到更大的吞吐量和并发数，
		但是需要更多的关注的底层复杂细节，实现的代价更高，较难实现跨平台的调用。
		而随着请求规模的扩展，基于TCP协议RPC的实现，程序需要考虑多线程并发，锁， IO等等复杂的底层细节的实现，实现起来较为复杂。
		在大流量高并发压力下，任意一个细小的错误，都会被无限放大，最终导致程序宕机。

	RPC通信协议的选择—HTTP协议

		基于HTTP协议的RPC，可以使用JSON或者是XML格式的响应数据，而JSON和XML作为通用的格式标准，开源的解析工具已经相当成熟，在其上进行二次开发屏蔽了很多底层繁琐的细节，非常便捷和简单。
		而对于基于HTTP协议的实现来说，很多成熟的开源WEB容器已经帮其处理好这些事情，如 tomcat、jboss、apache等等，开发人员可以将更多的精力集中在业务的实现上，而非底层细节的处理。
		基于HTTP协议的实现，也有其处于劣势的一面。由于是上层协议，发送包含同等内容的信息，使用HTTP协议传输所占用的字节数肯定要比使用TCP协议传输所占用的字节数更多。
		因此，同等网络环境下，通过HTTP协议传输相同内容，效率会比基于TCP协议的数据传输要低，信息传输所占用的时间要更长。
		通过优化代码实现以及使用gzip数据压缩，能够缩小这一差距。通过权衡利弊，结合实际环境中其性能对于用户体验的影响来看，基于HTTP协议的RPC还是有很大优势的。

	对象序列化

		将对象转换为能够在网络上传输的二进制流的过程称为对象的序列化。
		将二进制流恢复为对象的过程称为对象的反序列化。

	对象序列化方式的选择

		Google的Protocol Buffers真正开源出来的时间并不长，但是其性能优异，短时间内引起了广泛的关注。
		其优势是性能十分优异，支持跨平台，但使用其编程代码侵入性较强，需要编写proto文件，无法直接使用Java等面向对象编程语言的对象。
		相对于Protocol Buffers，Hessian的效率稍低，但是其对各种编程语言有着良好的支持，且性能稳定，比Java本身内置的序列化方式的效率要高很多。 
		Java内置的序列化方式不需要引入第三方包，使用简单，在对效率要求不是很敏感的场景下，也未尝不是一个好的选择。
		而的Xml和Json格式，在互联网领域尤其是现在流行的移动互联网领域，得益于其跨平台的特性，得到了极为广泛的应用。

	基于java的序列化方式

	基于hession的序列化方式

	基于JSON的序列化方式

	基于XML的序列化方式

	远程调用的实现 – 基于TCP的远程调用

	远程调用的实现—— 基于HTTP的远程调用

	两种URL风格— RPC

		RPC风格的URL比较好理解，直接在HTTP请求的参数中标明需要远程调用的服务接口名称，服务需要的参数，如下所示：
		http://hostname/provider.do?service=com.http.sayhello&format=json&timestamp=2013-07-07-13-22-09&arg1=arg1&arg2=arg2
		hostname表示服务提供方的主机名，service表示远程调用的服务接口名称，format表示返回参数的格式，timestamp表示客户端请求的时间戳， arg1和arg2表示服务所需要的参数。

	两种URL风格—RESTful

		POST http://hostname/people 创建name为zhangsan的people记录
		GET http://hostname/people/zhangsan 返回name为zhangsan的people记录
		PUT http://hostname/people/zhangsan 提交name为zhangsan的people记录更新
		DELETE http://hostname/people/zhangsan 删除name为zhangsan的people记录

	两种URL风格—RESTful

		RESTful风格其中的一个思想是，通过HTTP请求对应的POST、 GET、 PUT、DELETE方法，来完成对应的CRUD 操作。

	两种URL风格—RESTful 结合 RPC

		POST arg1=hello arg2=123
		URL http://hostname/provider/sayhelloservice/2013-07-07-13-22-09.json

		URL中hostname表示的是服务提供方的主机名， provider表示访问的是服务提供方， 
		sayhelloservice是对应的服务接口名称， .json表示的是需要服务端返回的数据格式， 
		2013-07-07-13-22-09表示的是客户端访问的时间戳，arg1和arg2参数采用POST方式发送到服务端。


SOA体系架构------路由和服务治理

	
	服务路由
	
		SOA架构中，服务消费者通过服务名称，在众多服务中找到要调用的服务的地址列表，称作为服务的路由。
		
	服务负载均衡
		
		对于负载较高的服务来说，往往对应着由多台服务器组成的集群。
		在请求到来时，为了将请求均衡地分配到后端服务器，负载均衡程序将从服务对应的地址列表中，
		通过相应的负载均衡算法和规则，选取一台服务器进行访问，这个过程称为服务的负载均衡
	
	单个服务的负载均衡
	
		当服务的规模较小时，可以采用硬编码的方式将服务地址和配置写在代码中，
		通过编码的方式来解决服务的路由和负载均衡的问题，也可以通过传统的硬件负载均衡设备如F5等，
		或者是采用LVS或nginx等软件解决方案，通过相关配置，来解决服务的路由和负载均衡问题。
		由于服务的机器数量在可控范围内，因此维护成本能够接受。
	
	多服务路由及负载均衡
	
		当服务越来越多，规模越来越大，对应的机器数量也越来越庞大，单靠人工来管理和维护服务及地址的配置信息，已经越来越困难。
		并且，依赖单一的硬件负载均衡设备或者使用LVS、 nginx等软件方案进行路由和负载均衡调度，
		单点故障的问题也开始凸显，一旦服务路由或者负载均衡服务器宕机，依赖其的所有服务均将失效。
	
	服务配置中心
	
		此时，需要一个能够动态注册和获取服务信息的地方，来统一管理服务名称和其对应的服务器列表信息，称之为服务配置中心。
	
	服务注册与查询
	
		服务提供者在启动的时候，将其提供的服务名称，服务器地址注册到服务配置中心，
		服务消费者通过服务配置中心来获得需要调用的服务的机器列表，通过相应的负载均衡算法，选取其中一台服务器进行调用，
		当服务器宕机或者下线的时候，相应的机器需要能够动态的从服务配置中心里面移除，
		并通知相应的服务消费者，否则服务消费者就有可能调用到已经失效的服务而发生错误。
		在这个过程中，服务消费者只有在第一次调用服务的时候需要查询服务配置中心，
		然后将查询到的信息缓存到本地，后面的调用直接使用本地缓存的服务地址列表信息，
		而不需要重新发起请求到服务配置中心去获取相应的服务地址列表，直到服务的地址列表有变更(机器上线或者下线)，
		这种无中心化的结构，解决了之前负载均衡设备所导致的单点故障的问题，并且大大减轻了服务配置中心的压力。
	
	Zookeeper让服务配置变得更简单
	
		zookeeper是Hadoop下的一个子项目，它是一个针对大型分布式系统的可靠的协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。
		zookeeper是可以集群复制的，集群间通过Zab(Zookeeper Atomic Broadcast)协议来保持数据的一致性。
		
		基于zookeeper的持久和非持久节点，我们能够近乎实时的感知到后端服务器的状态(上线、下线、宕机)。通过集群间zab协议，使得服务配置信息能够保持一致。
		而zookeeper本身容错特性以及leader选举机制，能保障我们方便的进行扩容。
		通过zookeeper来实现的服务动态注册、机器上线与下线的动态感知，扩容方便，容错性好，
		且无中心化结构能够解决之前使用负载均衡设备所带来的单点故障问题，
		只有当配置信息更新时才会去zookeeper上取最新的服务地址列表，其他时候使用本地缓存即可。
	
	服务负载均衡—常见的负载均衡算法
	
		轮询(Round Robin)法，
			轮询很容易理解，将请求按顺序轮流的分配到后端服务器上，它均衡的对待后端每一台服务器，而不关心服务器实际的连接数和当前的系统负载。
		
		随机(Random)法，
			通过系统随机函数，根据后端服务器列表的大小值，来随机选取其中一台进行访问，
			由概率统计的理论可以得知，随着调用量的增大，其实际效果越来越接近于平均分配流量到每一台后端服务器，也就是轮询的效果。
		
		源地址哈希(Hash)法，
			源地址哈希的思想是获取客户端访问的ip地址值，通过哈希函数计算得到一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是要访问的服务器的序号。
			采用哈希法进行负载均衡，同一ip地址的客户端，当后端服务器列表不变的时候，它每次都会被映射到同一台后端服务器进行访问。
		
		加权轮询(Weight Round Robin)法，
			不同的后端服务器，可能机器的配置和系统当前的负载并不相同，
			因此他们抗压能力也不尽相同，给配置高负载低的机器配置更高的权重，
			让其处理更多的请求，而低配置负载高的机器，则给其分配较低的权重，降低其系统负载，
			加权轮询能很好的处理这一问题，并将请求顺序且按照权重分配到后端。
		
		
		加权随机(Weight Random)法，
			与加权轮询法类似，加权随机法也根据后端服务器不同的配置和负载情况，配置不同的权重，不同的是，其实按照权重来随机选取服务器，而非顺序。
		
		最小连接数(Least Connections)法，
			最小连接数算法比较灵活和智能，由于后端服务器配置不尽相同，对于请求的处理有快有慢，
			它正是根据后端服务器当前的连接情况，动态的选取其中一台当前积压连接数最少的服务器，来处理当前请求，
			尽可能的提高后端服务器的利用效率，将负载合理的分流到每一台机器。
	
	服务服务负载均衡—多机房场景
	
		每个机房都有自己的容量上限，如果网站的规模非常大，就需要多个机房来支撑了，机房之间可能是跨地域的，机房之间的距离决定了我们采用什么样的架构策略。
		先不考虑服务配置中心的跨机房问题，因为服务的信息是可以本地缓存的，来重点看一下服务消费者和服务提供者在多机房下的情况。
	
	服务升级
	
		1.对于只在接口中增加方法，这种情况比较简单，直接增加方法便可。需要使用新方法的调用者直接使用新方法，原来的调用者继续使用原来的方法。
		2.对于需要对接口中某些方法修改调用参数列表的情况，这种情况相对复杂，我们有几种方式来进行应对：
			A. 对使用原来方法的代码都进行修改，然后和服务端一起发布。
				这仅仅从理论上来说可行，但是实际情况下操作起来非常困难，因为依赖这个服务提供者的系统可能非常之多，要求这些系统同时发布，很难实现。
			B. 通过版本号来解决，这是比较常用的方式，使用老方法的系统继续调用原来版本的服务，而需要使用新方法的系统则使用新版服务。
			C. 在设计方法上考虑参数的扩展性，这是一个可行的方式，但是不太好，因为参数列表可扩展一般意味着采用类似map的方式来传递参数，这样使得参数校验会比较麻烦。
	
	借助zookeeper实现路由与负载均衡
	
		当服务越来越多，规模越来越大，对应的机器数量也越来越庞大，单靠人工来管理和维护服务及地址的配置信息，已经越来越困难。
		并且，依赖单一的硬件负载均衡设备或者使用LVS、nginx等软件方案进行路由和负载均衡调度，单点故障的问题也开始凸显，
		一旦服务路由或者负载均衡服务器宕机，依赖其的所有服务均将失效。
		如果采用双机高可用的部署方案，使用一台服务器stand by，能部分解决问题，
		但是鉴于负载均衡设备的昂贵成本，也难以全面推广。
	
	服务治理
	
		分布式SOA环境下系统的依赖错综复杂，同一个应用即可能是服务者也可能是服务消费者，作为服务提供者所提供的服务，可能被多个服务消费者调用，
		外部调用的时间、 频次难以控制，而作为服务消费者，当前系统也可能会依赖其他第三方服务，但是第三方服务稳定性并不受服务调用方所控制，
		因此， 如何及时发现和避免由于第三方服务不稳定而影响到当前系统， 抑或是当前服务被某一第三方系统异常调用，导致整个系统瘫痪， 成为丞待解决的问题，这也成为服务治理的初衷。
		服务治理主要分为两个方面的内容，
		一个是服务的管理(服务上线下线、服务路由、服务限流和降级、服务归组、机房规则、服务授权)，
		另一方面即是服务相关信息的收集和展现
		(服务基本信息、服务质量的好坏、服务的容量和水位、服务依赖和被依赖、服务的机房分布、服务调用统计、服务提供的方法和参数、服务负责人、服务的统计报表、服务运行状态监视)，
		后面将主要介绍服务的稳定性管理。
	
	稳定性--依赖管理
	
		依赖管理最重要的意义在于弄清楚谁调用了谁，谁被谁调用了，调用频次如何。
		分布式SOA架构体系的特点便是，系统高度解耦，不同的应用对外提供了大量的服务，
		而通过第三方的服务调用，大大提高了开发的工作效率，降低重复造轮子的几率，
		与此同时，作为服务提供方，又可能要依赖许多其他第三方所提供的服务，因而，最终将形成一个网状的依赖关系。
	
	
	稳定性--依赖管理—调用日志分析
	
		通过服务消费日志，可以分析出每个服务依赖的服务，以及调用的频次，也可以分析出依赖于当前服务的应用，以及服务被调用的次数。
	
	稳定性--服务分级
	
		通过依赖的管理，我们能够知道，当前系统调用了哪些服务，被哪些服务调用。
		接下来，我们便可以根据当前系统所依赖的服务，以及系统的流程，判断依赖的服务是否会影响应用的主流程，以此来决定当前应用依赖的优先级。
		对于服务提供者来说，需要清楚了解当前的服务到底被多少人调用，并建立应用白名单机制，服务调用需要事先申请，以便将调用方增加到白名单当中进行管理和容量规划。
		为保障系统稳定，对于未知的调用者，最好的方式便是直接拒绝，以免给系统带来不确定风险。
		如果没有事先的容量规划，当未知的调用者流量突增，很可能将系统拖垮。
		服务提供者也需要对服务消费者的优先级进行区分，哪些调用将影响核心链路，哪些调用是非核心链路。
		当系统压力过大，无法承载的时候，必须优先确保重要等级高的应用，核心的调用链路优先确保畅通，
		而对于重要性不那么高的应用，则可以暂时先丢车保帅。
	
	稳定性--优雅降级
	
		当依赖的服务出现不稳定，响应缓慢或者调用超时，或者依赖系统宕机，当前的系统需要能够及时感知到并进行相应处理，
		否则，大量超时的调用，有可能将当前系统的线程和可用连接数用完，导致新的请求进不来，服务僵死，这便是故障传递。
		如果处理不及时，故障的传递可将一个非核心链路的问题扩大，引起核心节点故障，最终形成多米诺骨牌效应，使得整个集群都不能对外提供服务。
		这样，服务调用优雅降级的重要性便体现出来了。对于调用超时的非核心服务，可以设定一个阀值，如果调用超时的次数超过这个阀值，便自动将该服务降级。
		此时，服务调用者跳过对该服务的调用，并指定一个休眠的时间点，当时间点过了以后，再次对该服务进行重试，如果服务恢复，则取消降级，
		否则，继续保持该服务的降级状态，直到所依赖的服务故障恢复。这样，便可以一定程度上避免故障传递的现象发生。
	
	稳定性--开关
		
		当系统负载较高，即将突破警戒水位的时候，如何通过实时地屏蔽一些非核心链路的调用，降低系统的负载呢？
		这个时候，需要系统预先定义一些开关，来控制程序的服务提供策略。开关通过修改一些预先定义好的全局变量，来控制系统的关键路径和逻辑，
		比如，可以定义一个是否允许某一个级别的应用调用当前服务的开关，当系统处于流量高峰期的时候，将非核心链路的调用屏蔽，等高峰期过去之后，再将相应的开关打开。
		当然，同一个应用，可能也会对外提供多个服务，如果服务耗费系统资源较多，且又不影响系统核心链路，
		这时，也可以将一些非核心的服务关闭掉，以减轻系统的负担，有效的提高系统对核心应用的服务能力
		
	服务监视、统计、报表
	
		服务运行运行期间，需要对服务器相应指标进行监控，如系统load、磁盘利用率、内存占用率、网络流量、 qps/tps等等对于服务的调用，需要有统计的报表，按照小时/日/周/月 展示，并且能够设置异常情况监控，如流量突增突降，系统要能够及时报警。
	
	应急预案
		紧急情况(如双十一、双十二、热点事件等)并不是时时刻刻都发生，大部分人在第一次面对突发事件时，难免会显得手足无措。
		因此，要想在系统出现故障的情况下，能够处变不惊，沉着应对，将损失降到最低，
		首先得准备一份应急预案，并且，得进行经常性的故障演练，以熟悉各种情况下对应的应急预案的操作流程和规范，
		避免紧急情况下错误的决策致使损失扩大，并且在实际操作中也能够积累经验。
		应急预案中需要明确的规定服务的级别，梳理清楚核心应用的调用链路，
		对于每一种故障，都做出合理的假设，并且有针对性的处理方法，对于级别低的调用和功能，事先准备好屏蔽的开关和接口。
	
	SOA所面临的问题
	
		SOA架构将公共的业务拆分出来，形成可共用的服务，最大程度的保障了代码和逻辑的复用， 避免了系统的重复建设，
		并且让应用程序的部署找到了一种持续可扩展的方案，给应用抗负载能力带来了质的飞跃。
		SOA架构所面临的一大问题就是如何解决集成服务应用普遍存在的一致性问题，
		举例来说，同时调用多个服务，当其中一个服务调用失败时，其他服务已经处理执行的结果该如何进行回滚，
		这在单机本地调用的情况下使用事务比较好处理，而分布式环境下的事务将问题复杂化，并且性能开销难以承受，
		因此，只有在极端情况下才会考虑强一致性，一般情况下更多的关注最终一致性。
		另外一个就是安全问题，面向企业的平台级的SOA架构，需要对参数传递、响应内容以及各种用户私有信息的交互，有着更严格的且特殊的安全需求，
		如何构建一个安全的SOA架构体系，也给技术人员带来了很大的挑战。
	
	
常见的网站攻击手和防御方式
	
	
	常见的攻击手段--XSS
	
		XSS攻击的全称是跨站脚本攻击(Cross Site Scripting)，为不跟层叠样式表(Cascading Style Sheets,CSS)的缩写混淆，故将跨站脚本攻击缩写为XSS,是WEB应用程序中最常见到的攻击手段之一。跨站脚本攻击指的是攻击者在网页中嵌入恶意脚本程序，当用户打开该网页时，脚本程序便开始在客户端的浏览器上执行，以盗取客户端cookie、盗取用户名密码、下载执行病毒木马程序甚至是获取客户端admin权限等等。
		
		<input type="text" name="nick" value="xiaomao">
		<input type="text" name="nick" value=""/><script>alert("haha")
		</script><!-" />
		还有一种场景，用户在表单上输入一段数据后，提交给服务端进行持久化，其他页面上需要从服务端将数据取出来展示。还是使用之前那个表单nick，用户输入昵称之后，服务端会将nick保存，并在新的页面展现给用户，当普通用户正常输入zhangsan，页面会显示用户的 nick 为 zhangsan：
		<body>
		zhangsan
		</body>
		但是，如果用户输入的不是一段正常的nick字符串，
		而是<script>alert("haha")</script>，
		服务端会将这段脚本保存起来，当有用户查看该页面时，页面会出现如下代码：
		<body>
		<script>alert("haha")</script>
		</body>
	
	常见的攻击手段—XSS该如何防御
	
		XSS之所以会发生，是因为用户输入的数据变成了代码。
		因此，我们需要对用户输入的数据进行HTML转义处理，将其中的“尖括号”、“单引号”、“引号” 之类的特殊字符进行转义编码。
		
		如今很多开源的开发框架本身默认就提供HTML代码转义的功能，如流行的jstl、 Struts等等，不需要开发人员再进行过多的开发。
		使用jstl标签进行HTML转义，将变量输出，代码如下：
		<c:out value="${nick}"
		escapeXml="true"></c:out>
		只需要将escapeXml设置为true，jstl就会将变量中的HTML代码进行转义输出。
	
	常见的攻击手段--CSRF
	
		CSRF攻击的全称是跨站请求伪造(cross site request forgery)，是一种对网站的恶意利用，
		尽管听起来跟XSS跨站脚本攻击有点相似，但事实上CSRF与XSS差别很大， XSS利用的是站点内的信任用户，而CSRF则是通过伪装来自受信任用户的请求来利用受信任的网站。你可以这么理解CSRF攻击：攻击者盗用了你的身份，以你的名义向第三方网站发送恶意请求。 CRSF能做的事情包括利用你的身份发邮件、发短信、进行交易转账等等，甚至盗取你的账号。
	
	常见的攻击手段—CSRF的防御
	
		1.cookie设置为HttpOnlyCSRF攻击很大程度上是利用了浏览器的cookie，为了防止站内的XSS漏洞盗取cookie，需要在cookie中设置"HttpOnly"属性，这样通过程序(如JavascriptS脚本、 Applet等)就无法读取到cookie信息，避免了攻击者伪造cookie的情况出现。
		2.增加token		CSRF攻击之所以能够成功，是因为攻击者可以伪造用户的请求，该请求中所有的用户验证信息都存在于cookie中，因此攻击者可以在不知道用户验证信息的情况下直接利用用户的cookie来通过安全验证。由此可知，抵御CSRF攻击的关键在于：在请求中放入攻击者所不能伪造的信息，并且该信息不存在于cookie之中。鉴于此，系统开发人员可以在HTTP请求中以参数的形式加入一个随机产生的token，并在服务端进行token校验，如果请求中没有token或者token内容不正确，则认为是CSRF攻击而拒绝该请求。
		3.通过Referer识别
		根据HTTP协议，在HTTP头中有一个字段叫Referer，它记录了该HTTP请求的来源地址。在通常情况下，访问一个安全受限页面的请求都来自于同一个网站。比如某银行的转账是通过用户访问http://www.xxx.com/transfer.do页面完成，用户必须先登录www.xxx.com，然后通过点击页面上的提交按钮来触发转账事件。当用户提交请求时，该转账请求的Referer值就会是提交按钮所在页面的URL（本例为www.xxx.com/transfer.do）。如果攻击者要对银行网站实施CSRF攻击，他只能在其他的网站构造请求，当用户通过其他网站发送请求到银行时，该请求的Referer的值是其他网站的地址，而不是银行转账页面的地址。
		因此，要防御CSRF攻击，银行网站只需要对于每一个转账请求验证其Referer值，如果是以www.xxx.com域名开头的地址，则说明该请求是来自银行网站自己的请求，是合法的。如果Referer是其他网站的话，就有可能是CSRF攻击，则拒绝该请求。
	
	常见的攻击手段—SQL注入攻击
	
		所谓SQL注入，就是通过把SQL命令伪装成正常的HTTP请求参数，传递到服务端，欺骗服务器最终执行恶意的SQL命令，达到入侵目的。攻击者可以利用SQL注入漏洞，查询非授权信息，修改数据库服务器的数据，改变表结构，甚至是获取服务器root权限。总而言之，SQL注入漏洞的危害极大，攻击者采用的SQL指令，决定攻击的威力。当前涉及到大批量数据泄露的攻击事件，大部分都是通过利用SQL注入来实施的。
	
	常见的攻击手段—SQL注入攻击原理
	
		Connection conn = getConnection();
		String sql = "select * from hhuser where nick = '" + nickname +
		"'" + " and passwords = '" + password + "'";
		Statement st = (Statement) conn.createStatement();
		ResultSet rs = st.executeQuery(sql);
		List<UserInfo> userInfoList = new ArrayList<UserInfo>();
		while (rs.next()) {
		UserInfo userinfo = new UserInfo();
		userinfo.setUserid(rs.getLong("userid"));
		userinfo.setPasswords(rs.getString("passwords"));
		userinfo.setNick(rs.getString("nick"));
		userinfo.setAge(rs.getInt("age"));
		userinfo.setAddress(rs.getString("address"));
		userInfoList.add(userinfo);
		}
	
		当用户输入nick为zhangsan，密码为' or '1'='1的时候，
		意想不到的事情出现了，页面显示为login状态。
		
		以上便是一次简单的、典型的SQL注入攻击。
		当然， SQL注入的危害不仅如此，
		假设用户输入用户名zhangsan，在密码框输入' ;drop tableaaa;--， 
	
	常见的攻击手段—SQL注入攻击防御
	
	1. 使用预编译语句
		预编译语句PreparedStatement是java.sql中的一个接口，继承自Statement接口。通过Statement对象执行SQL语句时，需要将SQL语句发送给DBMS，由DBMS先进行编译后再执行。而预编译语句和Statement不同，在创建PreparedStatement对象时就指定了SQL语句，该语句立即发送给DBMS进行编译，当该编译语句需要被执行时，DBMS直接运行编译后的SQL语句，而不需要像其他SQL语句那样首先将其编译。
		前面介绍过，引发SQL注入的根本原因是恶意用户将SQL指令伪装成参数传递到后端数据库执行，作为一种更为安全的动态字符串的构建方法，预编译语句使用参数占位符来替代需要动态传入的参数，这样攻击者无法改变SQL语句的结构， SQL语句的语义不会发生改变，即便用户传入类似于前面' or '1'='1这样的字符串，数据库也会将其作为普通的字符串来处理。
	
	2. 使用ORM框架
		由上文可见，防止SQL注入的关键在于对一些关键字符进行转义，而常见的一些ORM框架，如ibatis、hibernate等，都支持对相应的关键字或者特殊符号进行转义，可以通过简单的配置，很好的预防SQL注入漏洞，降低了普通的开发人员进行安全编程的门槛。
		Ibatis的insert语句配置：
		<insert id="insert" parameterClass="userDO">
		insert into
		users(gmt_create,gmt_modified,userid,user_nick,address,age,sex)
		values(now(),now(),#userId#,#userNick#,#address#,#age#,#sex#)
		</insert>
		通过#符号配置的变量，ibatis能够对输入变量的一些关键字进行转义，防止SQL注入攻击。
	
	
	3.避免密码明文存放
		对存储的密码进行单向Hash，如使用MD5对密码进行摘要，而非直接存储明文密码，这样的好处就是万一用户信息泄露，即圈内所说的被“拖库”，黑客无法直接获取用户密码，而只能得到一串跟密码相差十万八千里的Hash码。

	4.处理好相应的异常
		后台的系统异常，很可能包含了一些如服务器版本、数据库版本、编程语言等等的信息，甚至是数据库连接的地址及用户名密码，攻击者可以按图索骥，找到对应版本的服务器漏洞或者数据库漏洞进行攻击，因此，必须要处理好后台的系统异常，重定向到相应的错误处理页面，而不是任由其直接输出到页面上。
	
	常见的攻击手段—文件上传漏洞
	
		在上网的过程中，我们经常会将一些如图片、压缩包之类的文件上传到远端服务器进行保存，文件上传攻击指的是恶意攻击者利用一些站点没有对文件的类型做很好的校验这样的漏洞，上传了可执行的文件或者脚本，并且通过脚本获得服务器上相应的权利，或者是通过诱导外部用户访问或者下载上传的病毒或者木马文件，达到攻击目的。
		为了防范用户上传恶意的可执行文件和脚本，以及将文件上传服务器当做免费的文件存储服务器使用，需要对上传的文件类型进行白名单(非黑名单，这点非常重要)校验，并且限制上传文件的大小，上传的文件，需要进行重新命名，使攻击者无法猜测到上传文件的访问路径。
		对于上传的文件来说，不能简单的通过后缀名称来判断文件的类型，因为恶意攻击可以将可执行文件的后缀名称改成图片或者其他的后缀类型，诱导用户执行。因此，判断文件类型需要使用更安全的方式。
		很多类型的文件，起始的几个字节内容是固定的，因此，根据这几个字节的内容，就可以确定文件类型，这几个字节也被称为魔数(magic number)。
	
	常见的攻击手段—DDoS攻击
	
	
		DDoS(Distributed Denial of Service)，即分布式拒绝服务攻击，
		是目前最为强大、最难以防御的攻击方式之一。要理解DDos，得先从DoS说起。
		最基本的DoS攻击就是利用合理的客户端请求来占用过多的服务器资源，从而使合法用户无法得到服务器的响应。 DDoS攻击手段是在传统的DoS攻击基础之上产生的一类攻击方式，传统的DoS攻击一般是采用一对一方式的，当攻击目标CPU速度、内存或者网络带宽等等各项性能指标不高的情况下，它的效果是明显的，但随着计算机与网络技术的发展，计算机的处理能力显著增加，内存不断增大，同时也出现了千兆级别的网络，这使得DoS攻击逐渐失去效果。这时候分布式拒绝服务攻击手段（DDoS）便应运而生了。
		你理解了DoS攻击以后，DDoS的原理就非常简单了，它指的是攻击者借助公共网络，将数量庞大的计算机设备联合起来作为攻击平台，对一个或多个目标发动攻击，从而达到瘫痪目标主机的目的。通常，在攻击开始前，攻击者会提前控制大量的用户计算机，称之为“肉鸡”，并通过指令使大量的肉鸡在同一时刻对某个主机进行访问，从而达到瘫痪目标主机的目的。
	
		DDoS的攻击有很多种类型，如依赖蛮力的ICMP Flood、 UDP Flood等等，
		随着硬件性能的提升，需要的机器规模越来越大，组织大规模的攻击越来越困难，现在已经不常见，还有就是依赖协议特征以及具体的软件漏洞进行的攻击，如Slowloris攻击， Hash碰撞攻击等等，这类攻击主要利用协议以及软件漏洞发起攻击，需要在特定环境下才会出现，更多的攻击者采用的是前面两种的混合方式，即利用了协议、系统的缺陷，又具备了海量的流量，如SYN Flood、 DNS Query Flood等等。
	
	常见的攻击手段—SYN Flood
		
		SYN Flood是互联网最经典的攻击方式之一，
		要明白它的攻击原理，还得从TCP协议连接建立的过程开始说起，TCP协议与UDP协议不同，TCP是基于连接的协议，也就是说，在进行TCP协议通讯之前，必须先建立基于TCP协议的一个连接，
		连接建立的过程如下：
			SYN、SYN-ACK、ACK。
	
	常见的攻击手段—DNS Query Flood
	
		DNS Query Flood实际上是UDP Flood攻击的一种变形，
		由于DNS服务在互联网中不可替代的作用，一旦DNS服务器瘫痪，影响甚大。
		DNS Query Flood 攻击采用的方法是向被攻击的服务器发送海量的域名解析请求，
		通常，请求解析的域名是随机生成，大部分根本就不存在，并且通过伪造端口和客户端IP，防止查询请求被ACL过滤。
		被攻击的DNS服务器在接收到域名解析请求后，首先会在服务器上查找是否有对应的缓存，由于域名是随机生成的，几乎不可能有相应的缓存信息，
		当没有缓存，并且该域名无法直接由该DNS服务器进行解析的时候，DNS服务器会向其上层DNS服务器递归查询域名信息，直到全球互联网的13台根DNS服务器。
		大量不存在的域名解析请求，给服务器带来了很大的负载，当解析请求超过一定量的时候，就会造成DNS服务器解析域名超时，这样攻击者便达成了攻击目的
	
	常见的攻击手段—CC攻击
	
		CC(Challenge Collapsar)攻击属于DDos的一种，
		是基于应用层HTTP协议发起的DDos攻击，也被称为HTTP Flood。
		CC攻击的原理是这样的，攻击者通过控制的大量“肉鸡”或者利用从互联网上搜寻的大量匿名的HTTP代理，模拟正常用户给网站发起请求直到该网站拒绝服务为止。
		大部分网站会通过CDN以及分布式缓存来加快服务端响应，提升网站的吞吐量，而这些精心构造的HTTP请求往往有意避开这些缓存，需要进行多次DB查询操作或者是一次请求返回大量的数据，加速系统资源消耗，从而拖垮后端的业务处理系统，甚至连相关存储以及日志收集系统也无法幸免。
	

常见安全加密算法及其使用场景
	
	
	常见安全算法—数字摘要
	
		数字摘要也称为消息摘要，它是一个唯一对应一个消息或文本的固定长度的值，它由一个单向Hash函数对消息进行计算而产生。
		如果消息在传递的途中改变了，接收者通过对收到消息采用相同的Hash重新计算，新产生的摘要与原摘要进行比较，就可知道消息是否被篡改了，因此消息摘要能够验证消息的完整性。
		消息摘要采用单向Hash函数将需要计算的内容"摘要"成固定长度的串，这个串亦称为数字指纹。
		这个串有固定的长度，且不同的明文摘要成密文，其结果总是不同的(相对的)，而同样的明文其摘要必定一致。这样这串摘要便可成为验证明文是否是"真身"的"指纹"了。
	
	常见安全算法—常用数字摘要算法
	
		MD5
			MD5即Message Digest Algorithm 5(信息摘要算法5)，是数字摘要算法一种实现，
			用于确保信息传输完整性和一致性，摘要长度为128位。
			MD5由MD4、MD3、MD2改进而来，主要增强算法复杂度和不可逆性，
			该算法因其普遍、稳定、快速的特点，在产业界得到了极为广泛的使用，
			目前主流的编程语言普遍都已有MD5算法实现。

		SHA
			SHA的全称是Secure Hash Algorithm，即安全散列算法。
			1993年，安全散列算法(SHA)由美国国家标准和技术协会（NIST)提出，
			并作为联邦信息处理标准(FIPS PUB 180)公布，
			1995年又发布了一个修订版FIPS PUB 180-1，通常称之为SHA-1。
			SHA-1是基于MD4算法的，现在已成为公认的最安全的散列算法之一，并被广泛使用。
			SHA-1算法生成的摘要信息的长度为160位，由于生成的摘要信息更长，运算的过程更加复杂，在相同的硬件上， SHA-1的运行速度比MD5更慢，但是也更为安全。
	
	常见安全算法—对称加密
	
		对称加密算法是应用较早的加密算法，技术成熟。
		在对称加密算法中，数据发送方将明文(原始数据)和加密密钥一起经过特殊加密算法处理后，生成复杂的加密密文进行发送，
		数据接收方收到密文后，若想读取原文，则需要使用加密使用的密钥及相同算法的逆算法对加密的密文进行解密，才能使其恢复成可读明文。
		在对称加密算法中，使用的密钥只有一个，发送和接收双方都使用这个密钥对数据进行加密和解密，这就要求加密和解密方事先都必须知道加密的密钥。
	
	常见安全算法—DES算法
	
		DES
			1973 年，美国国家标准局(NBS)在认识到建立数据保护标准既明显又急迫的情况下，开始征集联邦数据加密标准的方案。
			1975 年3月17日， NBS公布了IBM公司提供的密码算法，以标准建议的形式在全国范围内征求意见。
			经过两年多的公开讨论之后， 1977 年7月15日， NBS宣布接受这建议，作为联邦信息处理标准46 号数据加密标准(Data Encryptin Standard)，
			即DES(Data Encryptin Standard)正式颁布，供商业界和非国防性政府部门使用。
			DES算法属于对称加密算法，明文按64位进行分组，密钥长64位，
			但事实上只有56位参与DES运算(第8、 16、 24、 32、 40、 48、 56、 64位是校验位，使得每个密钥都有奇数个1),
			分组后的明文和56位的密钥按位替代或交换的方法形成密文。
			由于计算机运算能力的增强，原版DES密码的密钥长度变得容易被暴力破解，因此演变出了3DES算法。
			3DES是DES向AES过渡的加密算法，它使用3条56位的密钥对数据进行三次加密，是DES的一个更安全的变形。
	
	常见安全算法—AES算法
	
		AES
			AES的全称是Advanced Encryption Standard，即高级加密标准，
			该算法由比利时密码学家Joan Daemen和Vincent Rijmen所设计，结合两位作者的名字，又称Rijndael加密算法，
			是美国联邦政府采用的一种对称加密标准，这个标准用来替代原先的DES算法，已经广为全世界所使用，已然成为对称加密算法中最流行的算法之一。
			AES算法作为新一代的数据加密标准汇聚了强安全性、高性能、高效率、易用和灵活等优点，设计有三个密钥长度:128,192,256位，比DES算法的加密强度更高，更为安全。
	
	常见安全算法—非对称加密
	
		非对称加密算法又称为公开密钥加密算法，它需要两个密钥，
		一个称为公开密钥(public key)，即公钥，
		另一个称为私有密钥(private key)，即私钥。
		公钥与私钥需要配对使用，
		如果用公钥对数据进行加密，只有用对应的私钥才能进行解密，
		而如果使用私钥对数据进行加密，那么只有用对应的公钥才能进行解密。
		因为加密和解密使用的是两个不同的密钥，所以这种算法称为非对称加密算法。
		
		非对称加密算法实现机密信息交换的基本过程是：
		甲方生成一对密钥并将其中的一把作为公钥向其它人公开，
		得到该公钥的乙方使用该密钥对机密信息进行加密后再发送给甲方，
		甲方再使用自己保存的另一把专用密钥，即私钥，对加密后的信息进行解密。
	
	常见安全算法—RSA算法
	
		RSA
			RSA非对称加密算法是1977年由Ron Rivest、 Adi Shamirh和LenAdleman开发的， RSA取名来自开发他们三者的名字。RSA是目前最有影响力的非对称加密算法，它能够抵抗到目前为止已知的所有密码攻击，已被ISO推荐为公钥数据加密标准。RSA算法基于一个十分简单的数论事实：将两个大素数相乘十分容易，但反过来想要对其乘积进行因式分解却极其困难，因此可以将乘积公开作为加密密钥
	
	
数字签名与数字证书
	
	
	常见安全算法—数字签名
	
		签名认证是对非对称加密技术与数字摘要技术的综合运用，
		指的是发送者将通信内容的摘要信息用私钥进行加密，
		然后将密文与原文一起传输给信息的接收者，
		接收者通过发送者的公钥解密被加密的摘要信息，
		然后使用与发送者相同的摘要算法，
		对接收到的内容采用相同的方式产生摘要串，
		与解密的摘要串进行对比，
		如果相同，则说明接收到的内容是完整的，在传输过程中没有受到第三方篡改，
		否则则说明通信内容已被第三方修改。
		
		每个人都有其特有的私钥且都是对外界保密的，
		而通过私钥加密的的信息，只能通过其对应的公钥才能解密，
		因此，私钥可以代表私钥持有者的身份，
		可以通过私钥对应的公钥来对私钥拥有者的身份进行校验。
		
		通过数字签名，能够确认消息是由信息发送方签名并发送出来的，
		因为其他人根本假冒不了消息发送方的签名，他们没有消息发送者的私钥。
		不同的内容，摘要信息千差万别，通过数字摘要算法，可以确保传输内容的完整性，
		如果传输内容中途被篡改，对应的数字签名的值也将发生改变。
	
		只有信息的发送者才能产生别人无法伪造的数字签名串，
		这个串能对信息发送者所发送的内容完整性以及发送者的身份进行校验和鉴别。
		通信正文经过相应的摘要算法生成摘要后，
		使用消息发送者的私钥进行加密，生成数字签名。
	
		数字证书(Digital Certificate)，也称为电子证书，
		类似于日常生活中的身份证，也是一种形式的身份认证，用于标识网络中的用户身份。
		数字证书集合了多种密码学的加密算法，证书自身带有公钥信息，
		可以完成相应的加密、解密操作，
		同时，还拥有自身信息的数字签名，可以鉴别证书的颁发机构，以及证书内容的完整性。
		由于证书本身含有用户的认证信息，因此可以作为用户身份识别的依据。
	
	
		通常数字证书会包含如下内容：
			对象的名称(人，服务器，组织)
			证书的过期时间
			证书的颁发机构(谁为证书担保)
			证书颁发机构对证书信息的数字签名
			签名算法
			对象的公钥
	
	常见安全算法—X.509证书标准
	
		不同的数字证书，所包含的内容信息以及格式可能不尽相同，
		因此，需要有一种格式标准，来规范数字证书的存储和校验。
		大多数的数字证书都以一种标准的格式，即X.509，来存储他们的信息。
		X.509提供了一种标准的方式，将证书信息规范地存储到一系列可解析的字段当中，
		X.509 V3是X.509标准目前使用最为广泛的版本。
	
	常见安全算法—证书签发
	
		网络用户的数字证书则需要由数字证书认证机构(Certificate Authority，CA)来进行颁发，
		只有经过CA颁发的数字证书在网络中才具备有可认证性。
		数字证书的签发过程实际上就是对数字证书的内容，
		包括证书所代表对象的公钥，进行数字签名，
		而验证证书的过程，实际上是校验证书的数字签名，包含对证书有效期的验证。
	
	常见安全算法—证书校验
	
		客户端接收到数字证书时，首先会对证书的认证机构进行检查，
		如果该机构是权威的证书认证机构，则通过该权威认证机构的根证书，获得证书颁发者的公钥，
		通过该公钥，对证书的数字签名进行校验，并验证证书的有效时间是否过期。
		根证书是证书认证机构给自己颁发的数字证书，是证书信任链的起始点，
		安装根证书则意味着对这个证书认证机构的信任。
	
	常见安全算法—证书管理
	
		任何机构或者个人都可以申请数字证书，并使用数字证书对网络通信保驾护航，
		要获得数字证书，首先需要使用数字证书管理工具，
		如KeyTool、OpenSSL等等，构建CSR(Certificate Signing Request，数字证书签发申请)，
		提交给数字证书认证机构进行签名，最终形成数字证书。
		
		keytool
			KeyTool是java的数字证书管理工具，用于数字证书的生成、导入、导出以及撤销等操作。
			它与本地密钥库关联，并可以对本地密钥库进行管理，可以将私钥存放于密钥库，
			而公钥则使用数字证书进行输出。
		OpenSSL
			OpenSSL包含一个开源的SSL协议的实现，
			虽然OpenSSL使用SSL作为其名字的重要组成部分，但其实现的功能却远远超出了SSL协议本身。
			OpenSSL事实上包括了三个组成部分：SSL协议库、密码算法库以及各种与之相关的应用程序。
			关于SSL协议，后面介绍HTTPS协议的时候会介绍到。
			同时作为一个基于密码学的安全开发包，OpenSSL提供的功能相当强大和全面，
			囊括了主要的密码算法、常用的密钥和证书封装管理功能以及SSL协议，
			并提供了丰富的应用程序供测试或其它目的使用。
	
	Keystore的使用
	
		在构建CSR之前，需要先在密钥库中生成本地数字证书。
		生成本地数字证书需要提供用户的身份、加密算法、有效期等等一些数字证书的基本信息，
		这里使用www.codeaholic.net作为别名，使用RSA算法作为加密算法，并使用1024位的密钥，
		使用MD5withRSA作为数字签名算法，证书的有效期设置为365天。
			keytool -genkeypair -keyalg RSA -keysize 1024 -sigalg MD5withRSA -validity 365 -alias www.codeaholic.net -keystore /tmp/chenkangxian.keystore
		参数介绍：
			-genkeypair 产生密钥对
			-keyalg 加密算法，这里用的是RSA算法
			-keysize 密钥大小，这里设置为1024位
			-sigalg 签名算法，这里用的是MD5withRSA
			-validity 证书有效期，这里指定365天
			-alias 别名，这里用的是www.codeaholic.net
			-keystore 指定密钥库的位置，此处为/tmp/chenkangxian.keystore
	
	openssl的安装
	
		这里主要是使用OpenSSL来进行密钥和证书的管理。
		安装命令集合：
			sudo apt-get remove openssl
			wget http://mirrors.ibiblio.org/openssl/source/openssl-1.0.1e.tar.gz
			tar -xf openssl-1.0.1e.tar.gz
			./config
			make
			make install
	
	openssl生成私钥
	
		openssl genrsa -aes256 -out private/cakey.pem 1024
		
		参数含义如下：
			genrsa 表示使用RSA算法产生私钥
			-aes256 表示使用256位密钥的AES算法对私钥进行加密
			-out 表示输出文件的路径
			1024用来指定生成私钥的长度

			
认证、HTTPS协议、OAuth协议
			
			
	为什么需要认证
	
		经由HTTP协议进行通信的数据大都是未经加密的明文，包括请求参数、返回值、cookie、head等等数据，
		因此外界通过对通信的监听，轻而易举便可根据请求和响应双方的格式，
		伪造请求与响应，修改和窃取各种信息。
		相对于基于TCP协议层面的通讯方式，针对HTTP协议的攻击门槛更低。
		因此，基于HTTP协议的WEB及SOA架构，在应用的安全性方面，需要更加的重视。
	
	摘要认证
	
		对于普通的非敏感数据，我们更多的关注其真实性和准确性，
		因此，如何在通信过程中保障数据不被篡改，便成为首当其冲需要考虑的问题。
		鉴于使用HTTPS性能上的成本以及需要额外申请CA证书，
		这种情况下，一般采用对参数和响应进行摘要的方法，即能够满足需求 。
	
		由于摘要算法的不可逆性，并且，大部分情况下不同的请求参数，会有不同的服务端响应，
		鉴于参数和响应的多变性，因此摘要认证这种方式能够在一定程度上防止信息被篡改，保障通信的安全。
		但是，摘要认证的安全性取决于secret的安全性，
		由于服务端与客户端采用的是相同的secret，一旦secret泄露，通信的安全则无法保障。
	
	服务端校验
	
	客户端校验
	
	签名认证
	
		与摘要认证的方式类似，由于传递端和接收端都认为HTTP协议的请求参数是无序的，
		因此对于签名认证来说，客户端与服务端双方需要约定好参数的排序方式，请求的参数经过排序后，
		再将参数名称和值经过一定的策略组织起来，
		这时不再是加上secret，而是直接通过约定的摘要算法生成数字摘要，
		并且使用客户端私钥对数字摘要进行加密，将加密的密文传递给服务端。
	
	HTTPS协议
	
		HTTPS协议在HTTP协议与TCP协议增加了一层安全层，
		所有请求和响应数据在经过网络传输之前，都会先进行加密， 然后再进行传输。
		SSL及其继任者TLS是为网络通信提供安全及数据完整性保障的一种安全协议，
		利用加密技术，以维护互联网数据传输的安全，验证通信双方的身份，
		防止数据在网络传输的过程中被拦截及窃听。
	
	SSL协议—握手
	
		SSL，全称 Secure Sockets Layer，即安全套接层；
		是一种网络安全协议，是网景在其推出的Web浏览器中同时提出的，
		目的是为了保障网络通信的安全，校验通信双方的身份，加密传输的数据，
		SSL在传输层与应用层之间进行数据通信的加密。
		SSL协议的优势在于它与应用层协议独立无关，
		高层的应用层协议如HTTP、SSH、FTP等等，能透明的建立于SSL协议之上，
		在应用层通信之前就已经完成加密算法、通信密钥的协商以及服务端及客户端的认证工作，
		在此之后所有应用层协议所传输的数据都会被加密，从而保证通信的私密性。
	
	SSL协议—数据传输
	
		服务端与客户端真正的数据交换阶段，实际上数据是通过对称加密算法来实现加密的，
		密钥为双方约定好的加密密钥。
		客户端首先使用加密密钥加密请求内容，发送给服务端，
		服务端使用加密密钥对请求进行解密，并处理相应的请求，生成响应内容，
		响应经过加密密钥加密过后，发送给客户端，
		客户端通过加密密钥对响应内容进行解密，以获得响应内容。
	
	Tomcat部署HTTPS WEB
	
		修改tomcat配置
			cd tomcat/conf
			vim server.xml
		找到默认注释的HTTPS配置的这一行
			<!--
			<Connector port="8443" protocol="HTTP/1.1" SSLEnabled="true"
			maxThreads="150" scheme="https" secure="true"
			clientAuth="false" sslProtocol="TLS" />
			-->
		打开注释，加上keystore的地址以及keystore密码两项，
		keystoreFile="/home/longlong/temp/ testssl/server.keystore"，
		keystorePass="123456"，
		并且，将port修改为HTTPS默认的443端口，
		由于此处使用的keystore为PKCS#12格式，因此需要加上参数keystoreType="pkcs12"，
		由于这里配置的是单向认证，只需要校验服务端证书的有效性，所以clientAuth一项设置为false。
	
		<Connector port="443" protocol="HTTP/1.1" SSLEnabled="true"
			maxThreads="150" scheme="https" secure="true"
			clientAuth="false" sslProtocol="TLS"
			keystoreFile="/home/longlong/temp/testssl/server.keystore"
			keystorePass="123456"
			keystoreType="pkcs12"/>
		ubuntu从10.04起，默认关闭1024以下的端口，需要安装authbind，才能使用相应的端口。
		authb ind是GNU下的一个小工具，用于帮助系统管理员来为程序指定端口。
			sudo apt-get install authbind
			sudo touch /etc/authbind/byport/443
			sudo ./shutdown.sh
			sudo authbind --deep ./startup.sh
	
	OAuth协议
	
		OAuth协议旨在为用户资源的授权访问提供一个安全、开放的标准。
		平台商通过OAuth协议，提示用户对第三方软件厂商(ISV)进行授权，
		使得第三方软件厂商能够使用平台商的部分数据，对用户提供服务。
		与以往的授权方式不同，OAuth协议并不需要触及到用户的账户信息，即用户名密码，
		便可以完成第三方对用户信息访问的授权。
	
		用户通过平台商，对第三方应用进行授权，而第三方应用得到授权后，
		便可以在一定的时间内，通过平台商提供的接口，访问到用户授权的信息，为用户提供服务。
	
		要获得授权，首先需要第三方开发者向平台商申请应用ID，对自己的APP进行注册。
		一次OA uth授权涵盖了三个角色：普通用户(consumer)、第三方应用(ISV)、平台商(platform)。
		OAuth 对ISV授权数据访问过程包含了如下几个步骤：
			1. 用户对ISV的应用进行访问，发起请求。
			2. ISV收到请求后，向平台商请求request token，并带上其申请的appId。
			3. 平台将返回给第三方应用request token。
			4. ISV应用将用户引导到平台授权页面，带上自己的appId、request token以及回调地址。
			5. 用户在平台的页面上进行登录，并且完成授			权。
			6. 平台通过ISV提供的回调链接，返回给ISV应用access token。
			7. ISV应用通过access token取到用户授权的数据，进行加工后返回给用户，授权数据访问完成。

	
分布式系统的基础设施------缓存


	分布式系统的基础设施
		一个大型的稳健成熟的分布式系统的背后，往往会涉及众多的支撑系统，
		我们将这些支撑系统称为分布式系统的基础设施。
		除了前面所介绍的分布式协作及配置管理系统zookeeper之外，
		我们进行系统架构设计所依赖的基础设施，
		还包括分布式缓存系统、持久化存储、分布式消息系统、搜索引擎，
		以及CDN系统、负载均衡系统、运维自动化系统等等，
		还有后面章节所要介绍的实时计算系统、离线计算系统、分布式文件系统、
		日志收集系统、监控系统、数据仓库等等。
		  
	分布式缓存
		  
		高并发环境下，大量的读写请求涌向数据库，
		磁盘的处理速度与内存显然不在一个量级，
		从减轻数据库的压力和提高系统响应速度两个角度来考虑，一般都会在数据库之前加一层缓存。
		由于单台机器的内存资源以及承载能力有限，
		如果大量使用本地缓存，也会使相同的数据被不同的节点存储多份，对内存资源造成较大的浪费，
		因此，才催生出了分布式缓存.
		
	memcache
	
		memcache是一款开源的高性能的分布式内存对象缓存系统，
		用于在应用中减少对数据库的访问，提高应用的访问速度，并降低数据库的负载。
		为了在内存中提供数据的高速查找能力，
		memcache使用key-value的形式存储和访问数据，在内存中维护一张巨大的HashTable，
		使得对数据查询的时间复杂度降低到O(1)，保证了对数据的高性能访问。
		内存的空间总是有限的，
		当内存没有更多的空间来存储新的数据时，memcache就会使用LRU(Least Recently Used)算法，
		将最近不常访问的数据淘汰掉，以腾出空间来存放新的数据。
		memcache存储支持的数据格式也是灵活多样的，
		通过对象的序列化机制，可以将更高层抽象的对象转换成为二进制数据，存储在缓存服务器中，
		当前端应用需要时，又可以通过二进制内容反序列化，将数据还原成原有对象。
	
	缓存的分布式架构
	
		memcache本身并不是一种分布式的缓存系统，它的分布式，是由访问它的客户端来实现的。
		一种比较简单的实现方式是根据缓存的key来进行hash，
		当后端有N台缓存服务器时，访问的服务器为hash(key)%N，
		这样可以将前端的请求均衡的映射到后端的缓存服务器，
		但是这样也会导致一个问题，
		一旦后端某台缓存服务器宕机，或者是由于集群压力过大，需要新增新的缓存服务器，
		大部分的key将会重新分布，
		对于高并发系统来说，这可能会演变成一场灾难，
		所有的请求将如洪水般疯狂的涌向后端的数据库服务器，
		而数据库服务器的不可用，将会导致整个应用的不可用，形成所谓的“雪崩效应”。
	
	一致性hash算法
	
		consistent hash算法能够在一定程度上改善缓存的雪崩问题，
		它能够在移除/添加一台缓存服务器时，尽可能小的改变已存在的key映射关系，
		避免大量key的重新映射。
	
	分布式session
	
		传统的应用服务器，如tomcat、jboss等等，其自身所实现的session管理大部分都是基于单机的，
		对于大型分布式网站来说，支撑其业务的远远不止是一台服务器，而是一个分布式集群，
		请求在不同服务器之间跳转，需要保持服务器之间的session同步。
		传统网站一般通过将一部分数据存储在cookie中，来规避分布式环境下session的操作，
		这样做弊端很多，一方面cookie的安全性一直广为诟病，
		并且，cookie存储数据的大小是有限制的，
		随着移动互联网的发展，很多情况下还得兼顾移动端的session需求，
		使得采用cookie来进行session同步的方式弊端更为凸显。
		分布式session正是在这种情况下应运而生的。
	
	一种分布式session解决方案
	
		前端用户请求经过随机分发之后，可能会命中后端任意的web server，
		并且，web server也可能会因为各种不确定的原因宕机，
		这种情况下，session是很难在集群间同步的，
		而通过将session以sessionid作为key，保存到后端的缓存集群中，
		使得不管请求如何分配，即便是web server宕机，
		也不会影响其他的web server通过sessionid从cache server中获得session，
		这样，即实现了集群间的session同步，又提高了web server的容错性。
	
	缓存的容灾
	
		业务强依赖缓存，缓存需做到容灾：
			1.双机房互相备份
			2.数据复制多份，单台缓存失效，集群间能够自动复制和备份
			3.数据库留有余量
			4.万兆网卡
	
	
分布式系统的基础设施------持久化存储
	
	
	持久化存储
	
		传统的IOE解决方案，使用和扩展的成本越来越高，使得互联网企业不得不思考新的解决方案，
		开源软件加廉价PC server的分布式架构，得益于社区的支持，
		在节约成本的同时，也给系统带来了良好的扩展能力，并且由于开源软件的代码透明，
		使得企业能够以更低的代价定制更符合自身使用场景的功能，以提高系统的整体性能。
		互联网企业常用的三种数据存储方案，
		传统关系型数据库mysql，用来存储结构化数据，
		google率先提出的bigtable概念及其开源实现HBase，则用来存储海量的非结构化数据，
		还有诸如包含丰富数据类型的key-value存储redis，文档型存储mongodb等等..
	
	关系型数据库mysql—业务拆分
	
		业务发展初期为了便于快速迭代，很多应用都采用集中式的架构，随着业务规模的扩展，
		系统变得越来越复杂，访问量越来越大，不得不进一步扩展系统的吞吐能力。
		
		举例来说，假设某门户网站，它包含了新闻、用户、帖子、评论等等几大块内容，
		对于数据库来说，它可能包含这样几张表，news、users、post、comment，
		随着数据量的增加，可以根据业务逻辑进行拆分，分成多个库，以提高系统吞吐能力。
	
	关系型数据库mysql—数据复制
	
		通过数据库的复制策略，
		可以将一台mysql数据库服务器中的数据复制到其他的mysql数据库服务器之上，
		当各台数据库服务器上都包含相同数据的时候，
		前端应用通过访问mysql集群中任意一台服务器，都能够读取到相同的数据，
		这样，每台mysql服务器所需要承担的负载就会大大降低，
		从而提高整个系统的承载能力，达到系统扩展的目的。
		
		要实现数据库的复制，需要开启master服务器端的binary log，
		数据复制的过程实际上就是slave从master获取binary log，
		然后再在本地镜像的执行日志中所记录的操作，
		由于复制过程是异步的，因此，master和slave之间的数据有可能存在延迟的现象，
		此时只能够保证数据最终的一致性。
	
	关系型数据库mysql—读写分离
	
		前端服务器通过master来执行数据写入的操作，数据的更新通过binary log同步到slave集群，
		而对于数据读取的请求，则交由slave来处理，
		这样，slave集群可以分担数据库读的压力，
		并且，读写分离还保障了数据能够达到最终一致性。
		一般而言，大多数站点的读数据库操作要比写数据库操作更为密集，
		如果读的压力较大，还可以通过新增slave来进行系统的扩展，
		因此，master- slave的架构能够显著的减轻前面所提到的单库读的压力，
		毕竟在大多数应用当中，读的压力要比写的压力大的多。
	
	关系型数据库mysql—dual-master架构
	
		master-slaves复制架构存在一个问题，即所谓的单点故障，
		当master宕机，系统将无法写入，而
		在某些特定的场景下，可能需要master停机，以便进行系统维护、优化或者升级，
		同样的道理，master停机将导致整个系统都无法写入，直到master恢复，
		大部分情况下这显然是难以接受的。
		为了尽可能的降低系统停止写入的时间，
		最佳的方式就是采用dual master架构，即master-master架构。
		
	关系型数据库mysql—分表
		
		对于访问极为频繁且数据量巨大的单表来说，
		我们首先要做的，就是减少单表的记录条数，
		以便减少数据查询所需要的时间，提高数据库的吞吐，这就是所谓的分表。
		在分表之前，首先需要选择适当的分表策略，使得数据能够较为均衡的分布到多张表中，
		并且，不影响正常的查询。
		对于互联网企业来说，大部分数据都是与用户进行关联的，
		因此，用户id是最常用的分表字段，因为大部分查询都需要带上用户id，
		这样既不影响查询，又能够使数据较为均衡的分布到各个表中。
		
	关系型数据库mysql—分库
		
		分表能够解决单表数据量过大带来的查询效率下降的问题，
		但是，却无法给数据库的并发处理能力带来质的提升，面对高并发的读写访问，
		当数据库master服务器无法承载写操作压力时，不管如何扩展slave服务器，此时都没有意义了。
		因此，我们必须换一种思路，对数据库进行拆分，从而提高数据库写入能力，这就是所谓的分库。
		
	关系型数据库mysql—分库分表
		
		有的时候，数据库可能即面临着高并发访问的压力，又需要面对海量数据的存储问题，
		这时候，需要对数据库即采用分库策略，又采用分表策略，
		以便同时扩展系统的并发处理能力，以及提升单表的查询性能，这就是所谓的分库分表。
			中间变量=user_id%(库数量*每个库的表数量)库=取整(中间变量/每个库的表数量)
			表=中间变量%每个库的表数量
		
	关系型数据库mysql—分库分表策略
		
		分库分表的策略比前面的仅分库或者仅分表的策略要更为复杂，
		一种分库分表的路由策略如下：
			中间变量=user_id%(库数量*每个库的表数量)库=取整(中间变量/每个库的表数量)
			表=中间变量%每个库的表数量
		
		假设将原来的单库单表order拆分成256个库，每个库包含1024个表，那么，按照前面所提到的路由策略，对于userid=262145的访问，路由的计算过程如下：
			中间变量=262145%(256*1024)=1
			库=取整(1/1024)=0
			表=1%1024=1
		这意味着，对于userid=262145的订单记录的查询和修改，将被路由到第0个库的第1个表中执行。
		
	分库分表带来的限制
		
		1.条件查询、分页查询受到限制，查询必须带上分库分表所带上的id
		2.事务可能跨多个库，数据一致性无法通过本地事务实现，无法使用外键
		3.分库分表规则确定以后，扩展变更规则需要迁移数据
	
	为提升性能，mysql的取舍

		1.主从同步，master与slave之间数据存在延时同步，一致性由强一致性变为最终一致性
		2.分库分表，牺牲了查询的灵活性，必须带上分库分表所依赖的关键属性，
			牺牲了诸如外键、多表关联查询等RDBMS的传统特性.
		3.系统扩展复杂，数据库库、表路由规则的变更，数据迁移的成本高.
		4.业务拆分后，原先一个库中的表，可能被拆分到多个库中，使得原本简单的事务控制发展为分布式事务.
		
	持久化存储--hbase
		
		HBase是Apache Hadoop项目下的一个子项目，它以google BigTable为原型，
		设计实现了高可靠性、高可扩展性、实时读写的列存储数据库，
		它的本质实际上是一张稀疏的大表，用来存储粗粒度的结构化数据，
		并且，能够通过简单的增加节点来实现系统的线性扩展。
		HBase运行在分布式文件系统HDFS之上，
		利用它可以在廉价的PCServer上搭建起大规模结构化存储集群。
		HBase的数据以表的形式来进行组织，每个表由行列组成，
		与传统的关系型数据库不同的是，HBase每个列属于一个特定的列族，
		通过行和列来确定一个存储单元，
		而每个存储单元又可以有多个版本，通过时间戳来标识。
		
	持久化存储—hbase的架构
		
		 HBase集群中通常包含两种角色，HMaster和HRegionServer，
		 当表随着记录条数的增加而不断变大后，将会分裂成一个个region，
		 每个region可以由[startkey,endkey)来表示，它包含一个startkey到endkey的半闭区间。
		 一个HRegionServer可以管理多个region，
		 并由HMaster来负责HRegionServer的调度以及集群状态的监管。
		 由于region可分散由不同的HRegionServer来管理，因此理论上再大的表都可以通过集群来处理。
		
	持久化存储—hbase的api使用
		
	持久化存储—rowkey的设计
		
		举例来说，假设使用HBase来存储用户的订单信息，
		我们可能会通过这样几个维度来记录订单的信息，
		包括购买用户的id、交易时间、商品id、商品名称、交易金额、卖家id等等，
		假设需要从卖家维度来查看某商品已售出的订单，并且按照下单时间区间来进行查询，
		那么，订单表可以这样设计：
			rowkey：seller_id + auction_id + create_time
			列族：order_info(auction_title,price,user_id)
		使用卖家id+商品id+交易时间作为表的rowkey，
		列族为order，该列族包含三列，即商品标题、价格、购买者id，
		由于HBase的行是按照rowkey来排序的，
		这样，通过rowkey进行范围查询，可以缩小scan的范围。
				
		假设需要从购买者维度来进行订单数据的查询，
		展现用户购买过的商品，并且按照购买时间进行查询分页，
		那么 rowkey的设计又不同了：
			rowkey：user_id + create_time
			列族：order_info(auction_id,auction_title,price,seller_id)
		这样通过买家id+交易时间区间，便能够查询出用户在某个时间范围内购买所产生的订单
		
	持久化存储—二级索引表
		
		有时我们即需要从卖家维度来查询商品售出情况，又需要从买家维度来查询商品购买情况，
		类似的多条件复杂查询关系型数据库能够很好的支持，
		但是对于HBase来说，实现起来并不是那么的容易，
		基本的解决思路就是建立一张二级索引表，
		将查询条件设计成二级索引表的rowkey，而存储的数据则是数据表的rowkey，
		这样就可以一定程度上的实现多个条件的查询。
		但是二级索引表也会引入一系列的问题，多表的插入将降低数据写入的性能，
		并且由于多表之间无事务保障，可能会带来数据一致性的问题。
		
	持久化存储—hbase的使用场景和限制
		
		 与传统的关系型数据库相比，HBase有更好的伸缩能力，更适合于海量数据的存储和处理，
		 并且，由于多个region server的存在，使得HBase能够多个节点同时写入，
		 显著提高了写入性能，并且是可扩展的。
		 但是，HBase本身能够支持的查询维度有限，难以支持复杂查询，
		 如group by、order by、j oin等等，这些特点使得它的应用场景受到了限制。
		 当然，这也并非是不可弥补的硬伤，通过后面章节所介绍的搜索引擎，构建索引，
		 可以在一定程度上解决HBase复杂条件组合查询的问题。
		
	持久化存储—redis
		
		redis是一个高性能的key-value数据库，
		与其他很多key-value数据库不同之处在于，redis不仅支持简单的键值对类型的存储，
		它还支持其他的一系列丰富的数据存储结构，
		包括strings、hashs、lists、sets、sorted set s等等，并在这些数据结构类型上定义了一套强大的API。
		通过定义不同的存储结构，redis可以很轻易完成很多其他key-value数据难以完成的任务，
		如排序、去重等等。
		
	持久化存储—redis的api使用
		
	持久化存储—redis的使用场景
		
		相较于传统的关系型数据库，redis有更好的读写吞吐能力，能够支撑更高的并发数，
		而相较于其他的key-value类型的数据库，
		redis能够提供更为丰富的数据类型的支持，能够更灵活的满足业务需求。
		redis能够高效率的实现诸如排序取topN、访问计数器、队列系统、数据排重等等业务需求，
		并且，通过将服务器设置为cache-only，还能够提供高性能的缓存服务，
		相较于memcache来说，在性能差别不大的情况下，它能够支持更为丰富的数据类型。
		
		
分布式系统的基础设施------消息系统
		
		
	消息系统
		
		在分布式系统中，消息系统的应用十分广泛，
		消息可以作为应用间通信的一种方式，消息被保存在队列中，直到被接收者取出，
		由于消息发送者不需要同步等待消息接收者的响应，消息的异步接收降低了系统集成的耦合度，
		提升了分布式系统协作的效率，使得系统能够更快的响应用户，提供更高的吞吐，
		当系统处于峰值压力时，
		分布式消息队列还能够作为缓冲，削峰填谷，缓解集群的压力，避免整个系统被压垮。
		
	消息系统--JMS
		
		JMS(Java Message Service)，即Java消息服务，是J2EE提出消息服务规范，
		它是一组java应用程序接口，它提供消息的创建、消息的发送、消息接收、消息读取等等一系列服务。
		JMS定义了一组公共应用程序接口和相应的语法，类似于java数据库的统一访问接口JDBC，
		它是一种与厂商无关的API，使得java程序能够很好的与不同厂商的消息组件进行通信。
		JMS支持的消息类型包括：
			简单文本(TextMessage)、可序列化的对象(ObjectMessage)、
			键值对(MapMessage)、字节流(BytesMessage)、流(StreamMessage)，
			以及无有效负载的消息(Message)等等。
		消息的发送是异步的，因此消息的发布者发送完消息之后，不需要等待消息接收者立即响应，
		提高了分布式系统协作的效率。
		
	消息系统—JMS消息模型
		
		JMS支持两种消息发送和接收模型：
		一种称为Point-to-Point(P2P)模型，即采用点对点的方式发送消息，
			P2P模型是基于queue(队列)的，消息生产者发送消息到队列，
			消息消费者从队列中接收消息，队列的存在，使得消息的异步传输称为可能，
			P2P模型在点对点的情况下进行消息传递时采用。
		另一种为pub/sub(Publish/Subscribe，即发布/订阅)模型，
			发布/订阅模型定义了如何向一个内容节点发布和订阅消息，
			这个内容节点称为topic(主题)，主题可以认为是消息传递的中介，
			消息发布者将消息发布到某个主题，而消息订阅者则从主题订阅消息，
			主题使得消息的订阅者与消息的发布者互相保持独立，不需要进行接触即可保证消息的传递，
			发布/订阅模型在消息的一对多广播时采用。
		
	消息系统—点对点模型
		
		多个消息的生产者和消息的消费者都可以注册到同一个消息队列，
		当消息的生产者发送一条消息之后，只有其中一个消息消费者会接收到消息生产者所发送的消息，
		而不是所有的消息消费者都会收到该消息。
		
	消息系统—发布/订阅模型
		
		对于发布/订阅的消息传输模型来说，消息的发布者需将消息投递给topic，
		而消息的订阅者则需要在相应的topic进行注册，以便接收相应topic的消息，
		与点对点消息传输模型不同的是，消息发布者的消息将被自动发送给所有订阅了该topic的消息订阅者。
		当消息订阅者某段时间由于某种原因断开了与消息发布者的连接时，
		这个时间段内的消息将会丢失，除非将消息的订阅模式设置为持久订阅(durable subscription)，
		这时消息的发布者将会为消息的订阅者保留这部分时间所产生的消息，
		当消息的订阅者重新连接消息发布者时，消息订阅者仍然可以获得这部分消息，而不至于这部分消息丢失。
		
	消息系统—JMS模型的限制
		
		应用扩展后的Queue模型
		应用扩展后的Topic模型
		
	消息系统—我们需要的消息模型
		
		大型分布式系统对于消息系统的需求：
			1.消息发送和消息接收都是集群
			2.同一个消息的接收方可能有多台机器甚至是多个集群来进行消息的处理
			3.不同集群对于同一条消息的处理都不能相互干扰
		
		具体来说，我们可以把集群和集群之间对消息的消费当做topic模型来处理，
		而集群内部的各个具体应用实例对消息的消费当做queue模型来处理，
		我们可以引入groupid，用这个id来标识不同的集群，
		而集群内的各个应用实例的连接使用同样的groupid，
		当服务器进行调度时，根据groupid进行连接分组，
		在不同的groupid之间保障消息的独立投送，而拥有同样groupid的连接则共同消费这些信息。
		这个策略分两级来进行处理，把topic模型和queue模型的特点结合起来使用，
		从而达到多个不同的集群进行消息订阅的目的。
		当然，抛弃JMS意味着，
		我们可能需要自己实现连接的管理、消息创建、消息发送、消息接收、消息读取等一系列接口。
		
	消息系统—持久订阅和非持久订阅
		
	消息系统—如何保障消息的一致性
		
		业务处理代码：
			function(){
			//业务操作
			//调用服务，将数据写入数据库
			//发送消息
			}
		1.业务操作在前，发送消息在后，如果业务失败还行，如果业务成功，此时系统宕机，消息则发送失败
		2.如果业务成功，应用也正常，此时消息系统宕机，消息没收到，也会导致消息收不到
		
		另外一种业务代码的写法：
			function(){
			//发送消息
			//业务操作
			//调用服务或者写数据库
			}
		这种方式更不靠谱，业务如果失败，消息却已经发出。
		真正的生产环境，第一种做法丢失消息的比例相对来说是很低的，
		但是，对于必须保证一致性的场景下，比如跟交易相关的业务操作，这两种方案都不能接受。
		
	消息系统—如何保障消息的一致性
		
		
分布式系统的基础设施------垂直化搜索引擎
		
		
	垂直化搜索引擎
		
		 垂直化的搜索引擎，与大家所熟知的google和baidu等互联网搜索引擎巨头存在着一些差别，
		 垂直化的搜索引擎主要针对企业内部的自有数据的检索，
		 而不像google和baidu等搜索引擎平台，
		 采用网络爬虫对全网数据进行抓取，从而建立索引并提供给用户进行检索。
		 在分布式系统中，垂直化的搜索引擎是一个非常重要的角色，
		 它即能够满足用户对于全文检索、模糊匹配的需求，解决数据库like查询效率低下的问题，
		 又能够解决分布式环境下，由于采用分库分表、或者是使用NOSQL数据库，
		 导致无法进行多表关联或者进行复杂查询的问题。
		
	Lucene简介
		
		要深入的理解垂直化搜索引擎的架构，不得不提一个开源检索工具—lucene。
		lucene是apache旗下的一款高性能、可伸缩的开源的信息检索库，
		最初是由Doug Cutting所开发，并在SourceForge的网站上提供下载，
		从2001年9月开始，lucene做为高质量的开源java产品加入到Apache软件基金会，
		经过多年的不断发展和成熟，lucene被翻译成C++、C#、perl、python等多种语言，
		在全球范围内众多知名互联网企业中得到了极为广泛的使用。
		通过lucene，可以十分容易的为你的应用程序添加文本搜索功能，
		而不必深入地了解搜索引擎实现的技术细节以及高深的算法，极大的降低了搜索技术推广及使用的门槛。
		
	搜索引擎的几个概念--倒排索引
		
		 倒排索引(inverted index)，也称为反向索引，是搜索引擎中最常见的数据结构，
		 几乎所有的搜索引擎都会使用到倒排索引，
		 它将文档中的词作为关键字，建立词与文档的映射关系，
		 通过对倒排索引的检索，可以根据词快速获取包含这个词的文档列表，
		 这对于搜索引擎来说至关重要。
		
	搜索引擎的几个概念--分词
		
		分词，又称为切词，就是将句子或者段落进行切割，从中提取出包含固定语义的词。
		对于英语来说，语言的基本单位就是单词，因此，分词特别容易，
		只需要根据空格/符号/段落进行分割，并且排除停止词(stop word)，提取词干，即可完成，
		但是对于中文来说，要将一段文字准确的切分成一个个词，就不那么容易了，
		中文是以字为最小单位，多个字连在一起才能构成一个表达具体含义的词，
		中文的句子和段落都有一个明显的标点符号分割，唯独词没有一个形式上的分割符，
		因此，对于支持中文搜索的搜索引擎来说，需要一个合适的中文分词工具，以便建立倒排索引。 提取词干：是西方语言特有的处理步骤，比如英文中的单词有单复数的变形，-ing和-ed的变形，
		但是在搜索引擎中，应该当做同一个词。
		
		停止词(stop word)，在英语中包含了a、the、and这样使用频率很高的词，
		如果这些词都被建到索引中进行索引的话，搜索引擎就没有任何意义了，
		因为几乎所有的文档都会包含这些词，对于中文来说也是如此，
		中文里面也有一些出现频率很高的词，如“在”、“这”、“了”、“于”等等，
		这些词没有具体含义，区分度低，搜索引擎对这些词进行索引没有任何意义，
		因此，停止词需要被忽略掉。
		
	搜索引擎的几个概念--排序
		
		排序，当输入一个关键字进行搜索时，可能会命中许多文档，
		搜索引擎给用户的价值就是快速的找到需要的文档，
		因此，需要将相关度更大的内容排在前面，以便用户能够更快的筛选出有价值的内容，
		这时，就需要有适当的排序算法。
		一般来说，命中标题的文档将比命中内容的文档有更高的相关性，
		命中多次的文档比命中一次的文档有更高的相关性，
		商业化的搜索引擎的排序规则十分复杂，搜索结果的排序融入了广告、竞价排名等因素，
		由于牵涉的利益广泛，一般属于核心的商业机密。
		
	lucene的几个概念--文档
		
		
		文档(document)，在lucene的定义中，文档是一系列域(field)的组合，
		而文档的域则代表一系列与文档相关的内容，
		与数据库表的记录的概念有点类似，一行记录所包含的字段对应的就是文档的域，
		举例来说，一个文档比如老师的个人信息，可能包括年龄、身高、性别、个人简介等等内容。
		
	lucene的几个概念--域
		
		域(field)，索引的每个文档中都包含一个或者多个不同名称的域，
		每个域都包含了域的名称和域对应的值，并且，域还可以是不同的类型，如字符串、整型、浮点型等。
		
	lucene的几个概念—词
		
		词(term)，term是搜索的基本单元，与field对应，
		它包括了搜索的域的名称以及搜索的关键词，可以用它来查询指定域中包含特定内容的文档。
		
	lucene的几个概念—查询
		
		查询(query)，最基本的查询可能是一系列term的条件组合，称为TermQuery，
		但也有可能是短语查询(PhraseQuery)、前缀查询(PrefixQuery)、
		范围查询(包括TermRangeQuery、NumericRangeQuery等)等等。
		
	lucene的几个概念—分词器
		
		分词器(analyzer)，文档在被索引之前，需要经过分词器处理，
		以提取关键的语义单元，建立索引，并剔除无用的信息，如停止词等，以提高查询的准确性。
		中文分词与西文分词区别在于，中文对于词的提取更为复杂。
		常用的中文分词器包括一元分词、二元分词、词库分词等等。
		一元分词，即将给定的字符串以一个字为单位进行切割分词，
			这种分词方式较为明显的缺陷就是语义不准，
			如“上海”两个字被切割成“上”、“海”，但是包含“上海”、“海上”的文档都会命中。
		二元分词比一元分词更符合中文的习惯，因为中文的大部分词汇都是两个字，但是问题依然存在。
			词库分词就是使用词库中定义的词来对字符串进行切分，这样的好处
			是分词更为准确，但是效率较N元分词更低，且难以识别互联网世界中层出不穷的新兴词汇。
		
	Lucene索引构建过程
		
		 lucene索引的构建过程大致分为这样几个步骤，
		 首先，通过指定的数据格式，将lucene的Document传递给分词器Analyzer进行分词，
		 经过分词器分词之后，通过索引写入工具IndexWriter将索引写入到指定的目录。
		
		索引的查询，大概可以分为如下几个步骤，
		首先，构建查询的Query，通过IndexSearcher进行查询，得到命中的TopDocs，
		然后通过TopDocs的scoreDocs()方法，拿到ScoreDoc，
		通过ScoreDoc，得到对应的文档编号，
		IndexSearcher通过文档编号，使用IndexReader对指定目录下的索引内容进行读取，
		得到命中的文档返回。
		
	lucene的使用
		
	索引优化
		
		lucene的索引是由段(segment)组成的，
		每个段可能又包含多个索引文件，每个段包含了一个或者多个Document，
		段结构使得lucene可以很好的支持增量索引，新增的Document将被添加到新的索引段当中。
		但是，当越来越多的段被添加到索引当中，索引文件也就越来越多，
		一般来说，操作系统对于进程打开的文件句柄数是有限的，
		当一个进程打开太多的文件时，会抛出too many open files异常，
		并且，执行搜索任务时，lucene必须分别搜索每个段，然后将各个段的搜索结果合并，
		这样，查询的性能就会降低。
		
	全量索引重建
		
		因为前面说到我们产生索引碎片，而这些索引碎片即使进行了碎片合并而减少碎片数，
		但是一旦当碎片达到一定大小后就不适合继续进行合并，否则合并代价很大，
		所以我们无法避免的会因为碎片问题而导致更新实时性和查询QPS性能损耗问题。
		我们的解决的办法就是通过一段时间对具体业务全部源数据进行一次构建全量索引DUMP工作
		，用构建好的新的全量主索引去替换原来老的主索引和磁盘索引，
		从而让实时更新、搜索服务性能恢复到最佳。
		
	Lucene的IndexReader和IndexWriter
		
		Lucene的IndexReader和IndexWriter具有隔离性：
			当IndexReader.open打开一个索引的时候，相对于给当前索引进行了一次snapshot，
			此后的任何修改都不会被看到
			仅当IndexReader.open打开一个索引后，才有可能看到从上次打开后对索引的修改
			当IndexWriter没有调用Commit的时候，其修改的内容是不能够被看到的，
			哪怕IndexReader被重新打开
			欲使最新的修改被看到，一方面IndexWriter需要commit，一方面IndexReader重新打开
		
	实时更新
		
		倒排索引是有一定的格式的，而这个格式一旦写入是非常难以改变，那么如何能够增量建索引呢？
		Lucene使用段这个概念解决了这个问题，对于每个已经生成的段，
		其倒排索引结构不会再改变，而增量添加的文档添加到新的段中，
		段之间在一定的时刻进行合并，从而形成新的倒排索引结构。
		然而也正因为Lucene的索引读写的隔离性，使得Lucene的索引不够实时，
		如果想Lucene实时，则必须在新添文档后对IndexWriter进行commit，
		在搜索的时候IndexReader需要重新的打开，
		然而当索引在硬盘上的时候，尤其是索引非常大的时候，
		IndexWriter的commit操作和IndexReader的open操作都是非常慢的，
		根本达不到实时性的需要。
		
	实时更新过程
		
	搜索引擎的分布式
		
	使用solr的两大优势
		
		1.支持schema构建索引
		2.对复杂的动态的类SQL的查询条件的支持
		3.Solr并不完美，还有很多地方需要改进
		
		
分布式系统稳定性------日志分析
		
		
	日志分析常用命令--cat
		
		cat：查看文件的内容；
		cat命令是一个显示文本文件内容的便捷工具，
		如果一个日志文件比较小，可以直接使用cat命令将其内容打印出来，进行查看，
		但是对于较大的日志文件，请不要这样做，打开一个过大的文件可能会占用过多的系统资源，
		从而影响系统对外的服务。
		
		
	日志分析常用命令—more  or  less
		
		more 分页显示文件；
		cat的缺点在于，一旦执行后，便无法再进行交互和控制，
		而more命令可以分页的展现文件内容，
		按enter键显示文件下一行，按空格键便显示下一页，按f键显示下一屏内容，按b键显示上一屏内容。
		另一个命令less提供比more更加丰富的功能，支持内容查找，并且能够高亮显示。
		
	日志分析常用命令—tail
		
		tail 显示文件尾；
		使用tail命令能够查看到文件最后几行，这对于日志文件非常有效，
		因为日志文件常常是追加写入的，新写入的内容处于文件的末尾位置。
		
	日志分析常用命令—head
		
		head 显示文件头；
		与tail命令类似，但是不同的是head命令用于显示文件开头的一组行。
		
	日志分析常用命令—sort
		
		sort 内容排序；
		一个文件中包含有众多的行，经常需要对这些行中的某一列进行排序操作，
		sort命令的作用便是对数据进行排序。
		
	日志分析常用命令—wc
		
		wc  字符统计；
		wc命令可以用来统计指定文件中的字符数，字数，行数，并输出统计结果。
		
	日志分析常用命令—uniq
		
		uniq 查看重复出现的行；
		uniq命令可以用来显示文件中行重复的次数，
		或者显示仅出现一次的行，以及仅仅显示重复出现的行，
		并且，uniq的去重针对的只是连续的两行，因此它常常与sort结合起来使用。
		
	日志分析常用命令—curl
		
		curl  URL访问工具；
		要想在命令行下通过HTTP协议访问网页文档，就不得不用到一个工具，这便是curl，
		它支持HTTP，HTTPS，FTP，FTPS，Telnet等多种协议，
		常被用来在命令行下抓取网页和监控WEB服务器状态。
		
		
分布式系统稳定性------服务器监控
		
		
	发挥命令的威力—查看请求访问量
		
		对于在线运行的系统来说，常常会碰到各种不怀好意的恶意攻击行为，
		其中比较常见的便是HTTP flood，也称为CC攻击。
		如何能够快速的定位到攻击，并迅速响应，便成为开发运维人员必备的技能。
		定位问题最快捷的办法，便是登录到相应的应用，查看访问日志，找到相应的攻击来源，
		如访问量排名前10的ip地址：
			cat access.log | cut -f1 -d " " | sort | uniq -c | sort -k 1 -n -r | head -10
		页面访问量排名前10的url：
			cat access.log | cut –f4 -d " " | sort | uniq -c | sort -k 1 -n -r | head -10
		
	发挥命令的威力—查看最耗时的页面
		
		对于开发人员来说，页面的响应时间是非常值得关注的，
		因为这直接关系到用户能否快速的看到他想看到的内容。
		因此，开发人员常常需要将响应慢的页面找出来，进行优化：
			cat access.log | sort -k 2 -n -r | head -10
		
	发挥命令的威力—统计404页面占比
		
		对于请求的返回码，有些时候也是需要关注的，
		比如，如果404请求占比过多，要么就是有恶意攻击者在进行扫描，要么就是系统出现问题了，
		同样，对于500的请求也是如此，可以通过如下命令来查看404请求的占比：
			export total_line=`wc -l access.log | cut -f1 -d " "` && export
			not_found_line=`awk '$6=='404'{print $6}' access.log | wc -l` && expr
			$not_found_line \* 100 / $total_line
		
	sed编辑器
		
		sed支持在命令行直接指定文本编辑命令，具体格式如下：
			sed [options] 'command' file(s)
			command为具体的文本编辑命令，而file为输入的文件。
		如将日志文件中的xxx替换成yahoo输出：
			sed ‘s/xxx/yahoo/’ access.log | head -10
		筛选日志中指定的行输出：
			sed -n '2,6p' access.log
		根据正则表达式删除日志中指定的行：
			sed '/qq/d' access.log
		显示文件行号：
			sed '=' access.log
		
	awk程序
		
		awk使用的通用格式如下：
			awk [option]  'pattern {action}'  file
		其中option为命令的选项，pattern为行匹配规则，action为执行的具体操作，
		如果没有pattern，则对所有行执行action，
		而如果没有action，则打印所有匹配的行，file为输入的文件。
		打印文件指定的列：
			awk '{print $1}' access.log | head -10
		筛选指定的列，并打印出其中一部分行：
			awk '/google/{print $5,$6}' access.log | head -10
		对内容进行格式化输出：
			awk '{line = sprintf ( "method:%s,response:%s", $3 , $7 ); print line}'
			access.log | head -10
		
	awk程序—计算页面的平均响应时间
		
		{
		if( map[$4] > 0 ){
		map[$4]=map[$4] + $2map_time[$4]=map_time[$4] + 1
		}
		else{
		map[$4]=$2
		map_time[$4]= 1
		}
		}
		END{
		for(i in map){
		print i"="map[i]/map_time[i];
		}
		}
		
	终极武器—shell脚本
		
		脚本能够更加方便的使用外部工具和命令，将内容输出到各个通道甚至是数据库，
		处理和调度各种复杂的任务等等。
		举个例子来说，线上环境常常需要编写一些脚本，来查看系统运行的情况，并且定期执行，
		一旦系统出现异常，便打印出错误消息，监控系统通过捕捉错误消息，发出报警，
		下面一个脚本将能够查看系统的load和磁盘占用，在load超过2或者磁盘利用超过85%的情况下报警：
			load=`top -n 1 | sed -n '1p' | awk '{print $11}'`
			load=${load%\,*}
			disk_usage=`df -h | sed -n '2p' | awk '{print $(NF - 1)}'`
			disk_usage=${disk_usage%\%*}
			overhead=`expr $load \> 2.00`
			if [ $overhead -eq 1 ];then
			echo "system load is overhead"
			fi
			if [ $disk_usage -gt 85 ];then
			echo "disk is nearly full, need more disk space"
			fi
			exit 0
		
	集群监控指标--load
		
		系统的load被定义为特定时间间隔内运行队列中的平均线程数。
		load的值越大，也就意味着系统的CPU越繁忙，
		这样线程运行完以后等待操作系统分配下一个时间片段的时间也就越长。
		一般来说，只要每个CPU当前的活动线程数不大于3，我们认为它的负载是正常的，
		如果每个CPU的线程数大于5，则表示当前系统的负载已经非常高了，
		需要采取相应的措施来降低系统的负载，以便影响系统的响应速度。
		命令：
			top
			uptime 
		
	集群监控指标—CPU利用率
		
		在linux系统下，CPU的时间消耗主要在这几个方面，
		即用户进程、内核进程、中断处理、IO等待、nice时间、丢失时间、空闲等几个部分，
		而CPU的利用率则为这些时间所占总时间的百分比，
		通过CPU的利用率，能够反映出CPU的使用和消耗情况。
		可以通过top命令，查看linux系统的CPU消耗情况：
			top | grep Cpu
		
	集群监控指标—磁盘剩余空间
		
		磁盘剩余空间也是一个非常关键的指标，
		如果磁盘没有足够的剩余空间，正常的日志写入以及系统IO都将无法进行。
		通过df命令，能够看到磁盘的剩余空间：
			df -h
		
	集群监控指标—网络traffic
		
		对于对外提供服务的网络应用而言，网络的traffic也很值得关注。
		一般而言，托管在运营商机房的机器，网络带宽一般情况下不会成为瓶颈，
		并且集群内部网络都是通过光纤来进行通信，传输质量相当好。
		但是，对于单个节点来说，由于业务赋予的使命不尽相同，
		比如某些节点是进行负载均衡和反向代理的节点，
		某些节点是集群的master，对于网卡和带宽的要求更高，
		并且，某些极端情况下，比如大促活动，热点事件，网络流量急剧上升，
		也不排除某些应用会出现网络瓶颈，
		因此，关注网络的流量，清楚各个节点的阀值和水位，对于开发和运维人员来说，也十分重要。
		通过sar命令，可以看到系统的网络状况：
			sar –n DEV 1 1
		
	集群监控指标—磁盘IO
		
		磁盘I/O的繁忙度，也是一个重要的系统指标，
		对于I/O密集型的应用来说，比如数据库应用和分布式文件系统等等，
		I/O的繁忙程度也一定程度的反映了系统的负载情况，容易成为应用性能的瓶颈。
		查看系统的I/O状况：
			iostat -d -k
		
	集群监控指标—内存使用
		
		程序运行时的数据加载，线程并发，I/O缓冲等等，都依赖于内存，
		可用内存的大小，决定了程序是否能正常运行以及运行的性能。
		通过free命令，能够查看到系统的内存使用情况，加上-m参数表示以M为单位：
			free -m
		
	集群监控指标—qps
		
		qps是query per second的缩写，即每秒查询数，
		qps很大程度上代表了系统在业务上的繁忙程度，
		而每次请求的背后，可能对应着多次磁盘I/O，多次网络请求，以及多个CPU时间片。
		通过关注系统的qps数，我们能够非常直观的了解到当前系统业务情况，
		一旦当前系统的qps值超过所设置的预警阀值，即可考虑增加机器以对集群进行扩容，
		以免因压力过大而导致宕机，集群预警阀值的设置，
		可以根据前期压测得出的值，综合后期的运维经验，评估一个较为合理的数值。
		
	集群监控指标—rt
		
		rt是response time的缩写，即请求的响应时间。
		响应时间是一个非常关键的指标，直接关系到前端的用户体验，
		因此，任何开发人员和设计师都想尽可能的降低系统的rt时间。
		对于WEB应用来说，如果响应太慢而导致用户失去耐心，将流失大量的用户。
		降低rt时间需要从各个方面入手，找到应用的瓶颈，对症下药，
		比如，通过部署CDN边缘节点，缩短用户请求的物理路径，
		通过内容压缩，减少传输的字节数，使用缓存，减少磁盘I/O和网络请求等等。
		通过apache或者nginx的访问日志，便能够得知每个请求的响应时间。以nginx为例，访问日志的输出格式中，增加$request_time的输出，便能够获得响应时间。
		
		
分布式系统稳定性------JVM
		
		
	集群监控指标—java的GC
		
	集群监控指标—java的GC日志
		
		Parallel Scavenge收集器的GC日志的格式如下：
			2014-02-17T14:17:19.047+0800: 97.756: [GC [PSYoungGen: 1348425K->2096K(2216192K)]
			3360755K->2018009K(5116160K), 0.0640020 secs] [Times: user=0.24 sys=0.01, real=0.06 secs]
		Parallel Scavenge/Parallel Old组合Full GC所产生日志如下：
			2014-02-18T04:37:20.618+0800: 99.327: [Full GC [PSYoungGen: 2779200K->0K(2782336K)]
			[PSOldGen: 2475753K->1210837K(2899968K)] 5254953K->1210837K(5682304K) [PSPermGen:
			94128K->94128K(109568K)], 5.8954740 secs] [Times: user=6.13 sys=0.00, real=5.89 secs]
		ParNew收集器的GC日志格式如下所示：
			2014-02-20T13:12:23.334+0800: 143.977: [GC 143.977: [ParNew: 2356922K-
			>166185K(2403008K), 0.0275450 secs] 3160143K->1021743K(3975872K), 0.0278960 secs]
			[Times: user=0.37 sys=0.00, real=0.03 secs]
		
		CMS收集器是一款以获取最短回收停顿时间为目的的收集器，它是基于标记
		-清除算法实现的，运转过程比前面介绍的几个收集器更为复杂，整个过程大
		致分为四个步骤：
			初始标记(CMS initial mark)
			并发标记(CMS concurrent mark)
			重新标记(CMS remark)
			并发清除(CMS concurrent sweep)
		2014-02-20T13:11:17.554+0800: 78.196: [GC [1 CMS-initial-mark: 0K(1572864K)] 2240616K(3975872K), 1.1883700 secs] [Times: user=1.19 sys=0.00, real=1.19 secs]
		2014-02-20T13:11:18.743+0800: 79.385: [CMS-concurrent-mark-start]
		2014-02-20T13:11:18.810+0800: 79.452: [CMS-concurrent-mark: 0.037/0.067 secs] [Times: user=0.37sys=0.01, real=0.07 secs]
		2014-02-20T13:11:18.810+0800: 79.452: [CMS-concurrent-preclean-start]
		2014-02-20T13:11:18.838+0800: 79.481: [CMS-concurrent-preclean: 0.027/0.028 secs] [Times: user=0.11 sys=0.00, real=0.02 secs]
		2014-02-20T13:11:18.838+0800: 79.481: [CMS-concurrent-abortable-preclean-start]
		2014-02-20T13:11:19.180+0800: 79.822: [GC 79.822: [ParNew: 2346280K->218432K(2403008K),
		0.2444410 secs] 2346280K->263080K(3975872K), 0.2446420 secs] [Times: user=1.53 sys=0.23,
		real=0.24 secs]
		2014-02-20T13:11:23.395+0800: 84.037: [CMS-concurrent-abortable-preclean: 4.172/4.557 secs] [Times:user=15.22 sys=0.39, real=4.56 secs]
		2014-02-20T13:11:23.396+0800: 84.038: [GC[YG occupancy: 1337142 K (2403008 K)]84.038: [Rescan
		(parallel) , 0.0550880 secs]84.094: [weak refs processing, 0.0000140 secs]84.094: [class unloading,
		0.0126960 secs]84.106: [scrub symbol & string tables, 0.0146290 secs] [1 CMS-remark:
		44648K(1572864K)] 1381790K(3975872K), 0.0851600 secs] [Times: user=0.99 sys=0.00, real=0.09 secs]2014-02-20T13:11:23.481+0800: 84.124: [CMS-concurrent-sweep-start]
		2014-02-20T13:11:23.513+0800: 84.156: [CMS-concurrent-sweep: 0.031/0.032 secs] [Times: user=0.06 sys=0.01, real=0.03 secs]
		2014-02-20T13:11:23.514+0800: 84.156: [CMS-concurrent-reset-start]
		2014-02-20T13:11:23.530+0800: 84.172: [CMS-concurrent-reset: 0.016/0.016 secs] [Times: user=0.02sys=0.01, real=0.01 secs]
		
	集群监控指标—数据收集
		
		
分布式系统稳定性------心跳检测

		
	服务器心跳检测--ping
		
		在计算机世界里，ping是最常用的心跳检测方法，
		通过执行ping命令，发出要求远端主机回应的信息，
		假如远程主机的网络没有问题，就会对该消息进行回应。
		ping指令能够检测网络链路是否通畅，远端主机是否能够到达。
			ping 192.168.2.105
		
	服务器心跳检测—应用层检测
		
		通过curl指令定时访问应用中预留的自检url，可以实时的感知应用的健康状态，
		一旦系统无响应或者是响应超时，即可输出报警信息，
		以被相应的监控调度系统捕捉到，第一时间通知开发和运维人员进行处理。
		通过curl执行自检：
			curl http://xxx.com/selfcheck/check.htm
		
	服务器心跳检测—业务检测
		
		假设服务端正常返回，将在response的header中写入如下值：
			response.setHeader("Server-Status", "ok");
		即使用Ser ver-Status为ok标识服务端当前的返回是正常的，
		而假如该页面所依赖的服务宕机，页面无法正常显示，则可以不在response的header中设置值，
		或者设置Ser ver-Status为另外一个值，这样，检测程序便能够感知到系统此时已经发生异常。
		通过curl对header进行检测，通过-I选项，只查看header：
			curl -I http://xxx.com/selfcheck/index.htm
		
		
分布式系统稳定性------容量与水位


	容量评估—流量分配
	
	容量评估—机器估算
	
		假设机器的配置都是均衡对称的，
		我们需要取其中的一个最小子集来进行压力测试，以便得出单个单元所能够承载的访问量。
		压测机器的配置需要与线上机器保持同等配置，以免结果出现误差。
		系统运行的峰值，关乎应用的生死，往往是最后的那一根稻草，将系统压垮。
		在进行系统峰值评估的时候，一般会遵循一个原则，
		即所谓的80-20原则，80%的访问请求将在20%的时间内到达，
		这样，便可以根据系统对应的PV，计算出系统的峰值qps，
		如果是大型促销或者是推广力度较以往更大，视情况可乘以3-5倍，计算公式如下：
			峰值qps = (总的PV * 80% ) / (60 * 60 * 24 * 20%)
		然后，再将总的峰值qps除以单台机器所能够承受的最高的qps值，便是所需要机器的数量：
			机器数 = 总的峰值qps / 压测得出的单台机器极限qps
	
	容量评估—应用水位
		
		通过访问日志分析，或者其他统计手段，实时计算出当前系统的qps值(前1-2分钟的平均值)，
		然后，结合系统上线之前压力测试所得到的单台机器的极限qps，
		乘以当前部署的机器总数，便能够得到当前的水位：
			当前水位 = 当前总qps / (单台机器极限qps * 机器数) * 100%
		
	容量评估—历史水位
		
		通过历史数据的积累，还可以绘制出单个系统随着时间推移的历史水位，
		以便系统管理者能够随时回溯到历史峰值，给容量评估提供参考依据。

		
分布式系统稳定性------流量控制
		
		
	流量控制—为何要流量控制
		
	流量控制—限QPS
		
	流量控制—限并发
		
	流量控制—java信号量实现流控
		
		//信号量定义
		Semaphore semphore = new Semaphore(100);…
		//请求处理
		if(semphore.getQueueLength() > 0){
		return;
		}
		try {
		semphore.acquire();
		//处理具体的业务逻辑
		} catch (InterruptedException e) {
		e.printStackTrace();
		}finally{
		semphore.release();//释放
		}
		
	流量控制—通过分布式队列来流控
		
	服务稳定性
		
		
高并发系统设计
		
	高并发系统与普通系统的区别
		
		高并发系统设计与普通系统设计的区别在于，
		高并发系统既要保障系统的可用性和可扩展性，
		又要兼顾数据的一致性，还要处理多线程下线程安全的问题。
		任何细微问题，都有可能在高并发环境下被无限的放大，直至系统宕机。
		
	数据一致性
		
		分布式系统常常通过数据的复制来提高系统的可靠性和容错性，
		并且将数据的副本存放到不同的机器上，
		由于存在多个副本，使得维护副本一致性的代价很高。
		所以，许多分布式系统都采用弱一致性或者是最终一致性，来提高系统的性能和吞吐能力，
		这样，不同的一致性模型也相继被提出
		
	原子操作
		
		原子操作指的是不可分割的操作，它要么执行成功，要么执行失败，不会产生中间状态，
		在多线程程序中，原子操作是一个非常重要的概念，它常常用来实现一些数据同步机制，
		具体的例子如java的原子变量、数据库的事务等等，
		原子操作也是一些常见的多线程程序bug的源头，
		并发相关的问题对于测试来说，并不是每次都能够重现，因此处理起来十分棘手。
		
	java的原子操作—一个count统计的例子
		
		当java代码最终被编译成字节码时，run()方法会被编译成这么几条指令：
			public void run();
			Code:
			0:   aload_0
			1:   getfield        #17;
			4:   dup
			5:   getfield        #26; //获取count.count的值,并将其压入栈顶
			8:   iconst_1 //将int型1压入栈顶
			9:   iadd //将栈顶两int型数值相加,并将结果压入栈顶
			10:  putfield        #26; //将栈顶的结果赋值给count.count
			13:  aload_0
			14:  getfield        #19;17:  invokevirtual    #31;20:  return
			}
		
			native方法compareAndSwapInt在linux下的jdk的实现如下：
			UNSAFE_ENTRY( jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x))
			UnsafeWrapper("Unsafe_CompareAndSwapInt");
			oop p = JNIHandles::resolve(obj);
			jint* addr = ( jint *) index_oop_from_field_offset_long(p, offset);
			return ( jint)(Atomic::cmpxchg(x, addr, e)) == e;
			UNSAFE_END
			注：该段代码来自openjdk6的源码，代码的路径为hotspot/src/share/vm/prims/unsafe.cpp
		
			Unsafe_CompareAndSwapInt最终通过Atomic::cmpxchg(x, addr, e)来实现原子操作，而Atomic::cmpxchg在x86处理器架构下的linux下的jdk实现如下：
			inline jint Atomic::cmpxchg( jint exchange_value, volatile jint* dest, jint compare_value){
			int mp = os::is_MP();
			__asm__ volatile(LOCK_IF_MP(%4) "cmpxchgl %1,(%3)"
			: "=a" (exchange_value)
			: "r" (exchange_value),"a" (compare_value),"r" (dest),"r" (mp)
			: "cc", "memory");
			return exchange_value;
			}
			注:该段代码来自openjdk6的源码，代码的路径为hotspot/src/os_cpu/linux_x86/vm/atomic_linu x_x86.inline.hpp
		
	数据库事务
		
		数据库事务具有ACID属性，
		即原子性(Atomic)、一致性(Consistency)，隔离性(Isolation)，持久性(Durability)，
		为针对数据库的一系列操作提供了一种从失败状态恢复到正常状态的方法，
		使数据库在异常状态下也能够保持数据的一致性，
		并且，面对并发访问时，数据库能够提供一种隔离方法，避免彼此间的操作互相干扰。
		
		通过java进行数据库事务操作的代码：
		Class.forName("com.mysql.jdbc.Driver");
		Connection conn = DriverManager.getConnection("jdbc:mysql://localhost:3306/hhuser",
		"root", "123456");
		conn.setAutoCommit(false);
		try{
		Statement stmt = conn.createStatement();
		int insertResult = stmt.executeUpdate
		("insert into hhuser set userid=125,nick = 'chenkangxian'");
		int updateResult = stmt.executeUpdate
		("update hhuser set nick='chenkangxian@abc.com' where userid = 125");
		if(insertResult > 0 && updateResult > 0){
		conn.commit();
		}else{
		conn.rollback();
		}
		}catch(Exception e){
		conn.rollback();
		}
		
	多线程同步--synchronized

		还是前面Count计数的例子，通过在java中使用synchronized关键字和锁，实现线程间的同步：
			public void run() {
			synchronized(count){
			count.count++;
			}
			……
			}
				……
				6:   monitorenter 
				7:   aload_0
				8:   getfield 
				11:  dup
				12:  getfield 
				15:  iconst_1
				16:  iadd
				17:  putfield 
				20:  aload_1
				21:  monitorexit ……
		
	多线程同步--ReentrantLock
	
		在Count对象中加入ReentrantLock的实例：
			private final ReentrantLock lock = new ReentrantLock();
		然后在count.count++之前加锁，并且，++操作完成之后，释放锁给其他线程：
			count.lock.lock();
			count.count++;
			count.lock.unlock();
		
	典型案例—秒杀抽奖系统设计
		
	秒杀抽奖系统设计—防机器提交
	
		简单验证码:
		稍微复杂的验证码:
		混淆过的验证码:
		提问验证码:
		中文验证码:
		
	秒杀抽奖系统设计—并发减库存
		
	秒杀抽奖系统设计—库存拆分
		
		
寻找性能瓶颈和优化性能	
		
		
	如何寻找性能瓶颈
		
		对于性能优化来说，第一步也是最重要的一步，便是寻找可以优化的点，
		也就是所谓的性能瓶颈，性能瓶颈实际上就是木桶原理中最短的那一块木板，
		只有补上这块短板，才能够更好的发挥应用的整体性能。
		WEB的性能优化涉及到包括前端优化，服务端优化，操作系统优化，数据库查询优化，
		JVM调优等等众多领域的知识，每个领域如果深入去发掘，都可以编著成一本相关的书籍。
		因此，本小节将只是介绍一些常用的方法以及工具，来帮助快速定位性能的瓶颈。
		
	前端优化工具--yslow
		
		YSlow是yahoo!提供的用于网页性能分析的浏览器插件，
		它通过一系列由yahoo！提出并且得到业界充分认可的页面性能评估规则，
		来对当前页面进行性能检测，提供F-A 6个级别的评分，F代表最差，A表示最好，
		并且给出分析所得到的相关数据以及优化的具体建议。
		我们可以通过相关数据，快速发现页面的不足，并对自己的网站和服务器做相应的优化。
		
	前端性能优化
		
		yahoo!曾对网站速度优化提出了非常著名34条准则，后精简为更为直观的23条，
		这些著名的规则最后都反映在YSlow的评分体系上，YSlow会针对每一条来进行评分，
		如：
			页面的HTTP请求数量
			是否使用CDN网络
			是否使用压缩
			样式放在页面首部加载
			避免CSS表达式
			减少DNS查找
			将脚本放在页面底部加载
		
	页面响应时间
		
		 服务端单个请求的响应速度，跟整个页面的响应时间以及页面的加载速度密切相关，
		 它也是衡量页面性能的一个重要指标。借助另外一个工具firebug，
		 我们能够清楚的看到，整个页面的加载时间，以及具体每一个请求耗费的时间。
		 这样我们便能够快速找到响应慢的请求，分析原因，进行优化。
		
	服务端优化—方法响应时间
		
		定位到响应慢的请求以后，接下来便需要深入发掘导致请求响应慢的原因，并且定位到具体的代码。
		通过对代码的检查分析，能够定位到具体的方法和代码行，
		但是通常来说这种方式比较浪费时间，且容易遗漏，
		通过java环境下的一个十分有效的动态跟踪工具--btrace，能够快速的定位和发现耗时的方法。
		一段测试代码：
			@Override
			protected void doPost(HttpServletRequest req, HttpServletResponse resp)
			throws ServletException, IOException {
			PrintWriter out = resp.getWriter();
			try {
			Thread.sleep(500L);
			} catch (InterruptedException e) {}
			out.write("success");
			}
		
	服务端优化—GC日志分析
		
		GC日志能够反映出java应用执行内存回收详细情况，
		如Minor GC的频繁程度，Full GC的频繁程度，GC所导致应用停止响应的时间，引起GC的原因等等。
		根据程序吞吐量优先还是响应时间优先的不同，
		sun HotSpot虚拟机1.6版在服务器端提供ParallelScavenge/Parallel Old
		以及ParNew/CMS两种比较常用的垃圾收集器的组合，
		其中Parallel Scavenge和ParNew为新生代的垃圾收集器，
		而Parallel Old和CMS为老年代的垃圾收集器。
		
		Case1，下面这段GC日志：
			2012-02-19T05:00:46.461+0800: 139.170: [Full GC [PSYoungGen: 1907328K-
			>0K(1910144K)] [PSOldGen: 2665961K->1211211K(2899968K)] 4573289K- >1211211K(4810112K) [PSPermGen: 94244K->94244K(98560K)], 4.9259400 secs]
			[Times: user=5.19 sys=0.00, real=4.93 secs]
		导致GC的原因是由于YoungGen的空间难以满足新对象创建的需要，
		并且，由于Parallel Scavenge垃圾收集器的悲观策略，
		每次晋升到OldGen的平均大小如果大于当前OldGen的剩余空间，则触发一次FullGC。
		上述情况如果频繁发生，则可以通过-Xmx与-Xms参数调整整个堆的大小，
		以增加OldGen的大小，YoungGen对应的-Xmn保持不变。
		
		Case2，下面这段GC日志：
			2012-07-13T11:21:45.423+0800: 4070.053: [Full GC [PSYoungGen: 53055K-
			>0K(2488128K)] [ParOldGen: 350072K->279976K(2682880K)] 403128K-
			>279976K(5171008K) [PSPermGen: 262143K->132624K(262144K)], 1.8700750 secs]
			[Times: user=10.46 sys=0.00, real=1.87 secs]
		通过日志可以发现，导致FullGC的原因是由于PermGen空间被占满，
		PermGen通常用来存放已被虚拟机加载的类信息，
		以及常量、静态变量、即时编译器编译后的代码等数据。
		PermGen的空间由于内存回收条件十分苛刻，在应用启动后一般都比较稳定，
		并且通过GC回收的内存也十分有限。如果频繁因为PermGen的空间不够用而发生FullGC，
		一种情况可能是由于PermGen设置的确实过小，
		对于Groovy一类的动态语言来说，会频繁的进行类型的加载操作，
		这时需要调整-XX:PermSize和-XX:MaxPermSize两个参数的大小，就可以解决，
		另一种情况则可能是由于错误的代码导致的频繁类加载，
		需要使用jmap将堆dump下来进行分析，以定位具体的错误代码位置。
		
	服务端优化—数据库查询
		
		通过mysql的配置文件my.cnf，可以修改慢日志的相关配置：
			log_slow_queries = /var/log/mysql/mysql-slow.log
			long_query_time = 1
		其中，log_slow_queries用来指定慢日志的路径，
		而long_query_time用来指定慢于多少秒的SQL会被记录到日志当中。
		
	查询优化—合理使用索引
		
		索引是影响数据库性能的一个重要因素，一旦索引使用不当，将严重影响数据库的性能。
		mysql提供了explain命令，用来解释和分析SQL查询语句，
		通过explain命令，可以模拟查询优化器执行SQL语句，从而知道mysql是如何执行你的SQL语句的。
			explain select * from order_info where order_id = 1;
		
	查询优化—合理使用索引
		
		建了索引就一定能够使用到么，不见得，某些情况下，查询的列即使建了索引，也不一定能够用上。
		表user:  a，b，c三个字段建立组合索引
		可以使用索引：
			select * from user  where   a=1
			select * from user where   a=1 and b=2
			select * from user where a=1 and b=2 and c=3
		不能使用索引：
			select * from user where   a>1  and b<2
		
	查询优化—普通分页
		
		SELECT *
		FROM feed_0000
		WHERE num_id = 50842480985
		AND suspended = 0
		AND rate = 1
		ORDER BY id
		LIMIT 4, 4
		
	查询优化—优化分页
		
		SELECT *
		FROM ( SELECT id
		FROM feed_0000
		WHERE num_id = 3606022462
		AND suspended = 0
		AND rate = 1
		ORDER BY id
		LIMIT 4, 4 ) a, feed_0000 b
		WHERE B.id = A.id
		ORDER BY B.ID
		
	查询优化—普通分页查询路径
		
	查询优化—优化后分页查询路径
		
	查询优化—SQL编写总结
		
		尽量条件确定
		尽量使用等号
		访问尽量少的数据
		尽量避免聚合运算
		尽量避免表关联
		关联表的分页尽量在一张表中完成	
		
	服务端优化—反范式设计
		
		关系数据库理论所提出的范式设计，
		要求在表的设计过程中尽可能的减少数据冗余，这样会带来很大好处。
		但是，对于大多数复杂的业务场景来说，数据展现的维度不可能是单表的，
		因此，在进行查询操作时，需要进行表的关联，这不仅代价高昂，
		且由于查询条件指定的列可能并不在同一个表中，
		因此也无法使用到索引，这将导致数据库的性能严重下降。
		为了尽可能的避免关联查询带来的性能损耗，有人提出了反范式设计，
		即将一些常用的需要关联查询的列进行进行冗余存储，以便减少表关联带来的随机I/O和全表扫描。
		
	服务端优化—反范式设计
	
		范式：
			create table user(
			user_id int primary key auto_increment, user_nick varchar(100) ,
			sex int,
			age int,
			introduce varchar(400)
			);
			create table order_info(order_id int primary key auto_increment, user_id int ,
			price int,
			good_id int,
			good_title varchar(100),good_info varchar(500)
			)
		优化：
			create table order_info_ext(order_id int primary key auto_increment, user_id int ,
			user_nick varchar(100) ,
			sex int,
			age int,
			price int,
			good_id int,
			good_title varchar(100),good_info varchar(500)
			);	
		
		
	为什么要性能测试
		
		性能测试指的是通过一些自动化的测试工具模拟多种正常、峰值
		以及异常负载条件来对系统的各项性能指标进行测试，
		系统在上线运行之前，需要经过一系列的性能测试，
		以确定系统在各种负载下的性能指标的变化，发现系统潜在的一些瓶颈和问题，
		通过性能测试，能够得到应用性能的基准线，即系统能够承载的峰值访问，高位运行时系统的稳定性，
		以及系统响应时间等一系列关键指标，给系统的上线运维提供了重要的参考依据。
		
	性能测试工具—ab、jmeter、LoadRunner
		
		ab的全称为ApacheBench，
		是apache基金会提供的一款专门用来对HTTP服务器进行性能测试的小工具，
		可以模拟多个并发请求对服务器进行压力测试，
		得出服务器在高负载下能够支持的qps以及应用的响应时间，为系统设计者提供参考依据。
		jmeter是apache基金会提供的另一个开源性能测试工具，
		它的功能比ab更为强大，采用纯java实现，支持多种协议的性能基准测试，
		如HTTP、SOAP、FTP、TCP、SMTP、POP3等等，
		可以用于模拟在服务器、网络或者其他对象上施加高负载，以测试他们的压力承受能力，
		或者分析他们在不同负载的情况下的性能表现，能够灵活的进行插件化的扩展，
		支持通过脚本方式的回归测试，并且提供各项指标的图形化展示。
		Load Runner是惠普(HP)公司研发的一款功能极为强大的商业付费性能测试工具，
		它通过模拟大量实际用户的操作行为及实时性能检测的方式，帮助更加快速的查找和确认问题，
		此外，LoadRunner能够支持最为广泛的协议标准，适应各种体系架构，
		几乎是应用性能测试领域的行业标准。
		
	性能测试工具—TCPCopy
		
		 TCPCopy是网易技术部于2011年9月所开源的一个项目，
		 它是一款请求复制工具，能够将在线请求复制到测试机器，模拟真实环境，
		 达到程序在不上线的情况下承担线上真实流量的效果，目前已广泛用于国内各大互联网公司。
		
	性能测试工具----适合分布式环境的性能测试工具
		
		1.能够通过分布式集群模拟大规模的流量
		2.通过JVM的接口、操作系统的接口，
			能够实时观测和记录被压测机器状态，包括GC、load、网络流量、qps、rt时间，热点方法等
		3.自动化的机器准备、环境搭建、账号生成等等，并且测试用例可以回放
		4.测试环境能够模拟的场景有限，
			因此，工具需要能够支持线上日志回放，线上真实环境引流压测，全链路压测的功能
		
	性能测试工具—性能环境与真实环境的差异
		
		
Java 程序的性能优化
		
		
	Btrace监控方法执行时间
		
		@Override
		protected void doPost(HttpServletRequest req, HttpServletResponse resp)
		throws ServletException, IOException {
		PrintWriter out = resp.getWriter();
		try {
		Thread.sleep(500L);
		} catch (InterruptedException e) {}
		out.write("success");
		}
		
	Java程序的性能优化
		
	服务端优化—使用单例
		
		对于IO处理、数据库连接、配置文件解析加载等一些非常耗费系统资源的操作，
		我们必须对这些实例的创建进行限制，或者是始终使用一个公用的实例，以节约系统开销，
		这种情况下就需要用到单例模式。
		单例模式的实现：
			public class Singleton {
			private static Singleton instance;
			static {
			instance = new Singleton();
			}
			private Singleton(){
			//消耗资源的操作
			}
			public static Singleton getInstance() {
			return instance;
			}
			}
		
	服务端优化—使用Future模式
		
		假设一个任务执行起来需要花费一些时间，为了省去不必要的等待时间，
		可以先获取一个“提货单”，即Future，然后继续处理别的任务，直到“货物”到达，
		即任务执行完得到结果，此时便可以用“提货单”进行提货，即通过Future对象得到返回值。
			public class TestFuture {
			static class Job<Object> implements Callable<Object>{
			@Override
			public Object call() throws Exception {
			return loadData();
			}
			}
			public static void main(String[] args) throws Exception{
			FutureTask future = new FutureTask(new Job<Object>());
			new Thread(future).start();
			//do something else
			Object result = (Object)future.get();
			}
			}
		
	服务端优化—使用线程池
		
		public class TestExecutorService {
		static class Job implements Runnable{
		@Override
		public void run() {
		doWork();// 具体工作
		}
		private void doWork(){
		System.out.println("doing...");
		}
		}
		public static void main(String[] args) {
		ExecutorService exec = Executors.newFixedThreadPool(5);
		for(int i = 0; i < 10; i ++)
		exec.execute(new Job());
		}
		}
		
	服务端优化—选择就绪
		
		 JDK自1.4起开始提供全新的I/O编程类库，简称NIO，
		 其不但引入了全新高效的Buffer和Channel，
		 同时，还引入了基于Selector的非阻塞I/O机制，
		 将多个异步的I/O操作集中到一个或几个线程当中进行处理，
		 使用NIO代替阻塞I/O能提高程序的并发吞吐能力，降低系统的开销。
		对于每一个请求，如果单独开一个线程进行相应的逻辑处理，
		当客户端的数据传递并不是一直进行，而是断断续续的，
		则相应的线程需要I/O等待，并进行上下文切换。
		而使用NIO引入的Selector机制后，可以提升程序的并发效率，改善这一状况。
		
	服务端优化—减少上下文切换
		
		进行线程上下文切换会有一定的调度开销，这个过程中操作系统和JVM会消耗一定的CPU周期，
		并且，由于CPU处理器会缓存线程的一部分数据，
		当新线程被切换进来时，它所需要的数据可能不在CPU缓存中，
		因此，还会导致CPU缓存的命中率下降。
		程序在进行锁等待或者被阻塞时，当前线程会挂起，
		因此，如果锁的竞争激烈，或者线程频繁I/O阻塞，
		就可能会导致上下文切换过于频繁，从而增加调度开销，并且降低程序的吞吐量。
		
	服务端优化—减少锁粒度
		
		static class RunningCount{
		private Integer runningCount = 0;
		public synchronized void run(Job job){
		runningCount ++;
		doSomething(job);
		runningCount --;
		}
		private void doSomething(Job job){
		……
		}
		}
				
		static class RunningCount{
		private Integer runningCount = 0;
		public void run(Job job){
		synchronized(runningCount){
		runningCount ++;
		}
		doSomething(job);
		synchronized(runningCount){
		runningCount --;
		}
		}
		private void doSomething(Job job){
		}
		}	
		
	服务端优化—数据压缩
		
		在进行数据传输之前，可以先将数据进行压缩，
		以减少网络传输的字节数，提升数据传输的速度，
		接收端可以将数据进行解压，以还原出传递的数据，
		并且，经过压缩的数据还可以节约所耗费的存储介质(磁盘或内存)的空间以及网络带宽，降低成本。
		当然，压缩也并不是没有开销的，数据压缩需要大量的CPU计算，
		并且，根据压缩算法的不同，计算的复杂度以及数据的压缩比也存在较大差异。
		一般情况下，需要根据不同的业务场景，选择不同的压缩算法。
		
	服务端优化—结果缓存
		
		对于相同的用户请求，如果每次都重复的查询数据库，重复的进行计算，将浪费很多的时间和资源。
		将计算后的结果缓存到本地内存，或者是通过分布式缓存来进行结果的缓存，
		可以节约宝贵的CPU计算资源，减少重复的数据库查询或者是磁盘I/O
		，将原本磁头的物理转动变成内存的电子运动，提高响应速度，
		并且线程的迅速释放也使得应用的吞吐能力得到提升。
		
		
Java 程序的故障排查
		
		
	Java故障排查工具—jvm自带工具
		
		 JDK自身提供了一系列的java故障排查工具，虽然简单，但是进行在线故障排查的时候确十分有用，
		 因为，生产环境的机器出于性能和安全方面的考虑，往往不能够使用图形化工具进行远程连接，
		 这时，就只能够依赖JDK命令行自带的工具了。
			jps
			jstate
			jinfo
			jstack
			jmap
		
	Java故障排查工具—jstack
		
	Java故障排查工具—jmap
		
	Java故障排查工具—BTrace
	
		BTrace的用法：
			btrace [-I <include-path>] [-p <port>] [-cp <classpath>] <pid> <btrace-script> [<args>]
			-I BTrace支持对#define、#include这样的条件编译指令进行简单的处理，
				include-path用来指定这样的头文件目录
			-p  port参数用来指定btrace agent端口，默认是2020
			-cp classpath用来指定编译所需类路径，一般是指btrace-client.jar等类所在路径
			pid 表示需要跟踪的java进程id
			btrace-script 为自定义的 btrace脚本
			args 为传递给btrace脚本的参数
		
	Java故障排查工具—MAT内存分析
		
	Java故障排查工具—VisualVM
		
	典型案例分析—内存溢出
		
		public class TestOOM {
		static class Obj{
		public byte[] bytes = "hello everyone".getBytes();
		}
		public static void main(String[] args) {
		ArrayList<Obj> list = new ArrayList<Obj>();
		while(true){
		list.add(new Obj());
		}
		}
		}
		-Xms10m -Xmx10m -Xmn5m -XX:+HeapDumpOnOutOfMemoryError
		
	典型案例分析—线程死锁
		
		protected void doPost(HttpServletRequest request, HttpServletResponse response)
		throws ServletException, IOException {
		try {
		SemaphoreSingleton.getSemaphore().acquire();
		} catch (InterruptedException e) {}
		response.setHeader("Server-Status", "ok");
		response.getWriter().write("hello\n");
		return ;
		}
		
	典型案例分析—类加载冲突
		
		假设存在test1.jar和test2.jar两个jar包，
		它们都包含了同一个类com.http.test.SaySomething，
		其中一个类的saySomething方法的实现为：
			public static void saySomething(){
			System.out.println("bye");
			}
		另一个类saySomething方法的实现为：
			public static void saySomething(){
			System.out.println("hello");
			}
		假如一个工程同时依赖了test1.jar和test2.jar，并调用了saySometing方法，如下所示：
			public static void main(String[] args) {
			SaySomething.saySomething();
			}	
		
		
大型网站的数据收集与数据分析
		
		
	日志收集—为何不使用轮询
		
		 对于日志的收集，最常用的方式便是文件轮询，
		 也就是通过设置一定的时间间隔，不断的读日志文件，直到文件尾，
		 然后再等待下一次轮询，这种方式很容易理解，实现起来也十分简单。
		 但是，对于一些写入并不十分频繁的文件，如错误日志等等，
		 轮询的效率显得十分低下，白白浪费了CPU时间片。
		
	日志收集—inotify的魅力
		
		 linux内核从2.6.13开始，引入了inotify机制。
		 通过inotify机制，能够对文件系统的变化进行监控，如对文件进行删除、修改等等操作，
		 可以及时通知应用程序进行相关事件的处理，
		 这种响应性的处理机制，避免了频繁的文件轮询任务，提高了任务的处理效率。
		
	日志收集—转发与存储
		
	Apache的日志解决方案
		
		 Chukwa是Yahoo！贡献给apache的基于hadoop开发的数据采集与分析的框架，
		 用来支持大型分布式系统的海量日志的收集与分析工作，
		 它具有良好的适应性和可扩展性，天生支持与MapReduce协同进行数据处理，
		 能提供完整数据收集与分析的解决方案。
		
	离线数据同步
	
		数据分析的过程往往是这样，首先从在线的OLTP库中，以及日志系统当中，
		提取和清洗所需要的数据到OLAP系统当中，如构建在hadoop上的Hive，
		然后在OLAP系统上进行多维度复杂的数据分析和汇总操作，利用这些数据构建数据报表，提供前端展现。
		对于全量的数据同步操作，一般耗时较长，并且会占用一定的资源，
		比如对于数据库来说很宝贵的连接资源，
		因此一般通过任务调度，将数据同步任务安排在访问量最低的时候执行，
		由于数据同步需要较长时间，常常一天只能够同步一到两次。
		对应的这部分数据，由于无法反映在线应用的实时状态，因此也称为离线数据。
		
		Sqoop是apache下的一个开源数据同步工具，
		支持关系型数据到hadoop的数据导入和导出功能，
		既能够通过Sqoop将关系型数据库(如Mysql、Oracle)中的数据导入到HDFS，
		也能够通过Sqoop从HDFS中将数据同步回关系型数据库。
		Sqoop使用MapReduce来执行数据导入和导出任务，提升了操作的并行效率以及容错能力。
		
	实时数据同步
		
		有的场景下，我们需要实时获取数据变更，同步到相应的数据库，
		如垂直搜索引擎的实时更新、高并发系统的数据迁移工作、实时统计等等。
		Sqoop在离线场景下能较好的满足要求，
		但是对于在线高并发读写的实时数据的处理，则需要思考其他的解决方案。
		
	离线数据分析
		
		作为全球搜索行业的领头羊，google需要对互联网上所有的网页建立搜索索引，
		因此在大数据处理方面积累极为丰富经验，随着技术的成熟，
		它相继发布的几篇介绍GFS、BigTable、MapReduce等产品的论文，
		对业界产生了极为深远的影响，推动了整个互联网时代的变革。
		然而，毕竟google是一个商业公司，作为google解决方案的开源替代，
		Hadoop是时下最流行大数据离线解决方案。
		hadoop目前的应用主要集中在大数据的离线批处理分析领域，
		提供对海量的数据高可靠性、高容错性、高可扩展性的存储解决方案，
		以及对海量数据进行分析的编程模型等等。
		
	离线数据分析—hadoop简介
		
		hadoop是一个提供可伸缩的、可信赖的分布式计算的开源项目，包含多个子项目。
		hadoop项目的核心便是分布式文件系统和编程模型MapReduce，
		HDFS用来对海量的数据提供高可靠性、高容错性、高可扩展性的存储解决方案，
		而MapReduce则是一种用来处理海量数据的并行编程模型和计算框架，
		用于对大规模的数据集进行并行计算。

		随着时间的推移和项目的发展，hadoop的功能也越来越强大，
		发展出一系列支撑分布式计算的关联项目，
		如前面提到的高性能分布式协作服务zookeeper，
		可伸缩的支持大表结构化存储的分布式数据库Hbase，
		提供类SQL查询功能的数据仓库平台Hive，
		大规模分布式系统的数据收集系统Chukwa，
		海量数据并行计算的编程语言和执行框架Pig，
		可扩展的机器学习和数据挖掘库Mahout等等。
		
	离线数据分析—HDFS
		
	离线数据分析—MapReduce
		
	流式数据分析
		
		互联网企业常常需要面对这样的需求，
		管理员需要了解服务器的负载、网络traffic、磁盘IO等等状态信息，
		决策人员需要实时地获知站点交易下单笔数、交易总金额、PV、UV等业务数据。
		这些都是源源不断产生的流式数据，并且需要给用户实时响应计算结果，
		对于这种场景来说，尽管MapReduce可以作一些实时性方面的改进，但仍很难稳定地满足需求。
		
		流式数据的特征是数据会源源不断的从各个地方汇集过来，来源众多，格式复杂，数据量巨大，
		对于流式数据的处理，有这样的一种观点，即数据的价值将随着时间的流逝而降低，
		因此数据生成后最好能够尽快的进行处理，实时的响应计算结果，
		而非等到数据累积以后再定期地进行处理，
		这样，对应的数据处理工具必须具备高性能，实时性，分布式和易用性几个特征。
		
	流式数据分析—storm简介
		
		storm是一个开源的分布式实时计算系统，可以简单的、可靠的对大量的流式数据进行分析处理。
		它有点类似于hadoop的MapReduce思想，
		不同的是，MapReduce执行的是批处理任务，
		而storm所提出的Topology原语，执行的是实时处理任务。
		批处理任务最终会结束，而Topology任务却会永远地运行，直到用户手动kill掉。
		storm在众多领域得到了广泛的使用，如实时分析、在线机器学习、持续计算、分布式RPC、ETL等等，
		它可以方便的进行系统扩容，具有很高的容错性，
		能够保障每个消息都会得到处理，并且有很高的处理效率。
		
	流式数据分析—storm集群架构
		
	流式数据分析—topology数据流向
		
	数据报表
		
		
作业
	
	1.实现一种简单的通信协议

	2.使用spring mvc 完成RESTful风格的远程调用

	3.使用google的protocol buffers来完成对象的序列化


	1.搭建zookeeper环境，使用java生成节点、删除节点

	2.使用zookeeper实现服务路由和负载均衡

	3.实现轮询、随机、加权轮询、源地址hash、加权随机几种负载均衡算法


	1.服务端将cookie设置为httponly，并在浏览器访问，结果截图

	2.使用md5算法生成摘要

	3.使用aes算法加密数据，并且用同样的方式解密

	4.使用rsa算法生成公钥和私钥，用私钥加密数据，并且用公钥解密


	1.实现签名认证的客户端签名生成和校验、服务端签名生成和校验，并附上结果

	2.keystore生成证书，openssl生成证书，结果截图

	3.通过tomcat部署双向校验https web，并将结果截图


	1.使用memcache完成增删改，并附上结果

	2.使用memcache简单实现分布式session，并附程序运行结果

	3.部署mysql主从同步，附配置文件及结果

	4.mysql分表查询，并附结果


	1.部署hbase环境，完成hbase的增删改查操作(编程实现)，并附上运行结果

	2.使用redis完成增删改查功能(编程实现)，并附上运行结果

	3.使用activemq，完成消息的接收与发送(编程实现)，并附上运行结果


	1.分别使用一元分词、二元分词、词库分词构建索引，检索结果高亮展示，并提交运行结果

	2.通过数据库建立两张关联表，通过lucene对数据库构建检索，并提交运行结果


	1.通过shell命令，查看access日志中，访问baidu.com/index的ip，并且，根据访问次数排序

	2.打印accesslog中的第5列(假定为数字)，并且去重排序，降序，取前10

	3.编写一个脚本，取出access 日志中访问了google的ip
	
		编写另外一个脚本，取出access日志中访问了baidu的ip
		
		编写第三个脚本，比较上述两个脚本的输出，将相同的ip地址取前10输出
		
		第三题虽然有更简便的方法，但是必须按照题目所述的逻辑执行


	1.实现一个网页，并限制并发

	2.实现一个网页，并限制QPS

	3.描述一个分布式网站机器评估的案例，包括流量分配图(如第七页ppt所示)，并估算机器数量，不得与ppt中案例雷同，为了使案例评估不流于形式，因此规定描述不得少于 200字


	1.分别使用原子变量、synchronized关键字、ReentrantLock实现count统计

	2.模拟实现一个秒杀减库存的案例


	1.搭建ab和jmeter测试环境，定义性能测试流程，对web进行性能测试，并上传性能测试结果截图

	2.配置mysql的慢sql日志输出，并将结果截图

	3.配置eclipse或者其他java开发工具的gc日志输出，并对jvm的内存参数进行调整，说明调整的原因


	1.将应用服务器堆内存dump，并通过mat分析，找出占用内存最多的class，并截图

	2.使用btrace分析容器内运行最慢的方法，输出截图

	3.使用一种压缩算法压缩一个文本文件，并将文件解压还原，输出截图

	4.配置nginx开启gzip压缩，并提交配置


	1.搭建hadoop环境，并运行hadoop的wordcount程序，将结果截图

	2.搭建storm环境，编写一个程序模拟循环写入日志，一个agent循环读取，并使用storm接收统计日志行数，页面输出，并截图

	3.利用inotify机制，监控文件的修改，并读取修改的行，结果截图



	