	
Python 笔记
	
	
Python 教程笔记

一、基础：
	
	Python 解释器：
		CPython 是使用最广的 Python 解释器。
			从 Python 官方网站下载并安装好 Python 3.x 后，就直接获得了一个官方版本的解释器：CPython。
			这个解释器是用 C 语言开发的，所以叫 CPython。在命令行下运行 python 就是启动 CPython 解释器。
		
	输入和输出
		输出：
			print()在括号中加上字符串，就可以向屏幕上输出指定的文字。
			print()函数也可以接受多个字符串，用逗号“,”隔开，就可以连成一串输出。
			print()会依次打印每个字符串，遇到逗号“,”会输出一个空格，输出的字符串是这样拼起来的。
		输入：
			input()，可以让用户输入字符串，并存放到一个变量里。
			input()可以让你显示一个字符串来提示用户。
		输入输出统称为 Input/Output，或者简写为 IO。
		
	数据类型和变量：
		数据类型：
			Number；String；List；Tuple；Dictionary；Set。
		Number 包括：
			int、float、bool、complex (复数)。
		整数 (int)；
			(Python 的整数没有大小限制)
		浮点数 (float)；
			因为按照科学记数法表示时，一个浮点数的小数点位置是可变的。
			(Python 的浮点数也没有大小限制，但是超出一定范围就直接表示为 inf 无限大)
		布尔值 (bool)；
			布尔值和布尔代数的表示完全一致，一个布尔值只有 True、False 两种值。
			Python 中，可以直接用 True、False 表示布尔值（请注意大小写），也可以通过布尔运算计算出来。
			布尔值可以用 and、or 和 not 运算。
				and 运算：与运算，只有所有都为 True，and 运算结果才是 True；
				or 运算：或运算，只要其中有一个为 True，or 运算结果就是 True；
				not 运算：非运算，它是一个单目运算符，把 True 变成 False，False 变成 True；
		空值 (None)；
			None 不能理解为0，因为0是有意义的，而 None 是一个特殊的空值。
			
		字符串 (str)；
			以单引号'或双引号"括起来的任意文本；
				''或""本身只是一种表示方式，不是字符串的一部分，因此字符串'abc'只有 a，b，c 这3个字符。
					如果'本身也是一个字符，那就可以用""括起来
			如果字符串内部既包含'又包含"怎么办？可以用转义字符\来标识。
				转义字符\可以转义很多字符，
					比如\n 表示换行，\t 表示制表符，字符\本身也要转义，所以\\表示的字符就是\
				用 r''表示''内部的字符串默认不转义。
			用'''...'''的格式表示多行内容。
		
		变量：
			Python 中，变量不仅可以是数字，还可以是任意数据类型。
			等号=是赋值语句，可以把任意数据类型赋值给变量，同一个变量可以反复赋值，
				而且可以是不同类型的变量。
			变量本身类型不固定的语言称之为动态语言，与之对应的是静态语言。
			静态语言在定义变量时必须指定变量类型，如果赋值的时候类型不匹配，就会报错。
				例如 Java 是静态语言。
				和静态语言相比，动态语言更灵活。
		常量：
			所谓常量就是不能变的变量，比如常用的数学常数π就是一个常量。
			在 Python 中，通常用全部大写的变量名表示常量。
			整数的除法为什么也是精确的。
				在 Python 中，有两种除法，一种除法是/；
					/除法计算结果是浮点数，即使是两个整数恰好整除，结果也是浮点数。
				还有一种除法是//，称为地板除，两个整数的除法仍然是整数；
					整数的地板除//永远是整数，即使除不尽。要做精确的除法，使用/就可以。
					因为//除法只取结果的整数部分。
				Python 还提供一个余数运算，可以得到两个整数相除的余数：%；
					无论整数做//除法还是取余数，结果永远是整数，所以，整数运算结果永远是精确的。
		小结：
			Python 支持多种数据类型，在计算机内部，可以把任何数据都看成一个“对象”，
				而变量就是在程序中用来指向这些数据对象的，对变量赋值就是把数据和变量给关联起来。
			对变量赋值 x = y 是把变量 x 指向真正的对象，该对象是变量 y 所指向的。
				随后对变量 y 的赋值不影响变量 x 的指向。
			注意：Python 的整数没有大小限制，而某些语言的整数根据其存储长度是有大小限制的，
				例如 Java 对32位整数的范围限制在-2147483648-2147483647。
			Python 的浮点数也没有大小限制，但是超出一定范围就直接表示为 inf（无限大）。
	
	数据类型：
		list：列表；
			list 是一种有序的集合，可以随时添加和删除其中的元素。
				支持倒数索引，如：list[-1]
			list 是一个可变的有序表，
				append()：可以往 list 中追加元素到末尾，用 append() 方法。
				insert()：也可以把元素插入到指定的位置，用 insert() 方法；
				pop()：删除 list 末尾的元素，用 pop() 方法；
				pop(i)：删除指定位置的元素，用 pop(i) 方法，其中 i 是索引位置；
				把某个元素替换成别的元素，可以直接赋值给对应的索引位置；
				list 里面的元素的数据类型也可以不同；
				list 元素也可以是另一个 list；
					二维数组，类似的还有三维、四维……数组，不过很少用到。
				如果一个 list 中一个元素也没有，就是一个空的 list，它的长度为 0 。
				
		tuple：元组；
			一种有序列表；和 list 非常类似；
			一旦初始化就不能修改；因为 tuple 不可变，所以代码更安全。
			没有 append()，insert()这样的方法。
			tuple 的陷阱：当你定义一个 tuple 时，在定义的时候，tuple 的元素就必须被确定下来。
			如果要定义一个空的 tuple，可以写成()。
				因为括号()既可以表示 tuple，又可以表示数学公式中的小括号，这就产生了歧义，
				因此，Python 规定，这种情况下，按小括号进行计算，计算结果自然是1。
			只有1个元素的 tuple 定义时必须加一个逗号,，来消除歧义。
				Python 在显示只有1个元素的 tuple 时，也会加一个逗号,，以免你误解成数学计算意义上的括号。
			tuple 所谓的“不变”是说，tuple 的每个元素，指向永远不变。
				理解了“指向不变”后，要创建一个内容也不变的 tuple 怎么做？
					那就必须保证 tuple 的每一个元素本身也不能变。
				
		dict：字典；
			dictionary，在其他语言中也称为 map，使用键-值（key-value）存储。
				把数据放入 dict，除了初始化时指定外，还可以通过 key 放入：
					d['Adam'] = 67
				由于一个 key 只能对应一个 value，所以，多次对一个 key 放入 value，后面的值会把前面的值冲掉；
				如果 key 不存在，dict 就会报错；
					要避免 key 不存在的错误，有两种办法：
						一是通过 in 判断 key 是否存在：
						二是通过 dict 提供的 get()方法，如果 key 不存在，可以返回 None，或者自己指定的 value：
				要删除一个 key，用 pop(key)方法，对应的 value 也会从 dict 中删除：
				Python 中，字符串、整数等都是不可变的，因此，可以放心地作为 key。
				list 是可变的，就不能作为 key：
				dict 有以下几个特点：
					查找和插入的速度极快，不会随着 key 的增加而变慢；
					需要占用大量的内存，内存浪费多。
				而 list 相反：
					查找和插入的时间随着元素的增加而增加；
					占用空间小，浪费内存很少。
				update()：
					dict.update(dict2)
					把字典 dict2的键/值对更新到 dict 里。
					该方法没有任何返回值。
		
		set：集合；
			set 和 dict 类似，也是一组 key 的集合，但不存储 value。
			要创建一个 set，需要提供一个 list 作为输入集合。
				传入的参数[1, 2, 3]是一个 list，
				而显示的{1, 2, 3}只是告诉你这个 set 内部有1，2，3这3个元素，
				显示的顺序也不表示 set 是有序的。
			由于 key 不能重复，所以，在 set 中，没有重复的 key。
				add(key)方法可以添加元素到 set 中；
				remove(key)方法可以删除元素；
			set 可以看成数学意义上的无序和无重复元素的集合；
				两个 set 可以做数学意义上的交集、并集等操作。
			set 的原理和 dict 一样，所以，同样不可以放入可变对象，
				因为无法判断两个可变对象是否相等，也就无法保证 set 内部“不会有重复元素”。
		
		不可变对象：
			变量和字符串：
				比如：
					a 是变量，'abc'是字符串对象；
						有些时候，我们经常说，对象 a 的内容是'abc'，
						但其实是指，a 本身是一个变量，它指向的对象的内容才是'abc'
					当我们调用 a.replace('a', 'A')时，实际上调用方法 replace 是作用在字符串对象'abc'上的，
						而这个方法虽然名字叫 replace，但却没有改变字符串'abc'的内容。
					相反，replace 方法创建了一个新字符串'Abc'并返回，
						如果我们用变量 b 指向该新字符串，就容易理解了，变量 a 仍指向原有的字符串'abc'，
						但变量 b 却指向新字符串'Abc'了
			对于不变对象来说，调用对象自身的任意方法，也不会改变该对象自身的内容。
			相反，这些方法会创建新的对象并返回，这样，就保证了不可变对象本身永远是不可变的。
			不可变对象包括：
				str、tuple、None。
				Number、String、Tuple。
				Number 包括：int、float、bool、complex。	
			可变对象包括：
				List、Dictionary、Set。
	
	字符串和编码：
		字符编码：
			计算机只能处理数字，如果要处理文本，就必须先把文本转换为数字才能处理。
			最早的计算机在设计时采用8个比特（bit）作为一个字节（byte），
				所以，一个字节能表示的最大的整数就是255（二进制11111111=十进制255），
			如果要表示更大的整数，就必须用更多的字节。
				比如两个字节可以表示的最大整数是65535，4个字节可以表示的最大整数是4294967295。
			Unicode 标准也在不断发展，但最常用的是用两个字节表示一个字符：
				ASCII 编码是1个字节，而 Unicode 编码通常是2个字节；
				（如果要用到非常偏僻的字符，就需要4个字节）。
			对于单个字符的编码，Python 提供了 ord()函数获取字符的整数表示，
				chr()函数把编码转换为对应的字符
			如果要在网络上传输，或者保存到磁盘上，就需要把 str 变为以字节为单位的 bytes。
				Python 对 bytes 类型的数据用带 b 前缀的单引号或双引号表示。
		Python 的字符串：
			Python 3 中，字符串是以 Unicode 编码的，也就是说，Python 的字符串支持多语言。
				以 Unicode 表示的 str 通过 encode()方法可以编码为指定的 bytes；
				把 bytes 变为 str，就需要用 decode()方法。
			源代码中包含中文的时候，在保存源代码时，就需要务必指定保存为 UTF-8编码。
				当 Python 解释器读取源代码时，为了让它按 UTF-8编码读取，我们通常在文件开头写上这两行：
					#!/usr/bin/env python3
					# -*- coding: utf-8 -*-
		格式化：
			输出格式化的字符串；
			Python 中，采用的格式化方式和 C 语言是一致的，用%实现：
				%运算符就是用来格式化字符串的。
				在字符串内部，%s 表示用字符串替换，%d 表示用整数替换，
				有几个%? 占位符，后面就跟几个变量或者值，顺序要对应好。
				如果只有一个%?，括号可以省略。
					占位符		替换内容
					%d			整数
					%f			浮点数
					%s			字符串
					%x			十六进制整数
				格式化整数和浮点数还可以指定是否补0和整数与小数的位数。
					如果你不太确定应该用什么，%s 永远起作用，它会把任何数据类型转换为字符串；
					有些时候，字符串里面的%是一个普通字符怎么办？这个时候就需要转义，用%%来表示一个%。
						>>> 'Hello, %s' % 'world'
						'Hello, world'
						>>> 'Hi, %s, you have $%d.' % ('Michael', 1000000)
						'Hi, Michael, you have $1000000.'
			format()：
				另一种格式化字符串的方法是使用字符串的 format()方法，
				它会用传入的参数依次替换字符串内的占位符{0}、{1}……，
				不过这种方式写起来比%要麻烦得多。
		小结：
			当 str 和 bytes 互相转换时，需要指定编码。最常用的编码是 UTF-8。
			
	条件判断：
		格式：
			if <条件判断1>:
				<执行1>
			elif <条件判断2>:
				<执行2>
			else:
				<执行3>
		if 判断条件还可以简写，
			只要 x 是非零数值、非空字符串、非空 list 等，就判断为 True，
			否则为 False。
			比如：
				if x:
					print('True')
		input()返回的数据类型是 str，str 不能直接和整数比较，必须先把 str 转换成整数。
		
	循环：
		Python 的循环有两种，一种是 for...in 循环，依次把 list 或 tuple 中的每个元素迭代出来
			for ... in ... 循环：
				sum = 0
				for x in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:
					sum = sum + x
				print(sum)
		第二种循环是 while 循环，只要条件满足，就不断循环，条件不满足时退出循环。
			while 循环：
				sum = 0
				n = 99
				while n > 0:
					sum = sum + n
					n = n - 2
				print(sum)
		break：
			提前退出循环，循环结束。
		continue：
			跳过当前的这次循环，开始下一次循环。
		小结：
			break 语句可以在循环过程中直接退出循环，
			而 continue 语句可以提前结束本轮循环，并直接开始下一轮循环。
			这两个语句通常都必须配合 if 语句使用。
			break 和 continue 会造成代码执行逻辑分叉过多，容易出错。
			大多数循环并不需要用到 break 和 continue 语句。
			
二、函数：
	调用函数：
		声明函数名称，传入参数；
		函数名其实就是指向一个函数对象的引用，完全可以把函数名赋给一个变量，
			相当于给这个函数起了一个“别名”。
		调用 Python 的函数，需要根据函数定义，传入正确的参数。
	
	定义函数：
		Python 中，定义一个函数要使用 def 语句，依次写出函数名、括号、括号中的参数和冒号:，
			然后，在缩进块中编写函数体，函数的返回值用 return 语句返回。
		函数体内部的语句在执行时，一旦执行到 return 时，函数就执行完毕，并将结果返回。
			因此，函数内部通过条件判断和循环可以实现非常复杂的逻辑。
		如果没有 return 语句，函数执行完毕后也会返回结果，只是结果为 None。
			return None 可以简写为 return。
		在 Python 交互环境中定义函数时，注意 Python 会出现...的提示。
			函数定义结束后需要按两次回车重新回到>>>提示符下
		
		空函数：
			如果想定义一个什么事也不做的空函数，可以用 pass 语句：
			def nop():
				pass
			pass 可以用来作为占位符，
				比如现在还没想好怎么写函数的代码，就可以先放一个 pass，让代码能运行起来。
			
		参数检查：
			调用函数时，如果参数个数不对，Python 解释器会自动检查出来；
			但是如果参数类型不对，Python 解释器就无法帮我们检查。
			
		返回多个值：
			Python 函数返回的是单一值：
				返回值是一个 tuple；
			语法上，返回一个 tuple 可以省略括号，多个变量可以同时接收一个 tuple，按位置赋给对应的值，
			所以，Python 的函数返回多值其实就是返回一个 tuple，但写起来更方便。
		小结：
			定义函数时，需要确定函数名和参数个数；
			如果有必要，可以先对参数的数据类型做检查；
			函数体内部可以用 return 随时返回函数结果；
			函数执行完毕也没有 return 语句时，自动 return None。
			函数可以同时返回多个值，但其实就是一个 tuple。
			
	函数的参数：
		除了正常定义的必选参数外，还可以使用默认参数、可变参数和关键字参数，
			使得函数定义出来的接口，
			不但能处理复杂的参数，还可以简化调用者的代码。
		
		位置参数：
			positional argument；
			定义函数时的占位形参。
			调用函数时，传入的两个值按照位置顺序依次赋给位置参数。
		
		默认参数：
			例如：def power(x, n=2):
			设置默认参数时，有几点要注意：
				一是必选参数在前，默认参数在后，否则 Python 的解释器会报错；
				二是如何设置默认参数。
			当函数有多个参数时，把变化大的参数放前面，变化小的参数放后面。
				变化小的参数就可以作为默认参数。
			默认参数好处：最大的好处是能降低调用函数的难度。
				有多个默认参数时，调用的时候，按顺序提供默认参数。
				当不按顺序提供部分默认参数时，需要把参数名写上。
					比如调用 enroll('Adam', 'M', city='Tianjin')，
						意思是，city 参数用传进去的值，其他默认参数继续使用默认值。
			定义默认参数要牢记一点：默认参数必须指向不变对象。
		
		可变参数：
			传入的参数个数是可变的。
			把函数的参数改为可变参数：
				def calc(*numbers):
			定义可变参数和定义一个 list 或 tuple 参数相比，仅仅在参数前面加了一个*号。
				在函数内部，参数 numbers 接收到的是一个 tuple，因此，函数代码完全不变。
				但是，调用该函数时，可以传入任意个参数，包括0个参数。
			Python 允许你在 list 或 tuple 前面加一个*号，把 list 或 tuple 的元素变成可变参数传进去。
				*nums 表示把 nums 这个 list 的所有元素作为可变参数传进去。这种写法相当有用，而且很常见。
			可变参数允许你传入0个或任意个参数，这些可变参数在函数调用时自动组装为一个 tuple。
		
		关键字参数：
			关键字参数允许你传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个 dict。
			关键字参数作用：可以扩展函数的功能。
				比如，在 person 函数里，我们保证能接收到 name 和 age 这两个参数，
					但是，如果调用者愿意提供更多的参数，我们也能收到。
			**extra 表示把 extra 这个 dict 的所有 key-value 用关键字参数传入到函数的**kw 参数，
				kw 将获得一个 dict，
				注意：kw 获得的 dict 是 extra 的一份拷贝，对 kw 的改动不会影响到函数外的 extra。
		
		命名关键字参数：
			如果要限制关键字参数的名字，就可以用命名关键字参数。
				例如，只接收 city 和 job 作为关键字参数。这种方式定义的函数如下：
					def person(name, age, *, city, job):
				和关键字参数**kw 不同，命名关键字参数需要一个特殊分隔符*，
					*后面的参数被视为命名关键字参数。
				如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要特殊分隔符*了：
					def person(name, age, *args, city, job):
				命名关键字参数必须传入参数名，这和位置参数不同。
					如果没有传入参数名，调用将报错。
				命名关键字参数可以有缺省值，从而简化调用：
					def person(name, age, *, city='Beijing', job):
			使用命名关键字参数时注意：
				如果没有可变参数，就必须加一个*作为特殊分隔符。
				如果缺少*，Python 解释器将无法识别位置参数和命名关键字参数：
				
		参数组合：
			在 Python 中定义函数，可以用
				必选参数、默认参数、可变参数、关键字参数和命名关键字参数，这5种参数都可以组合使用。
			但是请注意，参数定义的顺序必须是：
				必选参数、默认参数、可变参数、命名关键字参数和关键字参数。
			对于任意函数，都可以通过类似 func(*args, **kw)的形式调用它，无论它的参数是如何定义的。
			虽然可以组合多达5种参数，但不要同时使用太多的组合，否则函数接口的可理解性很差。
			
		小结：
			Python 的函数具有非常灵活的参数形态，既可以实现简单的调用，又可以传入非常复杂的参数。
			默认参数一定要用不可变对象，如果是可变对象，程序运行时可能会有逻辑错误。
			要注意定义可变参数和关键字参数的语法：
				*args 是可变参数，args 接收的是一个 tuple；
				**kw 是关键字参数，kw 接收的是一个 dict。
			以及调用函数时如何传入可变参数和关键字参数的语法：
				可变参数既可以直接传入：func(1, 2, 3)，
					又可以先组装 list 或 tuple，
					再通过*args 传入：func(*(1, 2, 3))；
				关键字参数既可以直接传入：func(a=1, b=2)，
					又可以先组装 dict，
					再通过**kw 传入：func(**{'a': 1, 'b': 2})。
			使用*args 和**kw 是 Python 的习惯写法，当然也可以用其他参数名，但最好使用习惯用法。
			命名的关键字参数是为了限制调用者可以传入的参数名，同时可以提供默认值。
			定义命名的关键字参数在没有可变参数的情况下不要忘了写分隔符*，否则定义的将是位置参数。
			
	递归函数：
		函数在内部调用自身本身。
		理论上所有的递归函数都可以写成循环的方式，但循环的逻辑不如递归清晰。
			在计算机中，函数调用是通过栈（stack）这种数据结构实现的，
			每当进入一个函数调用，栈就会加一层栈帧，每当函数返回，栈就会减一层栈帧。
			由于栈的大小不是无限的，所以，递归调用的次数过多，会导致栈溢出。
		解决递归调用栈溢出的方法是通过尾递归优化，
			事实上尾递归和循环的效果是一样的，
			把循环看成是一种特殊的尾递归函数也是可以的。
		尾递归：在函数返回的时候，调用自身本身，并且，return 语句不能包含表达式。
			尾递归调用时，如果做了优化，栈不会增长，无论多少次调用也不会导致栈溢出。
		大多数编程语言没有针对尾递归做优化，Python 解释器也没有做优化，
			所以，即使把上面的 fact(n)函数改成尾递归方式，也会导致栈溢出。	
		递归函数的优点是逻辑简单清晰，缺点是过深的调用会导致栈溢出。
		汉诺塔问题：
			思路：
				move((1), a, b, c)	print(a, "->", c)
				move((2), a, b, c)	print(a, "->", b)	print(a, "->", c)	print(b, "->", c)
				move((3), a, b, c)
					move((2), a, c, b)
					print(a, "->", c)
					move((2), b, a, c)
						move((1), a, c, b)	print(a, "->", c)
						print(a, "->", c)	print(a, "->", b)
						move((1), b, a, c)	print(c, "->", b)
						print(a, "->", c)	print(a, "->", c)
						move((1), a, c, b)	print(b, "->", a)
						print(a, "->", c)	print(b, "->", c)
						move((1), b, a, c)	print(a, "->", c)
			解答：
				# -*- coding: utf-8 -*-
				def move(n, a, b, c):
					if n == 1:
						print(a, '-->', c)
					else:
						move((n-1), a, c, b)
						print(a, "-->", c)
						move((n-1), b, a, c)
				move(3, 'A', 'B', 'C')
				
	数据类型转换函数：
		int()：把其他数据类型转换为整数；
		float()：把其他数据类型转换为浮点数；
		str()：把其他数据类型转换为字符串；
		bool()：把其他数据类型转换为布尔型；
		chr(x)：将一个整数转换为一个字符；
		hex()：把一个整数转换成十六进制表示的字符串；
		oct(x)：将一个整数转换为一个八进制字符串。
	
	常用函数：
		abs()：
			求绝对值的函数。
		range()：
			整数列表；
			可以生成一个整数序列，再通过 list()函数可以转换为 list。
		max()：
			可以接收任意多个参数，并返回最大的那个。
		len()：
			获得 list 的元素个数；
			计算 str 的字符数；
			计算 bytes 的字节数。
		lower()：
			返回小写的字符串。
		upper()：
			返回大写的字符串。
		strip()：
			用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。
		split()：
			根据规定的字符将字符串进行分割。
		
三、高级特性：
		
	切片：
		L[0:3]表示，从索引0开始取，直到索引3为止，但不包括索引3。即索引0，1，2，正好是3个元素。
		如果第一个索引是0，还可以省略。
		L[-1]取倒数第一个元素，同样支持倒数切片；倒数第一个元素的索引是-1。
			tuple 也可以用切片操作，只是操作的结果仍是 tuple。
			字符串也可以用切片操作，只是操作结果仍是字符串：
		注意：slice 切片和 range 整数列表都是前包后不包。
		
	迭代 Iteration ：
		for ... in ... 循环：
			for 循环不仅可以用在 list 或 tuple 上，还可以作用在其他可迭代对象上。
		Python 内置的 enumerate 函数可以把一个 list 变成索引-元素对，
			这样就可以在 for 循环中同时迭代索引和元素本身：
				for i, value in enumerate(['A', 'B', 'C']):
		可迭代对象：
			list；tuple；dict；set；str。
			生成式；生成器。
		不可迭代对象：
			int；float；bool；None。
		判断对象是可迭代对象：
			通过 collections 模块的 Iterable 类型判断
				>>> from collections import Iterable
				>>> isinstance('abc', Iterable) # str 是否可迭代
		
	列表生成式：
		写列表生成式：
			把要生成的元素 x * x 放到前面，后面跟 for 循环，就可以把 list 创建出来，
			十分有用，多写几次，很快就可以熟悉这种语法。
		生成 [1x1, 2x2, 3x3, ..., 10x10]：
			[x * x for x in range(1, 11)]
		for 循环后面还可以加上 if 判断，这样我们就可以筛选出仅偶数的平方：
			[x * x for x in range(1, 11) if x % 2 == 0]
		还可以使用两层循环，可以生成全排列：
			[m + n for m in 'ABC' for n in 'XYZ']
		os.listdir 可以列出文件和目录
			[d for d in os.listdir('.')]
		for 循环其实可以同时使用两个甚至多个变量，
			比如 dict 的 items()可以同时迭代 key 和 value：
				d = {'x': 'A', 'y': 'B', 'z': 'C' }
				for k, v in d.items():
		列表生成式也可以使用两个变量来生成 list：
			d = {'x': 'A', 'y': 'B', 'z': 'C' }
			[k + '=' + v for k, v in d.items()]
		一个 list 中所有的字符串变成小写：
			L = ['Hello', 'World', 'IBM', 'Apple']
			[s.lower() for s in L]
			
	生成器：
		generator：在循环的过程中不断推算出后续的元素。
			Python 中一边循环一边计算的机制。
		创建 generator 第一种方法：把一个列表生成式的[]改成()：
			L = [x * x for x in range(10)]
			g = (x * x for x in range(10))
			可以通过 next()函数获得 generator 的下一个返回值：
				generator 保存的是算法，每次调用 next(g)，就计算出 g 的下一个元素的值，
				直到计算到最后一个元素，没有更多的元素时，抛出 StopIteration 的错误。
			不断调用 next(g)实在是太变态了，正确的方法是使用 for 循环，因为 generator 也是可迭代对象：
				g = (x * x for x in range(10))
				for n in g:
			我们创建了一个 generator 后，通过 for 循环来迭代它，并且不需要关心 StopIteration 的错误。
		创建 generator 第二种方法：函数定义中包含 yield 关键字，
			这个函数不再是一个普通函数，而是一个 generator；
		generator 和函数的执行流程不一样。
			函数是顺序执行，遇到 return 语句或者最后一行函数语句就返回。
			而变成 generator 的函数，在每次调用 next()的时候执行，遇到 yield 语句返回，
			再次执行时从上次返回的 yield 语句处继续执行。
		把函数改成 generator 后，我们基本上从来不会用 next()来获取下一个返回值，而是直接使用 for 循环来迭代。
		用 for 循环调用 generator 时，发现拿不到 generator 的 return 语句的返回值。
			如果想要拿到返回值，必须捕获 StopIteration 错误，返回值包含在 StopIteration 的 value 中：
				g = fib(6)
				while True:
					try:
						x = next(g)
						print('g:', x)
					except StopIteration as e:
						print('Generator return value:', e.value)
						break
		杨辉三角：
			把每一行看做一个 list，试写一个 generator，不断输出下一行的 list：
				# -*- coding: utf-8 -*-
				def triangles():
					N = [1]
					while True:
						yield N
						N = N + [0]
						N = [N[i-1] + N[i] for i in range(len(N))]
				
	迭代器(Iterator)：
		可以被 next()函数调用并不断返回下一个值的对象。
		可以直接作用于 for 循环的对象统称为可迭代对象：Iterable。
			可以直接作用于 for 循环的数据类型：
				集合数据类型，如：list、tuple、dict、set、str 等；
				generator，包括：生成器和带 yield 的 generator function。
		可以使用 isinstance()判断一个对象是否是 Iterable 对象：
			from collections import Iterable
			isinstance([], Iterable)
		为什么 list、dict、str 等数据类型不是 Iterator？
			这是因为 Python 的 Iterator 对象表示的是一个数据流，
				Iterator 对象可以被 next()函数调用并不断返回下一个数据，直到没有数据时抛出 StopIteration 错误。
			可以把这个数据流看做是一个有序序列，
				但我们却不能提前知道序列的长度，只能不断通过 next()函数实现按需计算下一个数据，
				所以 Iterator 的计算是惰性的，只有在需要返回下一个数据时它才会计算。
			Iterator 甚至可以表示一个无限大的数据流，例如全体自然数。
				而使用 list 是永远不可能存储全体自然数的。
		小结：
			可作用于 for 循环的对象都是 Iterable 类型；
			可作用于 next()函数的对象都是 Iterator 类型，它们表示一个惰性计算的序列；
			集合数据类型如 list、dict、str 等是 Iterable 但不是 Iterator，
			不过可以通过 iter()函数获得一个 Iterator 对象。
			Python 的 for 循环本质上就是通过不断调用 next()函数实现的。
	
四、函数式编程：
		函数是 Python 内建支持的一种封装，我们通过把大段代码拆成函数，通过一层一层的函数调用，
			就可以把复杂任务分解成简单的任务，这种分解可以称之为面向过程的程序设计。
		函数式编程(Functional Programming)，虽然也可以归结到面向过程的程序设计，但其思想更接近数学计算。
		计算机的层次上，CPU 执行的是加减乘除的指令代码，以及各种条件判断和跳转指令，
			所以，汇编语言是最贴近计算机的语言。
		计算则指数学意义上的计算，越是抽象的计算，离计算机硬件越远。
			对应到编程语言：越低级的语言，越贴近计算机，抽象程度低，执行效率高，比如 C 语言；
				越高级的语言，越贴近计算，抽象程度高，执行效率低，比如 Lisp 语言。
		函数式编程就是一种抽象程度很高的编程范式，纯粹的函数式编程语言编写的函数没有变量，
			因此，任意一个函数，只要输入是确定的，输出就是确定的，这种纯函数我们称之为没有副作用。
		允许使用变量的程序设计语言，由于函数内部的变量状态不确定，同样的输入，可能得到不同的输出，
			因此，这种函数是有副作用的。
		函数式编程的一个特点就是，允许把函数本身作为参数传入另一个函数，还允许返回一个函数。
		
	高阶函数：
		Higher-order function：
			高阶函数：
				变量可以指向函数，函数的参数能接收变量，一个函数就可以接收另一个函数作为参数。
				高阶函数的抽象能力是非常强大的，核心代码可以保持得非常简洁。
			变量可以指向函数：
				函数本身也可以赋值给变量；
			函数名也是变量：
				可以把函数名指向其他对象；
			传入函数：
				高阶函数的参数可以接收函数，也可以返回函数。
				把函数作为参数传入，函数式编程就是指这种高度抽象的编程范式。
			
		map()：
			接收两个参数，一个是函数，一个是可迭代对象(Iterable)，
				map 将传入的函数依次作用到序列的每个元素，并把结果作为新的 Iterator 返回。
			
		reduce()：
			reduce 把一个函数作用在一个序列[x1, x2, x3, ...]上，
			这个函数必须接收两个参数，reduce 把结果继续和序列的下一个元素做累积计算，
			其效果就是：
				reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)
			字符串 str 也是一个序列，配合 map()，可以写出把 str 转换为 int 的函数：
				from functools import reduce
				DIGITS = {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}
				def str2int(s):
					def fn(x, y):
						return x * 10 + y
					def char2num(s):
						return DIGITS[s]
					return reduce(fn, map(char2num, s))
			
		lambda()：
			匿名函数；
				例如：lambda x, y: x * 10 + y
				lambda 后面是自变量；
				冒号后面是表达式。
			
		filter()：
			用于过滤序列。
			和 map()类似，filter()也接收一个函数和一个序列。
			和 map()不同的是，filter()把传入的函数依次作用于每个元素，
			然后根据返回值是 True 还是 False 决定保留还是丢弃该元素。
			把一个序列中的空字符串删掉，可以这么写：
				def not_empty(s):
					return s and s.strip()
				list(filter(not_empty, ['A', '', 'B', None, 'C', '  ']))
			return 中的 or 和 and 语句：
				and：
					return 1 and 0 	# 返回 0
					return 1 and 2	# 返回 2
					return o and ''	# 返回 0
				or：
					return 1 or 0 	# 返回 1
					return 1 or 2	# 返回 1
					return '' or 0	# 返回 0
				结论：
					or ：找真值：
						如果有一个值为真，or 返回第一个真值；
						如果所有的值都为假，or 返回最后一个假值。
					and ：找假值：
						如果有一个值为假，and 返回第一个假值；
						如果所有的值都为真，and 返回最后一个真值。
					特别的：
						如果所有值都是真值，且演算符号不一致，
						那么演算完第一个 and 或 or，就立即返回。
			filter() 返回的是一个 Iterator，也就是一个惰性序列，
				所以要强迫 filter()完成计算结果，需要用 list()函数获得所有结果并返回 list。
			用 filter 求素数：
				计算素数的一个方法是埃氏筛法：
					def _odd_iter():
						n = 1
						while True:
							n = n + 2
							yield n
					def _not_divisible(n):
						return lambda x: x % n > 0	
					def primes():
						yield 2
						it = _odd_iter() # 初始序列
						while True:
							n = next(it) # 返回序列的第一个数
							yield n
							it = filter(_not_divisible(n), it) # 构造新序列			
					# 打印1000以内的素数:
					for n in primes():
						if n < 1000:
							print(n)
						else:
							break
			回数：从左向右读和从右向左读都是一样的数：
				用 filter()筛选出回数：
					def is_palindrome(n):
						n = str(n)
						return int(n) == int(n[::-1])
				
		sorted()：
			排序算法：
				可以对 list 进行排序：
					sorted([36, 5, -12, 9, -21])
				sorted()是一个高阶函数，它还可以接收一个 key 函数来实现自定义的排序：
					sorted([36, 5, -12, 9, -21], key=abs)
					key 指定的函数将作用于 list 的每一个元素上，并根据 key 函数返回的结果进行排序。
					然后 sorted()函数按照 keys 进行排序，并按照对应关系返回 list 相应的元素。
				字符串排序：
					sorted(['bob', 'about', 'Zoo', 'Credit'])
						默认情况下，对字符串排序，是按照 ASCII 的大小比较的，
						由于'Z' < 'a'，结果，大写字母 Z 会排在小写字母 a 的前面。
					字符串忽略大小写排序：
						sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower)
					字符串忽略大小写反向排序：
						sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower, reverse=True)
				用 sorted()排序的关键在于实现一个映射函数。
			
		zip()：
			将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，
				然后返回由这些元组组成的列表。
			如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，
				利用 * 号操作符，可以将元组解压为列表。
			zip 方法在 Python 2 和 Python 3 中的不同：
				在 Python 3.x 中为了减少内存，zip() 返回的是一个对象。
				如需展示列表，需手动 list() 转换。
			
	返回函数：
		函数作为返回值：
			高阶函数除了可以接受函数作为参数外，还可以把函数作为结果值返回。
			
		闭包：
			相关参数和变量都保存在返回的函数中；
				有权访问另一个函数作用域内变量的函数。
			注意：
				当我们调用闭包时，每次调用都会返回一个新的函数，即使传入相同的参数
			返回的函数在其定义内部引用了局部变量，
				当一个函数返回了一个函数后，其内部的局部变量还被新函数引用，
				返回的函数并没有立刻执行，而是直到调用了 f()才执行。
			返回闭包时牢记一点：
				返回函数不要引用任何循环变量，或者后续会发生变化的变量。
			如果一定要引用循环变量怎么办？
				方法是再创建一个函数，用该函数的参数绑定循环变量当前的值，
				无论该循环变量后续如何更改，已绑定到函数参数的值不变
					def count():
						def f(j):
							def g():
								return j*j
							return g
						fs = []
						for i in range(1, 4):
							fs.append(f(i)) # f(i)立刻被执行，因此 i 的当前值被传入 f()
						return fs
			闭包返回一个计数器：
				def createCounter():
					ls = [0]
					def counter():
						ls[0] += 1
						return ls[0]
					return counter
				counterA = createCounter()
				print(counterA(), counterA(), counterA(), counterA(), counterA()) # 1 2 3 4 5
			
	匿名函数：
		关键字 lambda：
			表示匿名函数，冒号前面的 x 表示函数参数，冒号后面是表达式。
			Lambda 是一个表达式，也可以说它是一个匿名函数。
		匿名函数有个限制：
			只能有一个表达式，不用写 return，返回值就是该表达式的结果。
		好处：
			因为函数没有名字，不必担心函数名冲突。
			匿名函数也是一个函数对象，也可以把匿名函数赋值给一个变量，再利用变量来调用该函数
				>>> f = lambda x: x * x
				>>> f
			同样，也可以把匿名函数作为返回值返回，比如：
				def build(x, y):
					return lambda: x * x + y * y
			奇数筛选：
				L = list(filter(lambda x : x % 2 == 1, range(1, 20)))
		
	装饰器：
		在代码运行期间动态增加功能。
		本质上，decorator 就是一个返回函数的高阶函数。
			@语法，把 decorator 置于函数的定义处：
			@log
			def now():
				print('2015-3-25')
			把 @log 放到 now()函数的定义处，相当于执行了语句：
				now = log(now)
		如果 decorator 本身需要传入参数，那就需要编写一个返回 decorator 的高阶函数，写出来会更复杂。
			比如，要自定义 log 的文本：
				def log(text):
					def decorator(func):
						def wrapper(*args, **kw):
							print('%s %s():' % (text, func.__name__))
							return func(*args, **kw)
						return wrapper
					return decorator
			这个3层嵌套的 decorator 用法如下：
				@log('execute')
				def now():
					print('2015-3-25')
		functools.wraps 可以让我么不需要编写 wrapper.__name__ = func.__name__ 这样的代码。
		一个完整的 decorator 的写法如下：
			import functools
			def log(func):
				@functools.wraps(func)
				def wrapper(*args, **kw):
					print('call %s():' % func.__name__)
					return func(*args, **kw)
				return wrapper
		或者针对带参数的 decorator：
			import functools
			def log(text):
				def decorator(func):
					@functools.wraps(func)
					def wrapper(*args, **kw):
						print('%s %s():' % (text, func.__name__))
						return func(*args, **kw)
					return wrapper
				return decorator
			*args：可变参数，用于元组；
			**kw：关键字参数，用于字典。
			
	偏函数(局部函数)：
		通过设定参数的默认值，可以降低函数调用的难度。
		计算机科学中，局部应用是指固定一个函数的一些参数，然后产生另一个更小元的函数。
		functools.partial 作用：
			把一个函数的某些参数给固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单。
		functools.partial 可以创建一个偏函数。
		小结：
			当函数的参数个数太多，需要简化时，使用 functools.partial 可以创建一个新的函数，
			这个新函数可以固定住原函数的部分参数，从而在调用时更简单。
	
五、模块
	使用模块：
		模块：
			一个.py 文件就称为一个模块（Module）。
			自己创建模块时要注意命名，不能和 Python 自带的模块名称冲突。
			例如，系统自带了 sys 模块，自己的模块就不可命名为 sys.py，否则将无法导入系统自带的 sys 模块。
				
		包：
			按目录来组织模块的方法称为包（Package）。
				每一个包目录下面都会有一个__init__.py 的文件，这个文件是必须存在的，
				否则，Python 就把这个目录当成普通目录，而不是一个包。
				__init__.py 可以是空文件，也可以有 Python 代码，
				因为__init__.py 本身就是一个模块，而它的模块名就是包名。
			自己创建模块时要注意命名，不能和 Python 自带的模块名称冲突。
				例如，系统自带了 sys 模块，自己的模块就不可命名为 sys.py，否则将无法导入系统自带的 sys 模块。
		
		sys 模块：
			#!/usr/bin/env python3
			# -*- coding: utf-8 -*-	
			' a test module '
			import sys
				第1行注释可以让这个 hello.py 文件直接在 Unix/Linux/Mac 上运行，
				第2行注释表示.py 文件本身使用标准 UTF-8编码；
				第3行是一个字符串，表示模块的文档注释，任何模块代码的第一个字符串都被视为模块的文档注释；
				第4行导入 sys 模块，就有了变量 sys 指向该模块，利用 sys 这个变量，就可以访问 sys 模块的所有功能。
			if __name__=='__main__':
				test()
				当我们在命令行运行 hello 模块文件时，Python 解释器把一个特殊变量__name__置为__main__，
				而如果在其他地方导入该 hello 模块时，if 判断将失败，
				因此，这种 if 测试可以让一个模块通过命令行运行时执行一些额外的代码，最常见的就是运行测试。
			通俗的理解__name__ == '__main__'：
				假如你叫小明.py，在朋友眼中，你是小明(__name__ == '小明')；
				在你自己眼中，你是你自己(__name__ == '__main__')。
			if __name__ == '__main__'的意思是：
				当.py 文件被直接运行时，if __name__ == '__main__'之下的代码块将被运行；
				当.py 文件以模块形式被导入时，if __name__ == '__main__'之下的代码块不被运行。
		作用域：
			通过_前缀来实现。
				正常的函数和变量名是公开的（public），可以被直接引用；
					比如：abc，x123，PI 等。
				类似__xxx__这样的变量是特殊变量，可以被直接引用，但是有特殊用途，
					比如上面的__author__，__name__就是特殊变量，
				hello 模块定义的文档注释也可以用特殊变量__doc__访问，
					我们自己的变量一般不要用这种变量名；
				类似_xxx 和__xxx 这样的函数或变量，就是非公开的（private），不应该被直接引用，
					比如_abc，__abc 等；
				private 函数和变量“不应该”被直接引用，而不是“不能”被直接引用，
					是因为 Python 并没有一种方法可以完全限制访问 private 函数或变量，
					但是，从编程习惯上不应该引用 private 函数或变量。
			外部不需要引用的函数全部定义成 private，只有外部需要引用的函数才定义为 public。
			
	第三方模块：
		通过包管理工具 pip 完成的。
			如果你正在使用 Mac 或 Linux，安装 pip 本身这个步骤就可以跳过了。
			如果你正在使用 Windows，安装 Python 时确保勾选了 pip 和 Add python.exe to Path。
		安装常用模块：
			推荐直接使用 Anaconda，
				这是一个基于 Python 的数据处理和科学计算平台，它已经内置了许多非常有用的第三方库，
				我们装上 Anaconda，就相当于把数十个第三方模块自动安装好了，非常简单易用。
		模块搜索路径：
			默认情况下，Python 解释器会搜索当前目录、所有已安装的内置模块和第三方模块，
			搜索路径存放在 sys 模块的 path 变量中：
				import sys
				sys.path
			如果我们要添加自己的搜索目录，有两种方法：
				一是直接修改 sys.path，添加要搜索的目录：
					import sys
					sys.path.append('/Users/michael/my_py_scripts')
					这种方法是在运行时修改，运行结束后失效。
				第二种方法是设置环境变量 PYTHONPATH，该环境变量的内容会被自动添加到模块搜索路径中。
					设置方式与设置 Path 环境变量类似。
					注意只需要添加你自己的搜索路径，Python 自己本身的搜索路径不受影响。
	
六、面向对象编程
	面向对象编程：
		Object Oriented Programming (OOP)：
			是一种程序设计思想。OOP 把对象作为程序的基本单元，一个对象包含了数据和操作数据的函数。
		面向过程与面向对象：
			面向过程的程序设计：
				把计算机程序视为一系列的命令集合，即一组函数的顺序执行。
				为了简化程序设计，面向过程把函数继续切分为子函数，
				即把大块函数通过切割成小块函数来降低系统的复杂度。
			而面向对象的程序设计：
				把计算机程序视为一组对象的集合，而每个对象都可以接收其他对象发过来的消息，并处理这些消息，
				计算机程序的执行就是一系列消息在各个对象之间传递。
		Python 中，所有数据类型都可以视为对象，当然也可以自定义对象。
			自定义的对象数据类型就是面向对象中的类（Class）的概念。
			给对象发消息实际上就是调用对象对应的关联函数，我们称之为对象的方法（Method）。
		面向对象的设计思想是抽象出 Class，根据 Class 创建 Instance。
			面向对象的抽象程度又比函数要高，因为一个 Class 既包含数据，又包含操作数据的方法。
		面向对象的三大特点：数据封装、继承和多态。
			
	类和实例：
		面向对象最重要的概念就是类（Class）和实例（Instance），必须牢记类是抽象的模板。
		类可以起到模板的作用，因此，可以在创建实例的时候，把一些我们认为必须绑定的属性强制填写进去。
			通过定义一个特殊的__init__方法，在创建实例的时候，就把 name，score 等属性绑上去：
				class Student(object):
					def __init__(self, name, score):
						self.name = name
						self.score = score
				__init__方法的第一个参数永远是 self，表示创建的实例本身，
				因此，在__init__方法内部，就可以把各种属性绑定到 self，因为 self 就指向创建的实例本身。
			和普通的函数相比，在类中定义的函数只有一点不同，就是第一个参数永远是实例变量 self，
				并且，调用时，不用传递该参数。
			除此之外，类的方法和普通函数没有什么区别，
				所以，你仍然可以用默认参数、可变参数、关键字参数和命名关键字参数。
		数据封装：
			封装数据的函数是和 Student 类本身是关联起来的，我们称之为类的方法。
				比如：print，get，set 方法。
				在 set 方法中，可以对参数做检查，避免传入无效的参数。
		小结：
			类是创建实例的模板，而实例则是一个一个具体的对象，各个实例拥有的数据都互相独立，互不影响；
			方法就是与实例绑定的函数，和普通函数不同，方法可以直接访问实例的数据；
			和静态语言不同，Python 允许对实例变量绑定任何数据，
				对于两个实例变量，虽然它们都是同一个类的不同实例，但拥有的变量名称都可能不同。
			
	访问限制：	
		要让内部属性不被外部访问，可以把属性的名称前加上两个下划线__，
		Python 中，实例的变量名如果以__开头，就变成了一个私有变量（private），
			只有内部可以访问，外部不能访问。
			确保了外部代码不能随意修改对象内部的状态，这样通过访问限制的保护，代码更加健壮。
		Python 中，变量名类似__xxx__的，也就是以双下划线开头，并且以双下划线结尾的，是特殊变量，
			特殊变量是可以直接访问的，不是 private 变量，
			所以，不能用__name__、__score__这样的变量名。
		单下划线和双下划线开头：
			有些时候，你会看到以一个下划线开头的实例变量名，
				比如_name，这样的实例变量外部是可以访问的，
				但是，按照约定俗成的规定，当你看到这样的变量时，
				意思就是，“虽然我可以被访问，但是，请把我视为私有变量，不要随意访问”。
			双下划线开头的实例变量是不是一定不能从外部访问呢？
				其实也不是。
				不能直接访问__name 是因为 Python 解释器对外把__name 变量改成了_Student__name，
				所以，仍然可以通过_Student__name 来访问__name 变量。
			
	继承和多态：
		继承：
			OOP 程序设计中，当我们定义一个 class 的时候，可以从某个现有的 class 继承，
			新的 class 称为子类（Subclass），
			而被继承的 class 称为基类、父类或超类（Base class、Super class）
		好处：
			使子类获得了父类的全部功能。
			可以实现多态：
				当子类和父类都存在相同的 run()方法时，我们说，子类的 run()覆盖了父类的 run()，
				在代码运行的时候，总是会调用子类的 run()。
				因为覆盖，所以多态。
		“开闭”原则：
			对扩展开放：允许新增 Animal 子类；
			对修改封闭：不需要修改依赖 Animal 类型的 run_twice()等函数。
		静态语言 vs 动态语言：
			对于静态语言（例如 Java）来说，如果需要传入 Animal 类型，
				则传入的对象必须是 Animal 类型或者它的子类，否则，将无法调用 run()方法。
			对于 Python 这样的动态语言来说，则不一定需要传入 Animal 类型。
				我们只需要保证传入的对象有一个 run()方法就可以了。	
			Python 的“file-like object“就是一种鸭子类型。
				对真正的文件对象，它有一个 read()方法，返回其内容。
				但是，许多对象，只要有 read()方法，都被视为“file-like object“。
				许多函数接收的参数就是“file-like object“，你不一定要传入真正的文件对象，
				完全可以传入任何实现了 read()方法的对象。
			
	获取对象信息：
		type()：
			判断对象类型；
			返回对应的 Class 类型。
		isinstance()：
			判断一个变量是否是某个类型；
				比如：isinstance(a, list)。
		type() 和 isinstance()：
			能用 type()判断的基本类型也可以用 isinstance()判断；
			isinstance()还可以判断一个变量是否是某些类型中的一种；
			总是优先使用 isinstance()判断类型，可以将指定类型及其子类“一网打尽”。
		dir()：
			目录 (directory)；
			获得一个对象的所有属性和方法；
			返回一个包含字符串的 list；
			__len__()：返回序列的长度。
				在 Python 中，如果你调用 len()函数试图获取一个对象的长度，
				实际上在 len()函数内部，它自动去调用该对象的__len__()方法。
			getattr()：获取属性；
			setattr()：设置属性；
			hasattr()：是否有某个属性。
			
	实例属性和类属性：
		直接在 class 中定义属性，这种属性是类属性，归类所有；
			当我们定义了一个类属性后，这个属性虽然归类所有，但类的所有实例都可以访问到。
		编写程序的时候，千万不要对实例属性和类属性使用相同的名字，
			因为相同名称的实例属性将屏蔽掉类属性，
			但是当你删除实例属性后，再使用相同的名称，访问到的将是类属性。
		小结：
			实例属性属于各个实例所有，互不干扰；
			类属性属于类所有，所有实例共享一个属性；
			不要对实例属性和类属性使用相同的名字，否则将产生难以发现的错误。
		
七、面向对象高级编程
		数据封装、继承和多态只是面向对象程序设计中最基础的3个概念。
		在 Python 中，面向对象还有很多高级特性，允许我们写出非常强大的功能。
		比如：多重继承、定制类、枚举类、元类等概念。
	
	__slots__ 使用：
		动态语言的灵活性：
			当我们定义了一个 class，创建了一个 class 的实例后，我们可以给该实例绑定任何属性和方法。
				动态绑定允许我们在程序运行的过程中动态给 class 加上功能，这在静态语言中很难实现。	
			如果想要限制实例的属性，需要使用__slots__。
		Python 允许在定义 class 的时候，定义一个特殊的__slots__变量，来限制该 class 实例能添加的属性：
			class Student(object):
				__slots__ = ('name', 'age')		# 用 tuple 定义允许绑定的属性名称
		没有被放到__slots__中的属性，都不能被绑定，试图绑定将得到 AttributeError 的错误。
			通过固定插槽，限制实例属性的添加。
			python __slots__ 只能限制实例的属性及方法，对于类则没有影响，对于子类则更是没有限制。
		注意：
			__slots__ 定义的属性仅对当前类实例起作用，对继承的子类是不起作用的：
			除非在子类中也定义__slots__，
				子类实例允许定义的属性就是自身的__slots__加上父类的__slots__。
		动态给类增加方法和属性：
			def set_score(self, score):
			#如果在 slots 中没有属性 score 将报 lotsAttributeError: 'Student' object has no attribute 'score'
				self.score = score
			Student.set_score = set_score	#给类绑定方法和属性不受限制，可以不在 slots 中加 set_score 和 score
			Student.set_score(Student,66)	#类调用 set_acore 方法给自己绑定属性 score 为66
			print(Student.score)
			print(s.score)	#实例可以调用类属性 scored 但是不能用 s.set_score(89)来中心赋值
		动态给实例增加方法和属性
			def set_age(self, age):
				self.age = age
			from types import MethodType
			s.set_age = MethodType(set_age, s)
			#直接给实例绑定方法由于类中没有该方法，必须在 slots 中添加 set_age, age 才可以
			s.set_age(25)
			print(s.age)
			
	@property 使用：
		Python 内置的 @property 装饰器负责把一个方法变成属性调用。
			既能检查参数，又可以用类似属性这样简单的方式来访问类的变量
			只定义 getter 方法，不定义 setter 方法就是一个只读属性。
			@property 广泛应用在类的定义中，可以让调用者写出简短的代码，同时保证对参数进行必要的检查。
			把一个 getter 方法变成属性，只需要加上 @property 就可以了，
				@property 本身又创建了另一个装饰器 @方法名.setter，负责把一个 setter 方法变成属性赋值。
			
	多重继承：	
		一个子类就可以同时获得多个父类的所有功能。
			class Animal(object):
				pass
			class Mammal(Animal):
				pass
			class Flyable(object):
				def fly(self):
					pass
			class Bat(Mammal, Flyable):
				pass
			
	MixIn：
		在设计类的继承关系时，通常，主线都是单一继承下来的。
			但是，如果需要“混入”额外的功能，通过多重继承就可以实现。
			这种设计通常称之为 MixIn。
		为了更好地看出继承关系，我们把 Runnable 和 Flyable 改为 RunnableMixIn 和 FlyableMixIn。
			比如：
				class Bat(Mammal, FlyableMixIn):
					pass
		目的：给一个类增加多个功能，
			在设计类的时候，优先考虑通过多重继承来组合多个 MixIn 的功能，
			而不是设计多层次的复杂的继承关系。
		由于 Python 允许使用多重继承，因此，MixIn 就是一种常见的设计。
			只允许单一继承的语言（如 Java）不能使用 MixIn 的设计。
			
	定制类：
		Python 的 class 中还有许多形如 __xxx__()，有特殊用途的函数，可以帮助我们定制类。
		__slots__()；
			固定卡槽来限定实例属性的添加。
		__len__()：
			返回想要的长度。
		__str__()：
			定义__str__()方法，返回一个好看的字符串。
			直接显示变量调用的不是__str__()，而是__repr__()。
		__repr__()：
			__str__()返回用户看到的字符串；
			__repr__()返回程序开发者看到的字符串，
				__repr__()是为调试服务的。
			通常__str__()和__repr__()代码都是一样的，所以，有个偷懒的写法：
				class Student(object):
					def __init__(self, name):
						self.name = name
					def __str__(self):
						return 'Student object (name=%s)' % self.name
					__repr__ = __str__
		__iter__()：
			如果一个类想被用于 for ... in 循环，类似 list 或 tuple 那样，就必须实现一个__iter__()方法；
				该方法返回一个迭代对象，
			Python 的 for 循环就会不断调用该迭代对象的__next__()方法拿到循环的下一个值，
				直到遇到 StopIteration 错误时退出循环。
			斐波那契数列为例：
				class Fib(object):
					def __init__(self):
						self.a, self.b = 0, 1 # 初始化两个计数器 a，b
					def __iter__(self):
						return self # 实例本身就是迭代对象，故返回自己
					def __next__(self):
						self.a, self.b = self.b, self.a + self.b # 计算下一个值
						if self.a > 100000: # 退出循环的条件
							raise StopIteration()
						return self.a # 返回下一个值
		__getitem__()：
			迭代对象虽然能作用于 for 循环，看起来和 list 有点像，但是，把它当成 list 来使用还是不行。
			要表现得像 list 那样按照下标取出元素，需要实现__getitem__()方法：
				class Fib(object):
					def __getitem__(self, n):
						a, b = 1, 1
						for x in range(n):
							a, b = b, a + b
						return a
			__getitem__()传入的参数可能是一个 int，也可能是一个切片对象 slice，所以要做判断：
				class Fib(object):
					def __getitem__(self, n):
						if isinstance(n, int): # n 是索引
							a, b = 1, 1
							for x in range(n):
								a, b = b, a + b
							return a
						if isinstance(n, slice): # n 是切片
							start = n.start
							stop = n.stop
							if start is None:
								start = 0
							a, b = 1, 1
							L = []
							for x in range(stop):
								if x >= start:
									L.append(a)
								a, b = b, a + b
							return L
			如果把对象看成 dict，__getitem__()的参数也可能是一个可以作 key 的 object，例如 str。
				与之对应的是__setitem__()方法，把对象视作 list 或 dict 来对集合赋值。
				还有一个__delitem__()方法，用于删除某个元素。				
			自己定义的类表现得和 Python 自带的 list、tuple、dict 没什么区别，
				这完全归功于动态语言的“鸭子类型”，不需要强制继承某个接口。
		__getattr__()：
			写一个__getattr__()方法，可以动态返回一个属性。
			当调用不存在的属性时，Python 解释器会试图调用__getattr__(self, 'score')来尝试获得属性，
				我们就有机会返回 score 的值
			注意：只有在没有找到属性的情况下，才调用__getattr__，已有的属性，不会在__getattr__中查找。
		__call__()：
			对象实例可以有自己的属性和方法，当我们调用实例方法时，我们用 instance.method()来调用。
			定义一个 __call__() 方法，就可以直接对实例进行调用。
			__call__() 还可以定义参数：
				对实例进行直接调用就好比对一个函数进行调用一样，
				所以完全可以把对象看成函数，把函数看成对象，因为这两者之间本来就没啥根本的区别。
			如果把对象看成函数，那么函数本身其实也可以在运行期动态创建出来，
				因为类的实例都是运行期创建出来的，这么一来就模糊了对象和函数的界限。
			如何判断一个变量是对象还是函数：
				判断一个对象是否能被调用，能被调用的对象就是一个 Callable 对象
				通过 callable()，我们就可以判断一个对象是否是“可调用”对象。
			
	枚举类：
		定义一个 class 类型，每个常量都是 class 的一个唯一实例。
			from enum import Enum
			Month = Enum('Month', ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'))
		@unique 装饰器可以帮助我们检查保证没有重复值。
			如果需要更精确地控制枚举类型，可以从 Enum 派生出自定义类：
				from enum import Enum, unique
				@unique
				class Weekday(Enum):
					Sun = 0 # Sun 的 value 被设定为0
					Mon = 1
					Tue = 2
					Wed = 3
					Thu = 4
					Fri = 5
					Sat = 6
		访问这些枚举类型有多种方式：
			可以用成员名称引用枚举常量，又可以直接根据 value 的值获得枚举常量。
		Enum 可以把一组相关常量定义在一个 class 中，且 class 不可变，而且成员可以直接比较。
		
	元类：
		type()：
			class 的定义是运行时动态创建的，而创建 class 的方法就是使用 type()函数。
			既可以返回一个对象的类型，又可以创建出新的类型，
				比如，我们可以通过 type()函数创建出 Hello 类，而无需通过 class Hello(object)...的定义。
			要创建一个 class 对象，type()函数依次传入3个参数：
				class 的名称；
				继承的父类集合，注意 Python 支持多重继承，如果只有一个父类，别忘了 tuple 的单元素写法；
				class 的方法名称与函数绑定，这里我们把函数 fn 绑定到方法名 hello 上。
		metaclass：
			除了使用 type()动态创建类以外，要控制类的创建行为，还可以使用 metaclass。
			metaclass，直译为元类，简单的解释就是：
				当我们定义了类以后，就可以根据这个类创建出实例，所以：先定义类，然后创建实例。
			但是如果我们想创建出类呢？
				那就必须根据 metaclass 创建出类，所以：先定义 metaclass，然后创建类。
				连接起来就是：先定义 metaclass，就可以创建类，最后创建实例。
			所以，metaclass 允许你创建类或者修改类。换句话说，你可以把类看成是 metaclass 创建出来的“实例”。
			metaclass 是 Python 面向对象里最难理解，也是最难使用的魔术代码。
				它可以改变类创建时的行为。这种强大的功能使用起来务必小心
			
	错误处理：
		try ... except ... finally ... 错误处理机制：
			Python 的错误其实也是 class，所有的错误类型都继承自 BaseException，
			所以在使用 except 时需要注意的是，它不但捕获该类型的错误，还把其子类也“一网打尽”。
		调用栈：
			如果错误没有被捕获，它就会一直往上抛，最后被 Python 解释器捕获，打印一个错误信息然后程序退出。
			出错的时候，一定要分析错误的调用栈信息，才能定位错误的位置。
		记录错误：
			Python 内置的 logging 模块可以非常容易地记录错误信息。
			通过配置，logging 还可以把错误记录到日志文件里，方便事后排查。
		抛出错误
			因为错误是 class，捕获一个错误就是捕获到该 class 的一个实例。
			因此，错误并不是凭空产生的，而是有意创建并抛出的。
			Python 的内置函数会抛出很多类型的错误，我们自己编写的函数也可以抛出错误。
			如果要抛出错误，首先根据需要，可以定义一个错误的 class，选择好继承关系，
			然后，用 raise 语句抛出一个错误的实例
			只有在必要的时候才定义我们自己的错误类型。
			如果可以选择 Python 已有的内置的错误类型（比如 ValueError，TypeError），
				尽量使用 Python 内置的错误类型。
			raise 语句如果不带参数，就会把当前错误原样抛出。
			此外，在 except 中 raise 一个 Error，还可以把一种类型的错误转化成另一种类型。
			
	调试：
		print()：
			用 print()把可能有问题的变量打印出来看看。
		断言：
			凡是用 print()来辅助查看的地方，都可以用断言（assert）来替代。
			启动 Python 解释器时可以用-O 参数来关闭 assert：
				python -O err.py
				关闭后，你可以把所有的 assert 语句当成 pass 来看。
		logging：
			把 print()替换为 logging 是第3种方式，和 assert 比，logging 不会抛出错误，而且可以输出到文件。
			logging 的好处：
				它允许你指定记录信息的级别，有 debug，info，warning，error 等几个级别，当
					我们指定 level=INFO 时，logging.debug 就不起作用了。
					同理，指定 level=WARNING 后，debug 和 info 就不起作用了。
					这样一来可以放心地输出不同级别的信息，也不用删除，最后统一控制输出哪个级别的信息。
				通过简单的配置，一条语句可以同时输出到不同的地方，比如 console 和文件。
		pdb：
			启动 Python 的调试器 pdb，让程序以单步方式运行，可以随时查看运行状态。
			这种通过 pdb 在命令行调试的方法理论上是万能的，但实在是太麻烦了。
			pdb.set_trace()：
				这个方法也不需要单步执行，我们只需要 import pdb，
				然后，在可能出错的地方放一个 pdb.set_trace()，就可以设置一个断点
				运行代码，程序会自动在 pdb.set_trace()暂停并进入 pdb 调试环境，
				可以用命令 p 查看变量，或者用命令 c 继续运行
		IDE
			如果要比较爽地设置断点、单步执行，就需要一个支持调试功能的 IDE。
			目前比较好的 Python IDE 有：
				Visual Studio Code：https://code.visualstudio.com/，需要安装 Python 插件。
				PyCharm：http://www.jetbrains.com/pycharm/
			
	单元测试：
		测试驱动开发（TDD：Test-Driven Development）
			以测试为驱动的开发模式好处：
				确保一个程序模块的行为符合我们设计的测试用例。
				在将来修改的时候，可以极大程度地保证该模块行为仍然是正确的。
		单元测试：用来对一个模块、一个函数或者一个类来进行正确性检验的测试工作。
			编写单元测试，需要引入 Python 自带的 unittest 模块。
			编写单元测试时，需要编写一个测试类，从 unittest.TestCase 继承。
			以 test 开头的方法就是测试方法，不以 test 开头的方法不被认为是测试方法，测试的时候不会被执行。
			对每一类测试都需要编写一个 test_xxx()方法。
				unittest.TestCase 提供了内置的条件判断，只需要调用这些方法就可以断言输出是否是所期望的。
					最常用的断言就是 assertEqual()。
				另一种重要的断言就是期待抛出指定类型的 Error，
					比如通过 d['empty']访问不存在的 key 时，断言会抛出 KeyError
		运行单元测试
			编写好单元测试，就可以运行单元测试。最简单的运行方式是在 mydict_test.py 的最后加两行代码：
				if __name__ == '__main__':
					unittest.main()
			另一种方法是在命令行通过参数-m unittest 直接运行单元测试；
				这样可以一次批量运行很多单元测试，并且，有很多工具可以自动来运行这些单元测试。
		setUp 与 tearDown
			可以在单元测试中编写两个特殊的 setUp()和 tearDown()方法。
			这两个方法会分别在每调用一个测试方法的前后分别被执行。
			setUp()和 tearDown()方法作用：
				如果测试需要启动一个数据库，这时，就可以在 setUp()方法中连接数据库，
				在 tearDown()方法中关闭数据库，这样，不必在每个测试方法中重复相同的代码
						
	文档测试
		Python 内置的“文档测试”（doctest）模块可以直接提取注释中的代码并执行测试。
			doctest 严格按照 Python 交互式命令行的输入和输出来判断测试结果是否正确。
			只有测试异常的时候，可以用...表示中间一大段烦人的输出。
			
	读文件：
		使用 Python 内置的 open()函数，传入文件名和标示符：
			f = open('/Users/michael/test.txt', 'r')
		如果文件打开成功，接下来，调用 read()方法可以一次读取文件的全部内容，
			Python 把内容读到内存，用一个 str 对象表示。
		最后一步是调用 close()方法关闭文件。
			文件使用完毕后必须关闭，因为文件对象会占用操作系统的资源，
			并且操作系统同一时间能打开的文件数量也是有限的。
		由于文件读写时都有可能产生 IOError，一旦出错，后面的 f.close()就不会调用。
			所以，为了保证无论是否出错都能正确地关闭文件，我们可以使用 try ... finally 来实现：
			try:
				f = open('/path/to/file', 'r')
				print(f.read())
			finally:
				if f:
					f.close()
		但是每次都这么写实在太繁琐，所以，Python 引入了 with 语句来自动帮我们调用 close()方法：
			with open('/path/to/file', 'r') as f:
				print(f.read())
		调用 read()会一次性读取文件的全部内容，如果文件有10G，内存就爆了，
			所以，要保险起见，可以反复调用 read(size)方法，每次最多读取 size 个字节的内容。
		调用 readline()可以每次读取一行内容，
		调用 readlines()一次读取所有内容并按行返回 list。
			
	file-like Object
		像 open()函数返回的这种有个 read()方法的对象，在 Python 中统称为 file-like Object。
		除了 file 外，还可以是内存的字节流，网络流，自定义流等等。
		file-like Object 不要求从特定类继承，只要写个 read()方法就行。
		StringIO 就是在内存中创建的 file-like Object，常用作临时缓冲。
			
	二进制文件
		前面讲的默认都是读取文本文件，并且是 UTF-8编码的文本文件。
		要读取二进制文件，比如图片、视频等等，用'rb'模式打开文件即可：
			f = open('/Users/michael/test.jpg', 'rb')
			f.read()
			
	字符编码
		要读取非 UTF-8编码的文本文件，需要给 open()函数传入 encoding 参数，例如，读取 GBK 编码的文件：
			f = open('/Users/michael/gbk.txt', 'r', encoding='gbk')
		open()函数还接收一个 errors 参数，表示如果遇到编码错误后如何处理。最简单的方式是直接忽略：
			f = open('/Users/michael/gbk.txt', 'r', encoding='gbk', errors='ignore')	
			
	写文件：
		写文件和读文件是一样的，
		唯一区别是调用 open()函数时，传入标识符'w'或者'wb'表示写文本文件或写二进制文件。
			f = open('/Users/michael/test.txt', 'w')
			f.write('Hello, world!')
			f.close()
		当我们写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存缓存起来，空闲的时候再慢慢写入。
		只有调用 close()方法时，操作系统才保证把没有写入的数据全部写入磁盘。
		忘记调用 close()的后果是数据可能只写了一部分到磁盘，剩下的丢失了。
		所以，还是用 with 语句来得保险：
			with open('/Users/michael/test.txt', 'w') as f:
				f.write('Hello, world!')
		以'w'模式写入文件时，如果文件已存在，会直接覆盖（相当于删掉后新写入一个文件）。
		如果希望追加到文件末尾，可以传入'a'以追加（append）模式写入。
			
	StringIO：
		在内存中读写 str。
		要把 str 写入 StringIO，我们需要先创建一个 StringIO，然后，像文件一样写入即可：
			from io import StringIO
			f = StringIO()
			f.write('hello')
			getvalue()方法用于获得写入后的 str。
		要读取 StringIO，可以用一个 str 初始化 StringIO，然后，像读文件一样读取：	
			from io import StringIO
			f = StringIO('Hello!\nHi!\nGoodbye!')
			
	BytesIO：
		StringIO 操作的只能是 str，如果要操作二进制数据，就需要使用 BytesIO。
		BytesIO 实现了在内存中读写 bytes，我们创建一个 BytesIO，然后写入一些 bytes：
			from io import BytesIO
			f = BytesIO()
			f.write('中文'.encode('utf-8'))
			
	操作文件和目录：
		操作系统提供的接口函数：
			Python 内置的 os 模块也可以直接调用操作系统提供的接口函数。
				os.name
				os.uname()
		环境变量：
			在操作系统中定义的环境变量，全部保存在 os.environ 这个变量中，可以直接查看：
				os.environ
		操作文件和目录：
			操作文件和目录的函数一部分放在 os 模块中，一部分放在 os.path 模块中。
				查看、创建和删除目录可以这么调用：
					# 查看当前目录的绝对路径:
						os.path.abspath('.')
					# 在某个目录下创建一个新目录，首先把新目录的完整路径表示出来:
						os.path.join('/Users/michael', 'testdir')
					# 创建一个目录:
						os.mkdir('/Users/michael/testdir')
					# 删掉一个目录:
						os.rmdir('/Users/michael/testdir')
			把两个路径合成一个时，不要直接拼字符串，而要通过 os.path.join()函数，
				这样可以正确处理不同操作系统的路径分隔符。
			在 Linux/Unix/Mac 下，os.path.join()返回这样的字符串：
				part-1/part-2
			而 Windows 下会返回这样的字符串：
				part-1\part-2
			# 对文件重命名:
				os.rename('test.txt', 'test.py')
			# 删掉文件:
				os.remove('test.py')
			
	序列化：
		把变量从内存中变成可存储或传输的过程。
			在 Python 中叫 pickling，在其他语言中也被称之为 serialization，marshalling，flattening 等等。
		反序列化 (unpickling) ：
			把变量内容从序列化的对象重新读到内存里。
		Python 提供了 pickle 模块来实现序列化。

			首先，我们尝试把一个对象序列化并写入文件：
				import pickle
				d = dict(name='Bob', age=20, score=88)
				pickle.dumps(d)
			pickle.dumps()方法把任意对象序列化成一个 bytes，然后，就可以把这个 bytes 写入文件。
			或者用另一个方法 pickle.dump()直接把对象序列化后写入一个 file-like Object：
				f = open('dump.txt', 'wb')
				pickle.dump(d, f)
				f.close()
			看看写入的 dump.txt 文件，一堆乱七八糟的内容，这些都是 Python 保存的对象内部信息。
			当我们要把对象从磁盘读到内存时，
			可以先把内容读到一个 bytes，然后用 pickle.loads()方法反序列化出对象，
			也可以直接用 pickle.load()方法从一个 file-like Object 中直接反序列化出对象。
			我们打开另一个 Python 命令行来反序列化刚才保存的对象：
				f = open('dump.txt', 'rb')
				d = pickle.load(f)
				f.close()
				d
			当然，这个变量和原来的变量是完全不相干的对象，它们只是内容相同而已。
			Pickle 的问题和所有其他编程语言特有的序列化问题一样，就是它只能用于 Python，
			并且可能不同版本的 Python 彼此都不兼容，
			因此，只能用 Pickle 保存那些不重要的数据，不能成功地反序列化也没关系。
			
	JSON：
		JSON 表示的对象就是标准的 JavaScript 语言的对象，
		JSON 和 Python 内置的数据类型对应如下：
			JSON 类型	Python 类型
			{}			dict
			[]			list
			"string"	str
			1234.56		int 或 float
			true/false	True/False
			null		None
		Python 内置的 json 模块提供了非常完善的 Python 对象到 JSON 格式的转换。
		我们先看看如何把 Python 对象变成一个 JSON：
			import json
			d = dict(name='Bob', age=20, score=88)
			json.dumps(d)
		dumps()方法返回一个 str，内容就是标准的 JSON。
		类似的，dump()方法可以直接把 JSON 写入一个 file-like Object。
		要把 JSON 反序列化为 Python 对象，用 loads()或者对应的 load()方法，
		前者把 JSON 的字符串反序列化，后者从 file-like Object 中读取字符串并反序列化：
			json_str = '{"age": 20, "score": 88, "name": "Bob"}'
			json.loads(json_str)
			
	JSON 进阶：
		Python 的 dict 对象可以直接序列化为 JSON 的{}，
			不过，很多时候，我们更喜欢用 class 表示对象，然后序列化。
		dumps()方法的参数列表，除了第一个必须的 obj 参数外，dumps()方法还提供了一大堆的可选参数：
			这些可选参数就是让我们来定制 JSON 序列化。
			默认情况下，dumps()方法不知道如何将实例变为一个 JSON 的{}对象。
			可选参数 default 就是把任意一个对象变成一个可序列为 JSON 的对象，
			我们只需要为实例专门写一个转换函数，再把函数传进去即可。
		把任意 class 的实例变为 dict：
			print(json.dumps(s, default=lambda obj: obj.__dict__))
		因为通常 class 的实例都有一个__dict__属性，它就是一个 dict，用来存储实例变量。
		也有少数例外，比如定义了__slots__的 class。
			
进程和线程
	多进程：
		Unix/Linux 操作系统提供了一个 fork()系统调用，它非常特殊。
			普通的函数调用，调用一次，返回一次，但是 fork()调用一次，返回两次，
			因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），
			然后，分别在父进程和子进程内返回。
		子进程永远返回0，而父进程返回子进程的 ID。
			这样做的理由是，一个父进程可以 fork 出很多子进程，
			所以，父进程要记下每个子进程的 ID，而子进程只需要调用 getppid()就可以拿到父进程的 ID。
		Python 的 os 模块封装了常见的系统调用，其中就包括 fork，可以在 Python 程序中轻松创建子进程。
			
	multiprocessing：	
		跨平台版本的多进程模块。
			multiprocessing 模块提供了一个 Process 类来代表一个进程对象。
			创建子进程时，只需要传入一个执行函数和函数的参数，创建一个 Process 实例，用 start()方法启动，
			这样创建进程比 fork()还要简单。
			join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。
			
	Pool：
		如果要启动大量的子进程，可以用进程池的方式批量创建子进程
			
	子进程：
		很多时候，子进程并不是自身，而是一个外部进程。
		我们创建了子进程后，还需要控制子进程的输入和输出。
		subprocess 模块可以让我们非常方便地启动一个子进程，然后控制其输入和输出。
		如果子进程还需要输入，则可以通过 communicate()方法输入。	
			
	进程间通信：
		Process 之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。
		Python 的 multiprocessing 模块包装了底层的机制，提供了 Queue、Pipes 等多种方式来交换数据。
			Unix/Linux 下，multiprocessing 模块封装了 fork()调用，使我们不需要关注 fork()的细节。
			由于 Windows 没有 fork 调用，因此，multiprocessing 需要“模拟”出 fork 的效果，
			父进程所有 Python 对象都必须通过 pickle 序列化再传到子进程去，
			所有，如果 multiprocessing 在 Windows 下调用失败了，要先考虑是不是 pickle 失败了。
			
	多线程：
		多任务可以由多进程完成，也可以由一个进程内的多线程完成。
			由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，
			Python 的线程是真正的 Posix Thread，而不是模拟出来的线程。
		Python 的标准库提供了两个模块：_thread 和 threading，
			_thread 是低级模块，threading 是高级模块，对_thread 进行了封装。
			绝大多数情况下，我们只需要使用 threading 这个高级模块。
		启动一个线程就是把一个函数传入并创建 Thread 实例，然后调用 start()开始执行：
			import time, threading
			# 新线程执行的代码:
			def loop():
				print('thread %s is running...' % threading.current_thread().name)
				n = 0
				while n < 5:
					n = n + 1
					print('thread %s >>> %s' % (threading.current_thread().name, n))
					time.sleep(1)
				print('thread %s ended.' % threading.current_thread().name)
			print('thread %s is running...' % threading.current_thread().name)
			t = threading.Thread(target=loop, name='LoopThread')
			t.start()
			t.join()
			print('thread %s ended.' % threading.current_thread().name)
		由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，
		Python 的 threading 模块有个 current_thread()函数，它永远返回当前线程的实例。
		主线程实例的名字叫 MainThread，子线程的名字在创建时指定，我们用 LoopThread 命名子线程。
		名字仅仅在打印时用来显示，完全没有其他意义，
		如果不起名字 Python 就自动给线程命名为 Thread-1，Thread-2……
			
	Lock：
		多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响；
		多线程中，所有变量都由所有线程共享，任何一个变量都可以被任何一个线程修改，
		因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。
			
		当某个线程开始执行时，该线程因为获得了锁，
		因此其他线程不能同时执行，只能等待，直到锁被释放后，获得该锁以后才能改。
		由于锁只有一个，无论多少线程，同一时刻最多只有一个线程持有该锁，所以，不会造成修改的冲突。
		创建一个锁就是通过 threading.Lock()来实现：
			balance = 0
			lock = threading.Lock()
			def run_thread(n):
				for i in range(100000):
					# 先要获取锁:
					lock.acquire()
					try:
						# 放心地改吧:
						change_it(n)
					finally:
						# 改完了一定要释放锁:
						lock.release()
		当多个线程同时执行 lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，
		其他线程就继续等待直到获得锁为止。
		获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。
		所以我们用 try...finally 来确保锁一定会被释放。
			
		锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，
		坏处当然也很多：
		首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。
		其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，
		导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。
			
	多核 CPU：
		用 C、C++ 或 Java 来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%
		Python 的线程虽然是真正的线程，但解释器执行代码时，有一个 GIL 锁：Global Interpreter Lock，
		任何 Python 线程执行前，必须先获得 GIL 锁，
		然后，每执行100条字节码，解释器就自动释放 GIL 锁，让别的线程有机会执行。
		这个 GIL 全局锁实际上把所有线程的执行代码都给上了锁，
		所以，多线程在 Python 中只能交替执行，即使100个线程跑在100核 CPU 上，也只能用到1个核。
			
		GIL 是 Python 解释器设计的历史遗留问题，通常我们用的解释器是官方实现的 CPython，
		要真正利用多核，除非重写一个不带 GIL 的解释器。
		在 Python 中，可以使用多线程，但不要指望能有效利用多核。
		如果一定要通过多线程利用多核，那只能通过 C 扩展来实现，不过这样就失去了 Python 简单易用的特点。
		Python 虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。
		多个 Python 进程有各自独立的 GIL 锁，互不影响。
			
	ThreadLocal：
		在多线程环境下，每个线程都有自己的数据。
		一个线程使用自己的局部变量比使用全局变量好，
		因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。
		但是局部变量也有问题，就是在函数调用的时候，传递起来很麻烦。
		线程局部变量(线程本地变量)：
			全局变量 local_school 就是一个 ThreadLocal 对象，
			每个 Thread 对它都可以读写 student 属性，但互不影响。
			你可以把 local_school 看成全局变量，但每个属性如 local_school.student 都是线程的局部变量，
			可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal 内部会处理。
		ThreadLocal 最常用的地方就是为每个线程绑定一个数据库连接，HTTP 请求，用户身份信息等，
		这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。
		一个 ThreadLocal 变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。
		ThreadLocal 解决了参数在一个线程中各个函数之间互相传递的问题。
			
	进程 vs. 线程：
		首先，要实现多任务，通常我们会设计 Master-Worker 模式，Master 负责分配任务，Worker 负责执行任务，
			因此，多任务环境下，通常是一个 Master，多个 Worker。
			如果用多进程实现 Master-Worker，主进程就是 Master，其他进程就是 Worker。
			如果用多线程实现 Master-Worker，主线程就是 Master，其他线程就是 Worker。
		多进程模式最大的优点就是稳定性高，因为一个子进程崩溃了，不会影响主进程和其他子进程。
			（当然主进程挂了所有进程就全挂了，但是 Master 进程只负责分配任务，挂掉的概率低）
			著名的 Apache 最早就是采用多进程模式。

		多进程模式的缺点是创建进程的代价大，
			在 Unix/Linux 系统下，用 fork 调用还行，
			在 Windows 下创建进程开销巨大。
			另外，操作系统能同时运行的进程数也是有限的，在内存和 CPU 的限制下，
			如果有几千个进程同时运行，操作系统连调度都会成问题。

		多线程模式通常比多进程快一点，但是也快不到哪去，
		而且，多线程模式致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃，
			因为所有线程共享进程的内存。
			在 Windows 上，如果一个线程执行的代码出了问题，
			你经常可以看到这样的提示：“该程序执行了非法操作，即将关闭”，
			其实往往是某个线程出了问题，但是操作系统会强制结束整个进程。
		在 Windows 下，多线程的效率比多进程要高，所以微软的 IIS 服务器默认采用多线程模式。
			由于多线程存在稳定性的问题，IIS 的稳定性就不如 Apache。
			为了缓解这个问题，IIS 和 Apache 现在又有多进程 + 多线程的混合模式，真是把问题越搞越复杂。
			
	线程切换：
		操作系统在切换进程或者线程时是有代价的，
		它需要先保存当前执行的现场环境（CPU 寄存器状态、内存页等），
		然后，把新任务的执行环境准备好（恢复上次的寄存器状态，切换内存页等），才能开始执行。
			这个切换过程虽然很快，但是也需要耗费时间。
			如果有几千个任务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，
			这种情况最常见的就是硬盘狂响，点窗口无反应，系统处于假死状态。
			
	计算密集型 vs. IO 密集型：
		是否采用多任务的第二个考虑是任务类型。
		我们可以把任务分为计算密集型和 IO 密集型。
		计算密集型任务的特点是要进行大量的计算，消耗 CPU 资源，
			比如计算圆周率、对视频进行高清解码等等，全靠 CPU 的运算能力。
			这种计算密集型任务虽然也可以用多任务完成，
			但是任务越多，花在任务切换的时间就越多，CPU 执行任务的效率就越低，
			所以，要最高效地利用 CPU，计算密集型任务同时进行的数量应当等于 CPU 的核心数。
			计算密集型任务由于主要消耗 CPU 资源，因此，代码运行效率至关重要。
				Python 这样的脚本语言运行效率很低，完全不适合计算密集型任务。
				对于计算密集型任务，最好用 C 语言编写。
		第二种任务的类型是 IO 密集型，涉及到网络、磁盘 IO 的任务都是 IO 密集型任务，
			这类任务的特点是 CPU 消耗很少，任务的大部分时间都在等待 IO 操作完成
			（因为 IO 的速度远远低于 CPU 和内存的速度）。
			对于 IO 密集型任务，任务越多，CPU 效率越高，但也有一个限度。
			常见的大部分任务都是 IO 密集型任务，比如 Web 应用。
			IO 密集型任务执行期间，99%的时间都花在 IO 上，花在 CPU 上的时间很少，
				用运行速度极快的 C 语言替换用 Python 这样运行速度极低的脚本语言，完全无法提升运行效率。
				对于 IO 密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选。
				
	异步 IO：
		考虑到 CPU 和 IO 之间巨大的速度差异，
			一个任务在执行的过程中大部分时间都在等待 IO 操作，
			单进程单线程模型会导致别的任务无法并行执行，
			因此，我们才需要多进程模型或者多线程模型来支持多任务并发执行。
		现代操作系统对 IO 操作已经做了巨大的改进，最大的特点就是支持异步 IO。
			如果充分利用操作系统提供的异步 IO 支持，就可以用单进程单线程模型来执行多任务，
			这种全新的模型称为事件驱动模型，
			Nginx 就是支持异步 IO 的 Web 服务器，它在单核 CPU 上采用单进程模型就可以高效地支持多任务。
			在多核 CPU 上，可以运行多个进程（数量与 CPU 核心数相同），充分利用多核 CPU。
			由于系统总的进程数量十分有限，因此操作系统调度非常高效。
			用异步 IO 编程模型来实现多任务是一个主要的趋势。
		对应到 Python 语言，单线程的异步编程模型称为协程，
			有了协程的支持，就可以基于事件驱动编写高效的多任务程序。
			后面会讨论如何编写协程。
			
	分布式进程：
		在 Thread 和 Process 中，应当优选 Process，因为 Process 更稳定，
			Process 可以分布到多台机器上，而 Thread 最多只能分布到同一台机器的多个 CPU 上。
		Python 的 multiprocessing 模块不但支持多进程，其中 managers 子模块还支持把多进程分布到多台机器上。
			一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。
			由于 managers 模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。
		在一台机器上写多进程程序时，创建的 Queue 可以直接拿来用，
			在分布式多进程环境下，添加任务到 Queue 不可以直接对原始的 task_queue 进行操作，
			那样就绕过了 QueueManager 的封装，必须通过 manager.get_task_queue()获得的 Queue 接口添加。
		Python 的分布式进程接口简单，封装良好，适合需要把繁重任务分布到多台机器的环境下。
			注意 Queue 的作用是用来传递任务和接收结果，每个任务的描述数据量要尽量小。
			比如发送一个处理日志文件的任务，就不要发送几百兆的日志文件本身，
			而是发送日志文件存放的完整路径，由 Worker 进程再去共享的磁盘上读取文件。
			
	正则表达式：
		一种用来匹配字符串的强有力的武器。
		它的设计思想是用一种描述性的语言来给字符串定义一个规则，
		凡是符合规则的字符串，我们就认为它“匹配”了，否则，该字符串就是不合法的。
			精确匹配：
				\d ：一个数字
				\w ：一个字母或数字
				\s ：匹配一个空格（也包括 Tab 等空白符）
				.  ：任意字符
				*  ：任意个字符（包括0个）
				+  ：至少一个字符
				?  ：最多一个字符；0个或1个字符
				{n} ：n 个字符
				{n,m} ：n-m 个字符
				\s+ ：至少有一个空格，例如匹配' '，' '等
			进阶：
				[] ：范围
					[0-9a-zA-Z\_] ：一个数字、字母或者下划线；
					[0-9a-zA-Z\_]+ ：匹配至少由一个数字、字母或者下划线组成的字符串
					[a-zA-Z\_][0-9a-zA-Z\_]* ：
						由字母或下划线开头，后接任意个由一个数字、字母或者下划线组成的字符串；
						也就是 Python 合法的变量。
					[a-zA-Z\_][0-9a-zA-Z\_]{0, 19} ：
						长度是1-20个字符（前面1个字符 + 后面最多19个字符）
				A|B ：配 A 或 B，所以(P|p)ython 可以匹配'Python'或者'python'。
				^   ：行的开头，^\d 表示必须以数字开头。
				$   ：行的结束，\d$表示必须以数字结束。
			re 模块：
				Python 提供 re 模块，包含所有正则表达式的功能。
				由于 Python 的字符串本身也用\转义，所以要特别注意：
					s = 'ABC\\-001' # Python 的字符串
					# 对应的正则表达式字符串变成：
					# 'ABC\-001'
				因此我们强烈建议使用 Python 的 r 前缀，就不用考虑转义的问题了：
					s = r'ABC\-001' # Python 的字符串
					# 对应的正则表达式字符串不变：
					# 'ABC\-001'
				match()：
					判断是否匹配，如果匹配成功，返回一个 Match 对象，否则返回 None。
			切分字符串：
				用正则表达式切分字符串比用固定的字符更灵活。
			分组：
				除了简单地判断是否匹配之外，正则表达式还有提取子串的强大功能。
				用 () 表示的就是要提取的分组（Group）。
				如果正则表达式中定义了组，就可以在 Match 对象上用 group()方法提取出子串来。
				注意到 group(0)永远是原始字符串，group(1)、group(2)……表示第1、2、……个子串。
			贪婪匹配：
				最后需要特别指出的是，正则匹配默认是贪婪匹配，也就是匹配尽可能多的字符。
					举例如下，匹配出数字后面的0：
						>>> re.match(r'^(\d+)(0*)$', '102300').groups()
						('102300', '')
					由于\d+ 采用贪婪匹配，直接把后面的0全部匹配了，结果0*只能匹配空字符串了。
				必须让\d+ 采用非贪婪匹配（也就是尽可能少匹配），才能把后面的0匹配出来，
					加个? 就可以让\d+ 采用非贪婪匹配：
						>>> re.match(r'^(\d+?)(0*)$', '102300').groups()
						('1023', '00')
			编译：
				当我们在 Python 中使用正则表达式时，re 模块内部会干两件事情：
					编译正则表达式，如果正则表达式的字符串本身不合法，会报错；
					用编译后的正则表达式去匹配字符串。
				如果一个正则表达式要重复使用几千次，出于效率的考虑，我们可以预编译该正则表达式，
					接下来重复使用时就不需要编译这个步骤了，直接匹配。
						>>> import re
						# 编译:
						>>> re_telephone = re.compile(r'^(\d{3})-(\d{3,8})$')
			
常用内建模块：
	datetime：
			Python 处理日期和时间的标准库。
		获取当前日期和时间：
			>>> from datetime import datetime
			>>> now = datetime.now() # 获取当前 datetime
			注意：
				datetime 是模块，datetime 模块还包含一个 datetime 类，
				通过 from datetime import datetime 导入的才是 datetime 这个类。
		获取指定日期和时间：
			直接用参数构造一个 datetime：
			>>> from datetime import datetime
			>>> dt = datetime(2015, 4, 19, 12, 20) # 用指定日期时间创建 datetime
		datetime 转换为 timestamp：
			1970年1月1日 00:00:00 UTC+00:00时区的时刻称为 epoch time，记为0
			（1970年以前的时间 timestamp 为负数），
			当前时间就是相对于 epoch time 的秒数，称为 timestamp。
			把一个 datetime 类型转换为 timestamp 只需要简单调用 timestamp()方法：
				>>> from datetime import datetime
				>>> dt = datetime(2015, 4, 19, 12, 20) # 用指定日期时间创建 datetime
				>>> dt.timestamp() # 把 datetime 转换为 timestamp
			注意 Python 的 timestamp 是一个浮点数。如果有小数位，小数位表示毫秒数。
			某些编程语言（如 Java 和 JavaScript）的 timestamp 使用整数表示毫秒数，
				这种情况下只需要把 timestamp 除以1000就得到 Python 的浮点表示方法。
		timestamp 转换为 datetime：
			要把 timestamp 转换为 datetime，使用 datetime 提供的 fromtimestamp()方法：
				>>> from datetime import datetime
				>>> t = 1429417200.0
				>>> print(datetime.fromtimestamp(t))
			timestamp 是一个浮点数，它没有时区的概念，而 datetime 是有时区的。
				上述转换是在 timestamp 和本地时间做转换。
			timestamp 也可以直接被转换到 UTC 标准时区的时间：
				>>> from datetime import datetime
				>>> t = 1429417200.0
				>>> print(datetime.fromtimestamp(t)) # 本地时间
				2015-04-19 12:20:00
				>>> print(datetime.utcfromtimestamp(t)) # UTC 时间
				2015-04-19 04:20:00
		str 转换为 datetime：
			很多时候用户输入的日期和时间是字符串，要处理日期和时间，首先必须把 str 转换为 datetime。
				转换方法是通过 datetime.strptime()实现，需要一个日期和时间的格式化字符串：
				>>> from datetime import datetime
				>>> cday = datetime.strptime('2015-6-1 18:19:59', '%Y-%m-%d %H:%M:%S')
				2015-06-01 18:19:59
		datetime 转换为 str：
			如果已经有了 datetime 对象，要把它格式化为字符串显示给用户，就需要转换为 str，
				转换方法是通过 strftime()实现的，同样需要一个日期和时间的格式化字符串：
				>>> from datetime import datetime
				>>> now = datetime.now()
				>>> print(now.strftime('%a, %b %d %H:%M'))
				Mon, May 05 16:28
		datetime 加减：
			对日期和时间进行加减实际上就是把 datetime 往后或往前计算，得到新的 datetime。
				加减可以直接用 + 和-运算符，不过需要导入 timedelta 这个类：
				>>> from datetime import datetime, timedelta
				>>> now = datetime.now()
				>>> now
				datetime.datetime(2015, 5, 18, 16, 57, 3, 540997)
				>>> now + timedelta(hours=10)
				datetime.datetime(2015, 5, 19, 2, 57, 3, 540997)
				>>> now - timedelta(days=1)
				datetime.datetime(2015, 5, 17, 16, 57, 3, 540997)
				>>> now + timedelta(days=2, hours=12)
				datetime.datetime(2015, 5, 21, 4, 57, 3, 540997)
		本地时间转换为 UTC 时间：
			本地时间是指系统设定时区的时间，
				例如北京时间是 UTC+8:00时区的时间，而 UTC 时间指 UTC+0:00时区的时间。
			一个 datetime 类型有一个时区属性 tzinfo，但是默认为 None，
				所以无法区分这个 datetime 到底是哪个时区，
				除非强行给 datetime 设置一个时区：
					>>> from datetime import datetime, timedelta, timezone
					>>> tz_utc_8 = timezone(timedelta(hours=8)) # 创建时区 UTC+8:00
					>>> now = datetime.now()
					>>> now
					datetime.datetime(2015, 5, 18, 17, 2, 10, 871012)
					>>> dt = now.replace(tzinfo=tz_utc_8) # 强制设置为 UTC+8:00
					>>> dt
					datetime.datetime(2015, 5, 18, 17, 2, 10, 871012, tzinfo=datetime.timezone(datetime.timedelta(0, 28800)))
				如果系统时区恰好是 UTC+8:00，那么上述代码就是正确的，否则不能强制设置为 UTC+8:00时区。
		时区转换：
			我们可以先通过 utcnow()拿到当前的 UTC 时间，再转换为任意时区的时间：
			时区转换的关键在于，拿到一个 datetime 时，要获知其正确的时区，
				然后强制设置时区，作为基准时间。
			利用带时区的 datetime，通过 astimezone()方法，可以转换到任意时区。
		小结：
			datetime 表示的时间需要时区信息才能确定一个特定的时间，否则只能视为本地时间。
			如果要存储 datetime，最佳方法是将其转换为 timestamp 再存储，因为 timestamp 的值与时区完全无关。
			
	collections：
		Python 内建的一个集合模块，提供了许多有用的集合类。
		namedtuple：
			可以创建一个自定义的 tuple 对象，
			并且规定了 tuple 元素的个数，
			可以用属性而不是索引来引用 tuple 的某个元素。
			它具备 tuple 的不变性，又可以根据属性来引用，使用十分方便。
			例如：
				# namedtuple('名称', [属性 list]):
				Circle = namedtuple('Circle', ['x', 'y', 'r'])
		deque：
			使用 list 存储数据时，按索引访问元素很快，但是插入和删除元素就很慢了，
			因为 list 是线性存储，数据量大的时候，插入和删除效率很低。
			deque 是为了高效实现插入和删除操作的双向列表，适合用于队列和栈：
				除了实现 list 的 append()和 pop()外，
				还支持 appendleft()和 popleft()，
				这样就可以非常高效地往头部添加或删除元素。
		defaultdict：
			使用 dict 时，如果引用的 Key 不存在，就会抛出 KeyError。
			如果希望 key 不存在时，返回一个默认值，就可以用 defaultdict。
			注意默认值是调用函数返回的，而函数在创建 defaultdict 对象时传入。
			除了在 Key 不存在时返回默认值，defaultdict 的其他行为跟 dict 是完全一样的。
		OrderedDict：
			使用 dict 时，Key 是无序的。在对 dict 做迭代时，我们无法确定 Key 的顺序。
			如果要保持 Key 的顺序，可以用 OrderedDict：
			注意：OrderedDict 的 Key 会按照插入的顺序排列，不是 Key 本身排序：
			OrderedDict 可以实现一个 FIFO（先进先出）的 dict，当容量超出限制时，先删除最早添加的 Key。
		ChainMap：
			ChainMap 可以把一组 dict 串起来并组成一个逻辑上的 dict。
			ChainMap 本身也是一个 dict，但是查找的时候，会按照顺序在内部的 dict 依次查找。
			什么时候使用 ChainMap 最合适？
				举个例子：
				应用程序往往都需要传入参数，
				参数可以通过命令行传入，可以通过环境变量传入，还可以有默认参数。
				我们可以用 ChainMap 实现参数的优先级查找，
				即先查命令行参数，如果没有传入，再查环境变量，如果没有，就使用默认参数。
		Counter：
			一个简单的计数器。
			例如：统计字符出现的个数：
				>>> from collections import Counter
				>>> c = Counter()
				>>> for ch in 'programming':
				...     c[ch] = c[ch] + 1
				...
				>>> c
				Counter({'g': 2, 'm': 2, 'r': 2, 'a': 1, 'i': 1, 'o': 1, 'n': 1, 'p': 1})
			Counter 实际上也是 dict 的一个子类。
				上面的结果可以看出，字符'g'、'm'、'r'各出现了两次，其他字符各出现了一次。
		
	Base64：
		是一种用64个字符来表示任意二进制数据的方法。
		Base64编码会把3字节的二进制数据编码为4字节的文本数据，长度增加33%，
		好处是编码后的文本数据可以在邮件正文、网页等直接显示。
		最后会剩下1个或2个字节怎么办？
			Base64用\x00字节在末尾补足后，再在编码的末尾加上1个或2个=号，表示补了多少字节，
			解码的时候，会自动去掉。
		Python 内置的 base64可以直接进行 base64的编解码：
			>>> import base64
			>>> base64.b64encode(b'binary\x00string')
			b'YmluYXJ5AHN0cmluZw=='
			>>> base64.b64decode(b'YmluYXJ5AHN0cmluZw==')
			b'binary\x00string'
		由于标准的 Base64编码后可能出现字符 + 和/，在 URL 中就不能直接作为参数，
		所以又有一种"url safe"的 base64编码，其实就是把字符 + 和/分别变成-和_：
			>>> base64.b64encode(b'i\xb7\x1d\xfb\xef\xff')
			b'abcd++//'
			>>> base64.urlsafe_b64encode(b'i\xb7\x1d\xfb\xef\xff')
			b'abcd--__'
			>>> base64.urlsafe_b64decode('abcd--__')
			b'i\xb7\x1d\xfb\xef\xff'
		还可以自己定义64个字符的排列顺序，这样就可以自定义 Base64编码，
			不过，通常情况下完全没有必要。
		Base64是一种通过查表的编码方法，不能用于加密，即使使用自定义的编码表也不行。
		Base64适用于小段内容的编码，比如数字证书签名、Cookie 的内容等。
		由于=字符也可能出现在 Base64编码中，但=用在 URL、Cookie 里面会造成歧义，
			所以，很多 Base64编码后会把=去掉：
		小结：
			Base64是一种任意二进制到文本字符串的编码方法，
			常用于在 URL、Cookie、网页中传输少量二进制数据。
			
	struct：
		Python 没有专门处理字节的数据类型。但由于 b'str'可以表示字节，所以，字节数组＝二进制 str。
		C 语言中，我们可以很方便地用 struct、union 来处理字节，以及字节和 int，float 的转换。
		在 Python 中，比方说要把一个32位无符号整数变成字节，也就是4个长度的 bytes，
			你得配合位运算符这么写：
				>>> n = 10240099
				>>> b1 = (n & 0xff000000) >> 24
				>>> b2 = (n & 0xff0000) >> 16
				>>> b3 = (n & 0xff00) >> 8
				>>> b4 = n & 0xff
				>>> bs = bytes([b1, b2, b3, b4])
				>>> bs
				b'\x00\x9c@c'
			非常麻烦。如果换成浮点数就无能为力了。
		Python 提供了一个 struct 模块来解决 bytes 和其他二进制数据类型的转换。
		struct 的 pack 函数把任意数据类型变成 bytes：
			>>> import struct
			>>> struct.pack('>I', 10240099)
			b'\x00\x9c@c'
			pack 的第一个参数是处理指令，'>I'的意思是：
				> 表示字节顺序是 big-endian，也就是网络序，
				I 表示4字节无符号整数。
				后面的参数个数要和处理指令一致。
		unpack 把 bytes 变成相应的数据类型：
			>>> struct.unpack('>IH', b'\xf0\xf0\xf0\xf0\x80\x80')
			(4042322160, 32896)
			根据>IH 的说明，后面的 bytes 依次变为
			I：4字节无符号整数
			H：2字节无符号整数。
		Windows 的位图文件（.bmp）是一种非常简单的文件格式，我们来用 struct 分析一下。
			首先找一个 bmp 文件，没有的话用“画图”画一个。
			读入前30个字节来分析：
				>>> s = b'\x42\x4d\x38\x8c\x0a\x00\x00\x00\x00\x00\x36\x00\x00\x00\x28\x00\x00\x00\x80\x02\x00\x00\x68\x01\x00\x00\x01\x00\x18\x00'
			BMP 格式采用小端方式存储数据，文件头的结构按顺序如下：
				两个字节：'BM'表示 Windows 位图，'BA'表示 OS/2位图；
				一个4字节整数：表示位图大小；
				一个4字节整数：保留位，始终为0；
				一个4字节整数：实际图像的偏移量；
				一个4字节整数：Header 的字节数；
				一个4字节整数：图像宽度；
				一个4字节整数：图像高度；
				一个2字节整数：始终为1；
				一个2字节整数：颜色数。
			所以，组合起来用 unpack 读取：
				>>> struct.unpack('<ccIIIIIIHH', s)
				(b'B', b'M', 691256, 0, 54, 40, 640, 360, 1, 24)
			结果显示，b'B'、b'M'说明是 Windows 位图，位图大小为640x360，颜色数为24。
			
	hashlib：
		摘要算法简介：
			摘要算法又称哈希算法、散列算法。
			它通过一个函数，把任意长度的数据转换为一个长度固定的数据串（通常用16进制的字符串表示）。
			通过摘要函数 f()对任意长度的数据 data 计算出固定长度的摘要 digest，
				目的是为了发现原始数据是否被人篡改过。
				因为摘要函数是一个单向函数，计算 f(data)很容易，但通过 digest 反推 data 却非常困难。
				而且，对原始数据做一个 bit 的修改，都会导致计算出的摘要完全不同。
			MD5是最常见的摘要算法，速度很快，
				生成结果是固定的128 bit 字节，通常用一个32位的16进制字符串表示。
			MD5 为例：
				import hashlib
				md5 = hashlib.md5()
				md5.update('how to use md5 in python hashlib?'.encode('utf-8'))
				print(md5.hexdigest())
			如果数据量很大，可以分块多次调用 update()，最后计算的结果是一样的：
				import hashlib
				md5 = hashlib.md5()
				md5.update('how to use md5 in '.encode('utf-8'))
				md5.update('python hashlib?'.encode('utf-8'))
				print(md5.hexdigest())
			SHA1 是另一种常见的摘要算法，
				结果是160 bit 字节，通常用一个40位的16进制字符串表示。
			SHA1 为例，调用 SHA1和调用 MD5完全类似：
				import hashlib
				sha1 = hashlib.sha1()
				sha1.update('how to use sha1 in '.encode('utf-8'))
				sha1.update('python hashlib?'.encode('utf-8'))
				print(sha1.hexdigest())
			比 SHA1更安全的算法是 SHA256和 SHA512，不过越安全的算法不仅越慢，而且摘要长度更长。
		摘要算法应用：
			如果以明文保存用户口令，如果数据库泄露，所有用户的口令就落入黑客的手里。
			此外，网站运维人员是可以访问数据库的，也就是能获取到所有用户的口令。
			正确的保存口令的方式是不存储用户的明文口令，而是存储用户口令的摘要；
			存储 MD5的好处是即使运维人员能访问数据库，也无法获知用户的明文口令。
			由于常用口令的 MD5值很容易被计算出来，
			所以，要确保存储的用户口令不是那些已经被计算出来的常用口令的 MD5，
			这一方法通过对原始口令加一个复杂字符串来实现，俗称“加盐”：
				def calc_md5(password):
					return get_md5(password + 'the-Salt')
			经过 Salt 处理的 MD5口令，只要 Salt 不被黑客知道，
				即使用户输入简单口令，也很难通过 MD5反推明文口令。
			但是如果有两个用户都使用了相同的简单口令比如123456，在数据库中，将存储两条相同的 MD5值，
				这说明这两个用户的口令是一样的。
			有没有办法让使用相同口令的用户存储不同的 MD5呢？
				如果假定用户无法修改登录名，就可以通过把登录名作为 Salt 的一部分来计算 MD5，
				从而实现相同口令的用户也存储不同的 MD5。
			
	hmac
		Hmac 算法：
			Keyed-Hashing for Message Authentication。
			它通过一个标准算法，在计算哈希的过程中，把 key 混入计算过程中。
			和我们自定义的加 salt 算法不同，Hmac 算法针对所有哈希算法都通用，无论是 MD5还是 SHA-1。
			采用 Hmac 替代我们自己的 salt 算法，可以使程序算法更标准化，也更安全。
			Python 自带的 hmac 模块实现了标准的 Hmac 算法。
				hmac 的代码如下：
					>>> import hmac
					>>> message = b'Hello, world!'
					>>> key = b'secret'
					>>> h = hmac.new(key, message, digestmod='MD5')
					>>> # 如果消息很长，可以多次调用 h.update(msg)
					>>> h.hexdigest()
			使用 hmac 和普通 hash 算法非常类似。hmac 输出的长度和原始哈希算法的长度一致。
			需要注意传入的 key 和 message 都是 bytes 类型，str 类型需要首先编码为 bytes。
			
	itertools：
		itertools 提供了非常有用的用于操作迭代对象的函数。
			count()：会创建一个无限的迭代器，所以上述代码会打印出自然数序列，只能按 Ctrl+C 退出；
			cycle()：会把传入的一个序列无限重复下去；
			repeat()：负责把一个元素无限重复下去，不过如果提供第二个参数就可以限定重复次数；
			无限序列只有在 for 迭代时才会无限地迭代下去，
				如果只是创建了一个迭代对象，它不会事先把无限个元素生成出来，
				事实上也不可能在内存中创建无限多个元素。
			无限序列虽然可以无限迭代下去，但是通常我们会通过 takewhile()等函数，
				根据条件判断来截取出一个有限的序列：
					>>> import itertools
					>>> natuals = itertools.count(1)
					>>> ns = itertools.takewhile(lambda x: x <= 10, natuals)
					>>> list(ns)
					[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
		chain()：
			chain()可以把一组迭代对象串联起来，形成一个更大的迭代器：
				>>> for c in itertools.chain('ABC', 'XYZ'):
				...     print(c)
				# 迭代效果：'A' 'B' 'C' 'X' 'Y' 'Z'
		groupby()：
			groupby()把迭代器中相邻的重复元素挑出来放在一起
				>>> for key, group in itertools.groupby('AAABBBCCAAA'):
				...     print(key, list(group))
				...
				A ['A', 'A', 'A']
				B ['B', 'B', 'B']
				C ['C', 'C']
				A ['A', 'A', 'A']
			实际上挑选规则是通过函数完成的，
			只要作用于函数的两个元素返回的值相等，这两个元素就被认为是在一组的，
			而函数返回值作为组的 key。
			如果我们要忽略大小写分组，就可以让元素'A'和'a'都返回相同的 key：
				>>> for key, group in itertools.groupby('AaaBBbcCAAa', lambda c: c.upper()):
				...     print(key, list(group))
				...
				A ['A', 'a', 'a']
				B ['B', 'B', 'b']
				C ['c', 'C']
				A ['A', 'A', 'a']
			
	contextlib：
		并不是只有 open()函数返回的 fp 对象才能使用 with 语句。
		实际上，任何对象，只要正确实现了上下文管理，就可以用于 with 语句。
			实现上下文管理是通过__enter__和__exit__这两个方法实现的。
			class Query(object):
				def __init__(self, name):
					self.name = name
				def __enter__(self):
					print('Begin')
					return self
				def __exit__(self, exc_type, exc_value, traceback):
					if exc_type:
						print('Error')
					else:
						print('End')
				def query(self):
					print('Query info about %s...' % self.name)
		@contextmanager：
			编写__enter__和__exit__仍然很繁琐，因此 Python 的标准库 contextlib 提供了更简单的写法，
			上面的代码可以改写如下：
				from contextlib import contextmanager
				class Query(object):
					def __init__(self, name):
						self.name = name
					def query(self):
						print('Query info about %s...' % self.name)
				@contextmanager
				def create_query(name):
					print('Begin')
					q = Query(name)
					yield q
					print('End')
			@contextmanager 这个 decorator 接受一个 generator，用 yield 语句把 with ... as var 把变量输出出去，
			然后，with 语句就可以正常地工作了。
		@closing
			如果一个对象没有实现上下文，我们就不能把它用于 with 语句。
			这个时候，可以用 closing()来把该对象变为上下文对象。
			closing 也是一个经过 @contextmanager 装饰的 generator，这个 generator 编写起来其实非常简单。
			它的作用就是把任意对象变为上下文对象，并支持 with 语句。
			
	urllib：
		Get：
			urllib 的 request 模块可以非常方便地抓取 URL 内容，
				也就是发送一个 GET 请求到指定的页面，然后返回 HTTP 的响应：
			如果我们要想模拟浏览器发送 GET 请求，就需要使用 Request 对象，
				通过往 Request 对象添加 HTTP 头，我们就可以把请求伪装成浏览器。
		Post：
			如果要以 POST 发送一个请求，只需要把参数 data 以 bytes 形式传入。
		Handler：
			如果还需要更复杂的控制，比如通过一个 Proxy 去访问网站，我们需要利用 ProxyHandler 来处理。
		小结
			urllib 提供的功能就是利用程序去执行各种 HTTP 请求。
			如果要模拟浏览器完成特定功能，需要把请求伪装成浏览器。
			伪装的方法是先监控浏览器发出的请求，再根据浏览器的请求头来伪装，
			User-Agent 头就是用来标识浏览器的。
			
	XML：
		DOM vs SAX：
			DOM：会把整个 XML 读入内存，解析为树，因此占用内存大，解析慢，优点是可以任意遍历树的节点。
			SAX：是流模式，边读边解析，占用内存小，解析快，缺点是我们需要自己处理事件。	
		用 SAX 解析 XML 非常简洁，通常我们关心的事件是 start_element，end_element 和 char_data，
			准备好这3个函数，然后就可以解析 xml 了。
			需要注意的是读取一大段字符串时，CharacterDataHandler 可能被多次调用，
			所以需要自己保存起来，在 EndElementHandler 里面再合并。
		除了解析 XML 外，如何生成 XML 呢？
			99%的情况下需要生成的 XML 结构都是非常简单的，最简单也是最有效的生成 XML 的方法是拼接字符串。
				L = []
				L.append(r'<?xml version="1.0"?>')
				L.append(r'<root>')
				L.append(encode('some & data'))
				L.append(r'</root>')
				return ''.join(L)
		如果要生成复杂的 XML 呢？建议你不要用 XML，改成 JSON。
			
	HTMLParser：
		feed()方法可以多次调用，也就是不一定一次把整个 HTML 字符串都塞进去，可以一部分一部分塞进去。
		特殊字符有两种，一种是英文表示的&nbsp;，一种是数字表示的&#1234;，
			这两种字符都可以通过 Parser 解析出来。
			
常用第三方模块：
	Pillow：
		PIL：Python Imaging Library，已经是 Python 平台事实上的图像处理标准库了。
			PIL 功能非常强大，但 API 却非常简单易用。
		由于 PIL 仅支持到 Python 2.7，加上年久失修，于是一群志愿者在 PIL 的基础上创建了兼容的版本，
		名字叫 Pillow，支持最新 Python 3.x，又加入了许多新特性，因此，我们可以直接安装使用 Pillow。
		操作图像：
			来看看最常见的图像缩放操作，只需三四行代码：
				from PIL import Image
				# 打开一个 jpg 图像文件，注意是当前路径:
				im = Image.open('test.jpg')
				# 获得图像尺寸:
				w, h = im.size
				print('Original image size: %sx%s' % (w, h))
				# 缩放到50%:
				im.thumbnail((w//2, h//2))
				print('Resize image to: %sx%s' % (w//2, h//2))
				# 把缩放后的图像用 jpeg 格式保存:
				im.save('thumbnail.jpg', 'jpeg')
			其他功能如切片、旋转、滤镜、输出文字、调色板等一应俱全。
			比如，模糊效果也只需几行代码：
				from PIL import Image, ImageFilter
				# 打开一个 jpg 图像文件，注意是当前路径:
				im = Image.open('test.jpg')
				# 应用模糊滤镜:
				im2 = im.filter(ImageFilter.BLUR)
				im2.save('blur.jpg', 'jpeg')
			PIL 的 ImageDraw 提供了一系列绘图方法，让我们可以直接绘图。比如要生成字母验证码图片：
				from PIL import Image, ImageDraw, ImageFont, ImageFilter
				import random
				# 随机字母:
				def rndChar():
					return chr(random.randint(65, 90))
				# 随机颜色1:
				def rndColor():
					return (random.randint(64, 255), random.randint(64, 255), random.randint(64, 255))
				# 随机颜色2:
				def rndColor2():
					return (random.randint(32, 127), random.randint(32, 127), random.randint(32, 127))
				# 240 x 60:
				width = 60 * 4
				height = 60
				image = Image.new('RGB', (width, height), (255, 255, 255))
				# 创建 Font 对象:
				font = ImageFont.truetype('Arial.ttf', 36)
				# 创建 Draw 对象:
				draw = ImageDraw.Draw(image)
				# 填充每个像素:
				for x in range(width):
					for y in range(height):
						draw.point((x, y), fill=rndColor())
				# 输出文字:
				for t in range(4):
					draw.text((60 * t + 10, 10), rndChar(), font=font, fill=rndColor2())
				# 模糊:
				image = image.filter(ImageFilter.BLUR)
				image.save('code.jpg', 'jpeg')
			我们用随机颜色填充背景，再画上文字，最后对图像进行模糊，得到验证码图片；
			如果运行的时候报错：
				IOError: cannot open resource
			这是因为 PIL 无法定位到字体文件的位置，可以根据操作系统提供绝对路径，比如：
				'/Library/Fonts/Arial.ttf'
			
	requests：
		urllib 模块用于访问网络资源。但是，它用起来比较麻烦，而且，缺少很多实用的高级功能。
		更好的方案是使用 requests。它是一个 Python 第三方库，处理 URL 资源特别方便。
			要通过 GET 访问一个页面，只需要几行代码：
				>>> import requests
				>>> r = requests.get('https://www.douban.com/') # 豆瓣首页
				>>> r.status_code
				>>> r.text
			对于带参数的 URL，传入一个 dict 作为 params 参数：
				>>> r = requests.get('https://www.douban.com/search', params={'q': 'python', 'cat': '1001'})
				>>> r.url # 实际请求的 URL
			requests 自动检测编码，可以使用 encoding 属性查看：
				>>> r.encoding
			无论响应是文本还是二进制内容，我们都可以用 content 属性获得 bytes 对象：
				>>> r.content
			requests 的方便之处还在于，对于特定类型的响应，例如 JSON，可以直接获取：
				>>> r = requests.get('https://query.yahooapis.com/v1/public/yql?q=select%20*%20from%20weather.forecast%20where%20woeid%20%3D%202151330&format=json')
				>>> r.json()
			需要传入 HTTP Header 时，我们传入一个 dict 作为 headers 参数：
				>>> r = requests.get('https://www.douban.com/', headers={'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit'})
				>>> r.text
			要发送 POST 请求，只需要把 get()方法变成 post()，然后传入 data 参数作为 POST 请求的数据：
				>>> r = requests.post('https://accounts.douban.com/login', data={'form_email': 'abc@example.com', 'form_password': '123456'})
			requests 默认使用 application/x-www-form-urlencoded 对 POST 数据编码。
			如果要传递 JSON 数据，可以直接传入 json 参数：
				params = {'key': 'value'}
				r = requests.post(url, json=params) # 内部自动序列化为 JSON
			类似的，上传文件需要更复杂的编码格式，但是 requests 把它简化成 files 参数：
				>>> upload_files = {'file': open('report.xls', 'rb')}
				>>> r = requests.post(url, files=upload_files)
			在读取文件时，注意务必使用'rb'即二进制模式读取，这样获取的 bytes 长度才是文件的长度。
			把 post()方法替换为 put()，delete()等，就可以以 PUT 或 DELETE 方式请求资源。
			除了能轻松获取响应内容外，requests 对获取 HTTP 响应的其他信息也非常简单。例如，获取响应头：
				>>> r.headers
				{Content-Type': 'text/html; charset=utf-8', 'Transfer-Encoding': 'chunked', 'Content-Encoding': 'gzip', ...}
				>>> r.headers['Content-Type']
				'text/html; charset=utf-8'
			requests 对 Cookie 做了特殊处理，使得我们不必解析 Cookie 就可以轻松获取指定的 Cookie：
				>>> r.cookies['ts']
				'example_cookie_12345'
			要在请求中传入 Cookie，只需准备一个 dict 传入 cookies 参数：
				>>> cs = {'token': '12345', 'status': 'working'}
				>>> r = requests.get(url, cookies=cs)
			最后，要指定超时，传入以秒为单位的 timeout 参数：
				>>> r = requests.get(url, timeout=2.5) # 2.5秒后超时
	chardet：
		字符串编码一直是令人非常头疼的问题，尤其是我们在处理一些不规范的第三方网页的时候。
		虽然 Python 提供了 Unicode 表示的 str 和 bytes 两种数据类型，并且可以通过 encode()和 decode()方法转换，
		但是在不知道编码的情况下，对 bytes 做 decode()不好做。
		对于未知编码的 bytes，要把它转换成 str，需要先“猜测”编码。
		猜测的方式是先收集各种编码的特征字符，根据特征字符判断，就能有很大概率“猜对”。
		chardet 用来检测编码，简单易用。
		使用 chardet：
			当我们拿到一个 bytes 时，就可以对其检测编码。用 chardet 检测编码，只需要一行代码：
				>>> chardet.detect(b'Hello, world!')
				{'encoding': 'ascii', 'confidence': 1.0, 'language': ''}
			检测出的编码是 ascii，注意到还有个 confidence 字段，表示检测的概率是1.0（即100%）。
			我们来试试检测 GBK 编码的中文：
				>>> data = '离离原上草，一岁一枯荣'.encode('gbk')
				>>> chardet.detect(data)
				{'encoding': 'GB2312', 'confidence': 0.7407407407407407, 'language': 'Chinese'}
			检测的编码是 GB2312，注意到 GBK 是 GB2312的超集，两者是同一种编码，检测正确的概率是74%。
			对 UTF-8编码进行检测：
				>>> data = '离离原上草，一岁一枯荣'.encode('utf-8')
				>>> chardet.detect(data)
				{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}
			
	psutil：
		psutil = process and system utilities，
		它不仅可以通过一两行代码实现系统监控，还可以跨平台使用，支持 Linux／UNIX／OSX／Windows 等，
		是系统管理员和运维小伙伴不可或缺的必备模块。
		获取 CPU 信息
			我们先来获取 CPU 的信息：
				>>> import psutil
				>>> psutil.cpu_count() # CPU 逻辑数量
				4
				>>> psutil.cpu_count(logical=False) # CPU 物理核心
				2
				# 2说明是双核超线程, 4则是4核非超线程
			统计 CPU 的用户／系统／空闲时间：
				>>> psutil.cpu_times()
				scputimes(user=10963.31, nice=0.0, system=5138.67, idle=356102.45)
			再实现类似 top 命令的 CPU 使用率，每秒刷新一次，累计10次：
				>>> for x in range(10):
				...     psutil.cpu_percent(interval=1, percpu=True)
				... 
				[14.0, 4.0, 4.0, 4.0]
				[12.0, 3.0, 4.0, 3.0]
				[8.0, 4.0, 3.0, 4.0]
				[12.0, 3.0, 3.0, 3.0]
				[18.8, 5.1, 5.9, 5.0]
				[10.9, 5.0, 4.0, 3.0]
				[12.0, 5.0, 4.0, 5.0]
				[15.0, 5.0, 4.0, 4.0]
				[19.0, 5.0, 5.0, 4.0]
				[9.0, 3.0, 2.0, 3.0]
		获取内存信息
			使用 psutil 获取物理内存和交换内存信息，分别使用：
				>>> psutil.virtual_memory()
				svmem(total=8589934592, available=2866520064, percent=66.6, used=7201386496, free=216178688, active=3342192640, inactive=2650341376, wired=1208852480)
				>>> psutil.swap_memory()
				sswap(total=1073741824, used=150732800, free=923009024, percent=14.0, sin=10705981440, sout=40353792)
			返回的是字节为单位的整数，总内存大小是8589934592 = 8 GB，已用7201386496 = 6.7 GB，使用了66.6%。
			而交换区大小是1073741824 = 1 GB。
		获取磁盘信息
			可以通过 psutil 获取磁盘分区、磁盘使用率和磁盘 IO 信息：
				>>> psutil.disk_partitions() # 磁盘分区信息
				[sdiskpart(device='/dev/disk1', mountpoint='/', fstype='hfs', opts='rw,local,rootfs,dovolfs,journaled,multilabel')]
				>>> psutil.disk_usage('/') # 磁盘使用情况
				sdiskusage(total=998982549504, used=390880133120, free=607840272384, percent=39.1)
				>>> psutil.disk_io_counters() # 磁盘 IO
				sdiskio(read_count=988513, write_count=274457, read_bytes=14856830464, write_bytes=17509420032, read_time=2228966, write_time=1618405)
			磁盘'/'的总容量是998982549504 = 930 GB，使用了39.1%。文件格式是 HFS，opts 中包含 rw 表示可读写，journaled 表示支持日志。
		获取网络信息
			psutil 可以获取网络接口和网络连接信息：
				>>> psutil.net_io_counters() # 获取网络读写字节／包的个数
				snetio(bytes_sent=3885744870, bytes_recv=10357676702, packets_sent=10613069, packets_recv=10423357, errin=0, errout=0, dropin=0, dropout=0)
				>>> psutil.net_if_addrs() # 获取网络接口信息
				{
				  'lo0': [snic(family=<AddressFamily.AF_INET: 2>, address='127.0.0.1', netmask='255.0.0.0'), ...],
				  'en1': [snic(family=<AddressFamily.AF_INET: 2>, address='10.0.1.80', netmask='255.255.255.0'), ...],
				  'en0': [...],
				  'en2': [...],
				  'bridge0': [...]
				}
				>>> psutil.net_if_stats() # 获取网络接口状态
				{
				  'lo0': snicstats(isup=True, duplex=<NicDuplex.NIC_DUPLEX_UNKNOWN: 0>, speed=0, mtu=16384),
				  'en0': snicstats(isup=True, duplex=<NicDuplex.NIC_DUPLEX_UNKNOWN: 0>, speed=0, mtu=1500),
				  'en1': snicstats(...),
				  'en2': snicstats(...),
				  'bridge0': snicstats(...)
				}
			要获取当前网络连接信息，使用 net_connections()：
				>>> psutil.net_connections()
				Traceback (most recent call last):
				  ...
				PermissionError: [Errno 1] Operation not permitted
				During handling of the above exception, another exception occurred:
				Traceback (most recent call last):
				  ...
				psutil.AccessDenied: psutil.AccessDenied (pid=3847)
			你可能会得到一个 AccessDenied 错误，原因是 psutil 获取信息也是要走系统接口，
			而获取网络连接信息需要 root 权限，这种情况下，可以退出 Python 交互环境，用 sudo 重新启动：
				$ sudo python3
				Password: ******
				Python 3.6.3 ... on darwin
				Type "help", ... for more information.
				>>> import psutil
				>>> psutil.net_connections()
				[
					sconn(fd=83, family=<AddressFamily.AF_INET6: 30>, type=1, laddr=addr(ip='::127.0.0.1', port=62911), raddr=addr(ip='::127.0.0.1', port=3306), status='ESTABLISHED', pid=3725),
					sconn(fd=84, family=<AddressFamily.AF_INET6: 30>, type=1, laddr=addr(ip='::127.0.0.1', port=62905), raddr=addr(ip='::127.0.0.1', port=3306), status='ESTABLISHED', pid=3725),
					sconn(fd=93, family=<AddressFamily.AF_INET6: 30>, type=1, laddr=addr(ip='::', port=8080), raddr=(), status='LISTEN', pid=3725),
					sconn(fd=103, family=<AddressFamily.AF_INET6: 30>, type=1, laddr=addr(ip='::127.0.0.1', port=62918), raddr=addr(ip='::127.0.0.1', port=3306), status='ESTABLISHED', pid=3725),
					sconn(fd=105, family=<AddressFamily.AF_INET6: 30>, type=1, ..., pid=3725),
					sconn(fd=106, family=<AddressFamily.AF_INET6: 30>, type=1, ..., pid=3725),
					sconn(fd=107, family=<AddressFamily.AF_INET6: 30>, type=1, ..., pid=3725),
					...
					sconn(fd=27, family=<AddressFamily.AF_INET: 2>, type=2, ..., pid=1)
				]
		获取进程信息
			通过 psutil 可以获取到所有进程的详细信息：
				>>> psutil.pids() # 所有进程 ID
				[3865, 3864, 3863, 3856, 3855, 3853, 3776, ..., 45, 44, 1, 0]
				>>> p = psutil.Process(3776) # 获取指定进程 ID=3776，其实就是当前 Python 交互环境
				>>> p.name() # 进程名称
				'python3.6'
				>>> p.exe() # 进程 exe 路径
				'/Users/michael/anaconda3/bin/python3.6'
				>>> p.cwd() # 进程工作目录
				'/Users/michael'
				>>> p.cmdline() # 进程启动的命令行
				['python3']
				>>> p.ppid() # 父进程 ID
				3765
				>>> p.parent() # 父进程
				<psutil.Process(pid=3765, name='bash') at 4503144040>
				>>> p.children() # 子进程列表
				[]
				>>> p.status() # 进程状态
				'running'
				>>> p.username() # 进程用户名
				'michael'
				>>> p.create_time() # 进程创建时间
				1511052731.120333
				>>> p.terminal() # 进程终端
				'/dev/ttys002'
				>>> p.cpu_times() # 进程使用的 CPU 时间
				pcputimes(user=0.081150144, system=0.053269812, children_user=0.0, children_system=0.0)
				>>> p.memory_info() # 进程使用的内存
				pmem(rss=8310784, vms=2481725440, pfaults=3207, pageins=18)
				>>> p.open_files() # 进程打开的文件
				[]
				>>> p.connections() # 进程相关网络连接
				[]
				>>> p.num_threads() # 进程的线程数量
				1
				>>> p.threads() # 所有线程信息
				[pthread(id=1, user_time=0.090318, system_time=0.062736)]
				>>> p.environ() # 进程环境变量
				{'SHELL': '/bin/bash', 'PATH': '/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:...', 'PWD': '/Users/michael', 'LANG': 'zh_CN.UTF-8', ...}
				>>> p.terminate() # 结束进程
				Terminated: 15 <-- 自己把自己结束了
			和获取网络连接类似，获取一个 root 用户的进程需要 root 权限，
			启动 Python 交互环境或者.py 文件时，需要 sudo 权限。
			psutil 还提供了一个 test()函数，可以模拟出 ps 命令的效果：
				$ sudo python3
				Password: ******
				Python 3.6.3 ... on darwin
				Type "help", ... for more information.
				>>> import psutil
				>>> psutil.test()
				USER         PID %MEM     VSZ     RSS TTY           START    TIME  COMMAND
				root           0 24.0 74270628 2016380 ?             Nov18   40:51  kernel_task
				root           1  0.1 2494140    9484 ?             Nov18   01:39  launchd
				root          44  0.4 2519872   36404 ?             Nov18   02:02  UserEventAgent
				root          45    ? 2474032    1516 ?             Nov18   00:14  syslogd
				root          47  0.1 2504768    8912 ?             Nov18   00:03  kextd
				root          48  0.1 2505544    4720 ?             Nov18   00:19  fseventsd
				_appleeven    52  0.1 2499748    5024 ?             Nov18   00:00  appleeventsd
				root          53  0.1 2500592    6132 ?             Nov18   00:02  configd
				...
			
virtualenv
	为一个应用创建一套“隔离”的 Python 运行环境。
		第一步，创建目录：
			Mac:~ michael$ mkdir myproject
			Mac:~ michael$ cd myproject/
			Mac:myproject michael$
		第二步，创建一个独立的 Python 运行环境，命名为 venv：
			Mac:myproject michael$ virtualenv --no-site-packages venv
			Using base prefix '/usr/local/.../Python.framework/Versions/3.4'
			New python executable in venv/bin/python3.4
			Also creating executable in venv/bin/python
			Installing setuptools, pip, wheel...done.
			命令 virtualenv 就可以创建一个独立的 Python 运行环境，我们还加上了参数--no-site-packages，
			已经安装到系统 Python 环境中的所有第三方包都不会复制过来，
			我们就得到了一个不带任何第三方包的“干净”的 Python 运行环境。
			新建的 Python 环境被放到当前目录下的 venv 目录。
			有了 venv 这个 Python 环境，可以用 source 进入该环境：
				Mac:myproject michael$ source venv/bin/activate
				(venv)Mac:myproject michael$
			在 venv 环境下，用 pip 安装的包都被安装到 venv 这个环境下，系统 Python 环境不受任何影响。
			也就是说，venv 环境是专门针对 myproject 这个应用创建的。
			退出当前的 venv 环境，使用 deactivate 命令：
				(venv)Mac:myproject michael$ deactivate 
				Mac:myproject michael$
			此时就回到了正常的环境，现在 pip 或 python 均是在系统 Python 环境下执行。
	原理：把系统 Python 复制一份到 virtualenv 的环境，
		用命令 source venv/bin/activate 进入一个 virtualenv 环境时，
		virtualenv 会修改相关环境变量，让命令 python 和 pip 均指向当前的 virtualenv 环境。
			
图形界面：
	Tkinter：
		Python 自带的库。
		我们编写的 Python 代码会调用内置的 Tkinter，Tkinter 封装了访问 Tk 的接口；
			Tk 是一个图形库，支持多个操作系统，使用 Tcl 语言开发；
			Tk 会调用操作系统提供的本地 GUI 接口，完成最终的 GUI。
			所以，我们的代码只需要调用 Tkinter 提供的接口就可以了。
						
			在 GUI 中，每个 Button、Label、输入框等，都是一个 Widget。
			Frame 则是可以容纳其他 Widget 的 Widget，所有的 Widget 组合起来就是一棵树。
			pack()方法把 Widget 加入到父容器中，并实现布局。
			pack()是最简单的布局，grid()可以实现更复杂的布局。

			在 createWidgets()方法中，我们创建一个 Label 和一个 Button，
			当 Button 被点击时，触发 self.quit()使程序退出。
		小结
			Python 内置的 Tkinter 可以满足基本的 GUI 程序的要求，
			如果是非常复杂的 GUI 程序，建议用操作系统原生支持的语言和库来编写。
			
网络编程：
	TCP/IP 简介：
		互联网协议簇（Internet Protocol Suite）：通用协议标准。
		Internet 是由 inter 和 net 两个单词组合起来的，原意就是连接“网络”的网络，
		有了 Internet，任何私有网络，只要支持这个协议，就可以联入互联网。
		互联网上每个计算机的唯一标识就是 IP 地址，类似123.123.123.123。
			IP 地址对应的实际上是计算机的网络接口，通常是网卡。
			IP 协议负责把数据从一台计算机通过网络发送到另一台计算机。
			数据被分割成一小块一小块，然后通过 IP 包发送出去。
			由于互联网链路复杂，两台计算机之间经常有多条线路，
			因此，路由器就负责决定如何把一个 IP 包转发出去。
			IP 包的特点是按块发送，途径多个路由，但不保证能到达，也不保证顺序到达。
			IP 地址实际上是一个32位整数（称为 IPv4），以字符串表示的 IP 地址如192.168.0.1，
				实际上是把32位整数按8位分组后的数字表示，目的是便于阅读。
			IPv6地址实际上是一个128位整数，它是目前使用的 IPv4的升级版，
				以字符串表示类似于2001:0db8:85a3:0042:1000:8a2e:0370:7334。
		TCP 协议则是建立在 IP 协议之上的。
			TCP 协议负责在两台计算机之间建立可靠连接，保证数据包按顺序到达。
			TCP 协议会通过握手建立连接，然后，对每个 IP 包编号，确保对方按顺序收到，
			如果包丢掉了，就自动重发。
			许多常用的更高级的协议都是建立在 TCP 协议基础上的，
				比如用于浏览器的 HTTP 协议、发送邮件的 SMTP 协议等。
			一个 TCP 报文除了包含要传输的数据外，还包含源 IP 地址和目标 IP 地址，源端口和目标端口。
		端口有什么作用？
			在两台计算机通信时，只发 IP 地址是不够的，因为同一台计算机上跑着多个网络程序。
			一个 TCP 报文来了之后，到底是交给浏览器还是 QQ，就需要端口号来区分。
			每个网络程序都向操作系统申请唯一的端口号，
			两个进程在两台计算机之间建立网络连接就需要各自的 IP 地址和各自的端口号。
			一个进程也可能同时与多个计算机建立链接，因此它会申请很多端口。
	TCP 编程：
		Socket 是网络编程的一个抽象概念。
		通常我们用一个 Socket 表示“打开了一个网络链接”，
			而打开一个 Socket 需要知道目标计算机的 IP 地址和端口号，再指定协议类型即可。
		客户端
			大多数连接都是可靠的 TCP 连接。
			创建 TCP 连接时，主动发起连接的叫客户端，被动响应连接的叫服务器。
			我们要创建一个基于 TCP 连接的 Socket，可以这样做：
				# 导入 socket 库:
				import socket
				# 创建一个 socket:
				s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
				# 建立连接:
				s.connect(('www.sina.com.cn', 80))
			创建 Socket 时，AF_INET 指定使用 IPv4协议，
			如果要用更先进的 IPv6，就指定为 AF_INET6。
			SOCK_STREAM 指定使用面向流的 TCP 协议，一个 Socket 对象就创建成功，但是还没有建立连接。
				客户端要主动发起 TCP 连接，必须知道服务器的 IP 地址和端口号。
				提供网页服务的服务器必须把端口号固定在80端口，因为80端口是 Web 服务的标准端口。
				其他服务都有对应的标准端口号，例如 SMTP 服务是25端口，FTP 服务是21端口，等等。
				端口号小于1024的是 Internet 标准服务的端口，端口号大于1024的，可以任意使用。
			TCP 连接创建的是双向通道，双方都可以同时给对方发数据。
			但是谁先发谁后发，怎么协调，要根据具体的协议来决定。
			例如，HTTP 协议规定客户端必须先发请求给服务器，服务器收到后才发数据给客户端。
		服务器
			和客户端编程相比，服务器编程就要复杂一些。
			服务器进程首先要绑定一个端口并监听来自其他客户端的连接。
			如果某个客户端连接过来了，服务器就与该客户端建立 Socket 连接，
				随后的通信就靠这个 Socket 连接了。
				所以，服务器会打开固定端口（比如80）监听，每来一个客户端连接，就创建该 Socket 连接。
			由于服务器会有大量来自客户端的连接，服务器要能够区分一个 Socket 连接是和哪个客户端绑定的。
				一个 Socket 依赖4项：服务器地址、服务器端口、客户端地址、客户端端口来唯一确定一个 Socket。
			但是服务器还需要同时响应多个客户端的请求，每个连接都需要一个新的进程或者新的线程来处理，
				否则服务器一次就只能服务一个客户端了。
			小于1024的端口号必须要有管理员权限才能绑定。
	UDP 编程：
		TCP 是建立可靠连接，并且通信双方都可以以流的形式发送数据。相对 TCP，UDP 则是面向无连接的协议。
		使用 UDP 协议时，不需要建立连接，只需要知道对方的 IP 地址和端口号，就可以直接发数据包。
			但是，能不能到达就不知道了。
		虽然用 UDP 传输数据不可靠，但它的优点是和 TCP 比，速度快，
			对于不要求可靠到达的数据，就可以使用 UDP 协议。
			
访问数据库：
	SQLite 使用：
		一种嵌入式数据库，它的数据库就是一个文件。
		由于 SQLite 本身是 C 写的，而且体积很小，
			所以，经常被集成到各种应用程序中，甚至在 iOS 和 Android 的 App 中都可以集成。
		Python 就内置了 SQLite3，所以，在 Python 中使用 SQLite，不需要安装任何东西，直接使用。
		数据库概念：
			表是数据库中存放关系数据的集合，一个数据库里面通常都包含多个表；
			要操作关系数据库，首先需要连接到数据库，一个数据库连接称为 Connection；
			连接到数据库后，需要打开游标，称之为 Cursor，通过 Cursor 执行 SQL 语句，然后，获得执行结果。
		Python 定义了一套操作数据库的 API 接口，
			任何数据库要连接到 Python，只需要提供符合 Python 标准的数据库驱动即可。
			由于 SQLite 的驱动内置在 Python 标准库中，所以我们可以直接来操作 SQLite 数据库。
		创建表：
			# 导入 SQLite 驱动:
			>>> import sqlite3
			# 连接到 SQLite 数据库
			# 数据库文件是 test.db
			# 如果文件不存在，会自动在当前目录创建:
			>>> conn = sqlite3.connect('test.db')
			# 创建一个 Cursor:
			>>> cursor = conn.cursor()
			# 执行一条 SQL 语句，创建 user 表:
			>>> cursor.execute('create table user (id varchar(20) primary key, name varchar(20))')
			<sqlite3.Cursor object at 0x10f8aa260>
			# 继续执行一条 SQL 语句，插入一条记录:
			>>> cursor.execute('insert into user (id, name) values (\'1\', \'Michael\')')
			<sqlite3.Cursor object at 0x10f8aa260>
			# 通过 rowcount 获得插入的行数:
			>>> cursor.rowcount
			1
			# 关闭 Cursor:
			>>> cursor.close()
			# 提交事务:
			>>> conn.commit()
			# 关闭 Connection:
			>>> conn.close()
		查询记录：
			>>> conn = sqlite3.connect('test.db')
			>>> cursor = conn.cursor()
			# 执行查询语句:
			>>> cursor.execute('select * from user where id=?', ('1',))
			<sqlite3.Cursor object at 0x10f8aa340>
			# 获得查询结果集:
			>>> values = cursor.fetchall()
			>>> values
			[('1', 'Michael')]
			>>> cursor.close()
			>>> conn.close()
		使用 Python 的 DB-API 时，只要搞清楚 Connection 和 Cursor 对象，打开后一定记得关闭，就可以放心地使用。
		使用 Cursor 对象执行 insert，update，delete 语句时，执行结果由 rowcount 返回影响的行数。
		使用 Cursor 对象执行 select 语句时，通过 featchall()可以拿到结果集。
			结果集是一个 list，每个元素都是一个 tuple，对应一行记录。
		如果 SQL 语句带有参数，那么需要把参数按照位置传递给 execute()方法，有几个? 占位符就必须对应几个参数
	MySQL 使用：
		MySQL 内部有多种数据库引擎，最常用的引擎是支持数据库事务的 InnoDB。
		例如：
			# 导入 MySQL 驱动:
			>>> import mysql.connector
			# 注意把 password 设为你的 root 口令:
			>>> conn = mysql.connector.connect(user='root', password='password', database='test')
			>>> cursor = conn.cursor()
			# 创建 user 表:
			>>> cursor.execute('create table user (id varchar(20) primary key, name varchar(20))')
			# 插入一行记录，注意 MySQL 的占位符是%s:
			>>> cursor.execute('insert into user (id, name) values (%s, %s)', ['1', 'Michael'])
			>>> cursor.rowcount
			1
			# 提交事务:
			>>> conn.commit()
			>>> cursor.close()
			# 运行查询:
			>>> cursor = conn.cursor()
			>>> cursor.execute('select * from user where id = %s', ('1',))
			>>> values = cursor.fetchall()
			>>> values
			[('1', 'Michael')]
			# 关闭 Cursor 和 Connection:
			>>> cursor.close()
			True
			>>> conn.close()
		小结：
			由于 Python 的 DB-API 定义都是通用的，所以，操作 MySQL 的数据库代码和 SQLite 类似。
			执行 INSERT 等操作后要调用 commit()提交事务；
			MySQL 的 SQL 占位符是%s。
	SQLAlchemy ：
		ORM 技术：Object-Relational Mapping，把关系数据库的表结构映射到对象上。
			Python 中，最有名的 ORM 框架是 SQLAlchemy。
		第一步，导入 SQLAlchemy，并初始化 DBSession：
			# 导入:
			from sqlalchemy import Column, String, create_engine
			from sqlalchemy.orm import sessionmaker
			from sqlalchemy.ext.declarative import declarative_base
			# 创建对象的基类:
			Base = declarative_base()
			# 定义 User 对象:
			class User(Base):
				# 表的名字:
				__tablename__ = 'user'
				# 表的结构:
				id = Column(String(20), primary_key=True)
				name = Column(String(20))
			# 初始化数据库连接:
			engine = create_engine('mysql+mysqlconnector://root:password@localhost:3306/test')
			# 创建 DBSession 类型:
			DBSession = sessionmaker(bind=engine)
		以上代码完成 SQLAlchemy 的初始化和具体每个表的 class 定义。
		如果有多个表，就继续定义其他 class，例如 School：
			class School(Base):
				__tablename__ = 'school'
				id = ...
				name = ...
		create_engine()用来初始化数据库连接。SQLAlchemy 用一个字符串表示连接信息：
			'数据库类型 + 数据库驱动名称://用户名:口令 @机器地址:端口号/数据库名'
		你只需要根据需要替换掉用户名、口令等信息即可。
		下面，我们看看如何向数据库表中添加一行记录。
		由于有了 ORM，我们向数据库表中添加一行记录，可以视为添加一个 User 对象：
			# 创建 session 对象:
			session = DBSession()
			# 创建新 User 对象:
			new_user = User(id='5', name='Bob')
			# 添加到 session:
			session.add(new_user)
			# 提交即保存到数据库:
			session.commit()
			# 关闭 session:
			session.close()
		可见，关键是获取 session，然后把对象添加到 session，最后提交并关闭。
			DBSession 对象可视为当前数据库连接。
		如何从数据库表中查询数据呢？有了 ORM，查询出来的可以不再是 tuple，而是 User 对象。
		SQLAlchemy 提供的查询接口如下：
			# 创建 Session:
			session = DBSession()
			# 创建 Query 查询，filter 是 where 条件，最后调用 one()返回唯一行，如果调用 all()则返回所有行:
			user = session.query(User).filter(User.id=='5').one()
			# 打印类型和对象的 name 属性:
			print('type:', type(user))
			print('name:', user.name)
			# 关闭 Session:
			session.close()
		运行结果如下：
			type: <class '__main__.User'>
			name: Bob
		可见，ORM 就是把数据库表的行与相应的对象建立关联，互相转换。
		由于关系数据库的多个表还可以用外键实现一对多、多对多等关联，
			相应地，ORM 框架也可以提供两个对象之间的一对多、多对多等功能。
		例如，如果一个 User 拥有多个 Book，就可以定义一对多关系如下：
			class User(Base):
				__tablename__ = 'user'
				id = Column(String(20), primary_key=True)
				name = Column(String(20))
				# 一对多:
				books = relationship('Book')
			class Book(Base):
				__tablename__ = 'book'
				id = Column(String(20), primary_key=True)
				name = Column(String(20))
				# “多”的一方的 book 表是通过外键关联到 user 表的:
				user_id = Column(String(20), ForeignKey('user.id'))
		当我们查询一个 User 对象时，该对象的 books 属性将返回一个包含若干个 Book 对象的 list。
		小结：
			ORM 框架的作用就是把数据库表的一行记录与一个对象互相做自动转换。
			正确使用 ORM 的前提是了解关系数据库的原理。
				
Web 开发：
	HTTP 协议简介：
		HTTP 是在网络上传输 HTML 的协议，用于浏览器和服务器的通信。
		HTML 是一种用来定义网页的文本，会 HTML，就可以编写网页；
		HTTP 请求：
			HTTP 请求的流程：
				步骤1：浏览器首先向服务器发送 HTTP 请求，请求包括：
					方法：GET 还是 POST，GET 仅请求资源，POST 会附带用户数据；
					路径：/full/url/path；
					域名：由 Host 头指定：Host: www.sina.com.cn
					以及其他相关的 Header；
					如果是 POST，那么请求还包括一个 Body，包含用户数据。
				步骤2：服务器向浏览器返回 HTTP 响应，响应包括：
					响应代码：200表示成功，3xx 表示重定向，4xx 表示客户端发送的请求有错误，
						5xx 表示服务器端处理时发生了错误；
					响应类型：由 Content-Type 指定；
					以及其他相关的 Header；
					通常服务器的 HTTP 响应会携带内容，也就是有一个 Body，包含响应的内容，
						网页的 HTML 源码就在 Body 中。
				步骤3：如果浏览器还需要继续向服务器请求其他资源，
					比如图片，就再次发出 HTTP 请求，重复步骤1、2。
			Web 采用的 HTTP 协议采用了非常简单的请求-响应模式，从而大大简化了开发。
				编写一个页面时，只需要在 HTTP 请求中把 HTML 发送出去，不需要考虑如何附带图片、视频等，
				浏览器如果需要请求图片和视频，它会发送另一个 HTTP 请求，
				因此，一个 HTTP 请求只处理一个资源。
			HTTP 协议同时具备极强的扩展性，虽在浏览器请求 HTML 中可以链入其他服务器的资源，
				比如<img src="">，从而将请求压力分散到各个服务器上，
				并且，一个站点可以链接到其他站点，无数个站点互相链接起来，就形成了 World Wide Web，简称 WWW。
		HTTP 格式：
			每个 HTTP 请求和响应都遵循相同的格式，一个 HTTP 包含 Header 和 Body 两部分，其中 Body 是可选的。
			HTTP 协议是一种文本协议，所以，它的格式也非常简单。
			HTTP GET 请求的格式：
				GET /path HTTP/1.1
				Header1: Value1
				Header2: Value2
				Header3: Value3
				每个 Header 一行一个，换行符是\r\n。
			HTTP POST 请求的格式：
				POST /path HTTP/1.1
				Header1: Value1
				Header2: Value2
				Header3: Value3
				body data goes here...
				当遇到连续两个\r\n 时，Header 部分结束，后面的数据全部是 Body。
			HTTP 响应的格式：
				200 OK
				Header1: Value1
				Header2: Value2
				Header3: Value3
				body data goes here...
			HTTP 响应如果包含 body，也是通过\r\n\r\n 来分隔的。
			请再次注意，Body 的数据类型由 Content-Type 头来确定，
				如果是网页，Body 就是文本，如果是图片，Body 就是图片的二进制数据。
			当存在 Content-Encoding 时，Body 数据是被压缩的，最常见的压缩方式是 gzip，
				所以，看到 Content-Encoding: gzip 时，需要将 Body 数据先解压缩，才能得到真正的数据。
				压缩的目的在于减少 Body 的大小，加快网络传输。
	HTML 简介：
		HTML 文档就是一系列的 Tag 组成，最外层的 Tag 是<html>。
			规范的 HTML 也包含<head>...</head>和<body>...</body>（注意不要和 HTTP 的 Header、Body 搞混了），
			由于 HTML 是富文档模型，所以，还有一系列的 Tag 用来表示链接、图片、表格、表单等等。
		CSS 简介：
			CSS 是 Cascading Style Sheets（层叠样式表）的简称，CSS 用来控制 HTML 里的所有元素如何展现
		JavaScript 简介：
			JavaScript 是为了让 HTML 具有交互性而作为脚本语言添加的，
			JavaScript 既可以内嵌到 HTML 中，也可以从外部链接到 HTML 中。
		小结：
			HTML 定义了页面的内容，CSS 来控制页面元素的样式，而 JavaScript 负责页面的交互逻辑。
			
	WSGI 接口：
		Web Server Gateway Interface。
		WSGI 接口定义非常简单，它只要求 Web 开发者实现一个函数，就可以响应 HTTP 请求。
		我们来看一个最简单的 Web 版本的“Hello, web!”：
			def application(environ, start_response):
				start_response('200 OK', [('Content-Type', 'text/html')])
				return [b'<h1>Hello, web!</h1>']
		上面的 application()函数就是符合 WSGI 标准的一个 HTTP 处理函数，它接收两个参数：
			environ：一个包含所有 HTTP 请求信息的 dict 对象；
			start_response：一个发送 HTTP 响应的函数。
		在 application()函数中，调用：
			start_response('200 OK', [('Content-Type', 'text/html')])
		就发送了 HTTP 响应的 Header，注意 Header 只能发送一次，也就是只能调用一次 start_response()函数。
			start_response()函数接收两个参数，一个是 HTTP 响应码，一个是一组 list 表示的 HTTP Header，
			每个 Header 用一个包含两个 str 的 tuple 表示。
		通常情况下，都应该把 Content-Type 头发送给浏览器。其他很多常用的 HTTP Header 也应该发送。
		然后，函数的返回值 b'<h1>Hello, web!</h1>'将作为 HTTP 响应的 Body 发送给浏览器。
		有了 WSGI，我们关心的就是如何从 environ 这个 dict 对象拿到 HTTP 请求信息，然后构造 HTML，
			通过 start_response()发送 Header，最后返回 Body。
		整个 application()函数本身没有涉及到任何解析 HTTP 的部分，
			底层代码不需要我们自己编写，我们只负责在更高层次上考虑如何响应请求就可以了。
		不过，等等，这个 application()函数怎么调用？
		如果我们自己调用，两个参数 environ 和 start_response 我们没法提供，返回的 bytes 也没法发给浏览器。
		所以 application()函数必须由 WSGI 服务器来调用。有很多符合 WSGI 规范的服务器，我们可以挑选一个来用。
		但是现在，我们只想尽快测试一下我们编写的 application()函数真的可以把 HTML 输出到浏览器，
			所以，要赶紧找一个最简单的 WSGI 服务器，把我们的 Web 应用程序跑起来。
		好消息是 Python 内置了一个 WSGI 服务器，这个模块叫 wsgiref，
			它是用纯 Python 编写的 WSGI 服务器的参考实现。
			所谓“参考实现”是指该实现完全符合 WSGI 标准，但是不考虑任何运行效率，仅供开发和测试使用。
			
	Web 框架：
		Flask：
			Flask 通过 Python 的装饰器在内部自动地把 URL 和函数给关联起来。
			Flask 自带的 Server 在端口 5000 上监听；
			Flask 通过 request.form['name'] 来获取表单的内容。
		除了 Flask，常见的 Python Web 框架还有：
			Django：全能型 Web 框架；
			web.py：一个小巧的 Web 框架；
			Bottle：和 Flask 类似的 Web 框架；
			Tornado：Facebook 的开源异步 Web 框架。
			
	模板使用：
		使用模板，需要预先准备一个 HTML 文档，这个 HTML 文档不是普通的 HTML，而是嵌入了一些变量和指令，
			然后，根据我们传入的数据，替换后，得到最终的 HTML，发送给用户。
		这就是传说中的 MVC：Model-View-Controller，中文名“模型-视图-控制器”。
			Python 处理 URL 的函数就是 C：Controller，Controller 负责业务逻辑，
				比如检查用户名是否存在，取出用户信息等等；
			包含变量{{ name }}的模板就是 V：View，View 负责显示逻辑，
				通过简单地替换一些变量，View 最终输出的就是用户看到的 HTML。
			MVC 中的 Model 在哪？
				Model 是用来传给 View 的，这样 View 在替换变量的时候，就可以从 Model 中取出相应的数据。
				Python 支持关键字参数，很多 Web 框架允许传入关键字参数，
					然后，在框架内部组装出一个 dict 作为 Model。
		Flask 通过 render_template()函数来实现模板的渲染。
			和 Web 框架类似，Python 的模板也有很多种。
			Flask 默认支持的模板是 jinja2，所以我们先直接安装 jinja2：
		通过 MVC，我们在 Python 代码中处理 M：Model 和 C：Controller，而 V：View 是通过模板处理的，
			这样，我们就成功地把 Python 代码和 HTML 代码最大限度地分离了。
		使用模板的另一大好处是，模板改起来很方便，而且，改完保存后，刷新浏览器就能看到最新的效果，
			这对于调试 HTML、CSS 和 JavaScript 的前端工程师来说实在是太重要了。
		在 Jinja2模板中，我们用{{ name }}表示一个需要替换的变量。
			很多时候，还需要循环、条件判断等指令语句，在 Jinja2中，用{% ... %}表示指令。
		除了 Jinja2，常见的模板还有：
			Mako：用<% ... %>和${xxx}的一个模板；
			Cheetah：也是用<% ... %>和${xxx}的一个模板；
			Django：Django 是一站式框架，内置一个用{% ... %}和{{ xxx }}的模板。
		小结：
			有了 MVC，我们就分离了 Python 代码和 HTML 代码。HTML 代码全部放到模板里，写起来更有效率。
			
异步 IO：
	同步 vs 异步 IO：
		同步 IO：
			CPU 的速度远远快于磁盘、网络等 IO。
			在一个线程中，CPU 执行代码的速度极快，然而，一旦遇到 IO 操作，如读写文件、发送网络数据时，
			就需要等待 IO 操作完成，才能继续进行下一步操作。
			CPU 高速执行能力和 IO 设备的龟速严重不匹配，多线程和多进程只是解决这一问题的一种方法。
			另一种解决 IO 问题的方法是异步 IO。
		当代码需要执行一个耗时的 IO 操作时，它只发出 IO 指令，并不等待 IO 结果，然后就去执行其他代码了。
			一段时间后，当 IO 返回结果时，再通知 CPU 进行处理。
			同步 IO 模型的代码是无法实现异步 IO 模型的。
		异步 IO 模型需要一个消息循环，在消息循环中，主线程不断地重复“读取消息-处理消息”这一过程：	
			loop = get_event_loop()
			while True:
				event = loop.get_event()
				process_event(event)
		消息模型其实早在应用在桌面应用程序中了。
			一个 GUI 程序的主线程就负责不停地读取消息并处理消息。
			所有的键盘、鼠标等消息都被发送到 GUI 程序的消息队列中，然后由 GUI 程序的主线程处理。
		消息模型是如何解决同步 IO 必须等待 IO 操作这一问题的呢？
			当遇到 IO 操作时，代码只负责发出 IO 请求，不等待 IO 结果，
				然后直接结束本轮消息处理，进入下一轮消息处理过程。
			当 IO 操作完成后，将收到一条“IO 完成”的消息，处理该消息时就可以直接获取 IO 操作结果。
			在“发出 IO 请求”到收到“IO 完成”的这段时间里，同步 IO 模型下，主线程只能挂起，
			但异步 IO 模型下，主线程并没有休息，而是在消息循环中继续处理其他消息。
				这样，在异步 IO 模型下，一个线程就可以同时处理多个 IO 请求，并且没有切换线程的操作。
				对于大多数 IO 密集型的应用程序，使用异步 IO 将大大提升系统的多任务处理能力。
			
	协程：
		协程，又称微线程，纤程。英文名 Coroutine。
			子程序，或者称为函数，在所有语言中都是层级调用，
				比如 A 调用 B，B 在执行过程中又调用了 C，C 执行完毕返回，B 执行完毕返回，最后是 A 执行完毕。
			所以子程序调用是通过栈实现的，一个线程就是执行一个子程序。
			子程序调用总是一个入口，一次返回，调用顺序是明确的。而协程的调用和子程序不同
		协程看上去也是子程序，但执行过程中，在子程序内部可中断，
			然后转而执行别的子程序，在适当的时候再返回来接着执行。
		注意：
			在一个子程序中中断，去执行其他子程序，不是函数调用，有点类似 CPU 的中断。
		优势：
			协程最大的优势就是极高的执行效率。
				因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，
					和多线程比，线程数量越多，协程的性能优势就越明显。
			第二大优势就是不需要多线程的锁机制，
				因为只有一个线程，也不存在同时写变量冲突，
				在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。
		因为协程是一个线程执行，那怎么利用多核 CPU 呢？
			最简单的方法是多进程 + 协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。
		Python 对协程的支持是通过 generator 实现的。
			在 generator 中，我们不但可以通过 for 循环来迭代，
				还可以不断调用 next()函数获取由 yield 语句返回的下一个值。
			但是 Python 的 yield 不但可以返回一个值，它还可以接收调用者发出的参数。
		例子：
			传统的生产者-消费者模型是一个线程写消息，一个线程取消息，
				通过锁机制控制队列和等待，但一不小心就可能死锁。
			改用协程，生产者生产消息后，直接通过 yield 跳转到消费者开始执行，
				待消费者执行完毕后，切换回生产者继续生产，效率极高。
				整个流程无锁，由一个线程执行，produce 和 consumer 协作完成任务，所以称为“协程”，
					而非线程的抢占式多任务。
			协程的特点：“子程序就是协程的一种特例。”
			
	asyncio：
		asyncio 是 Python 3.4 版本引入的标准库，直接内置了对异步 IO 的支持。
		asyncio 的编程模型就是一个消息循环。
			我们从 asyncio 模块中直接获取一个 EventLoop 的引用，
				然后把需要执行的协程扔到 EventLoop 中执行，就实现了异步 IO。
			@asyncio.coroutine 把一个 generator 标记为 coroutine 类型，
				然后，我们就把这个 coroutine 扔到 EventLoop 中执行。
			用 Task 封装两个 coroutine：
				import threading
				import asyncio
				@asyncio.coroutine
				def hello():
					print('Hello world! (%s)' % threading.currentThread())
					yield from asyncio.sleep(1)
					print('Hello again! (%s)' % threading.currentThread())

				loop = asyncio.get_event_loop()
				tasks = [hello(), hello()]
				loop.run_until_complete(asyncio.wait(tasks))
				loop.close()
			观察执行过程：
				Hello world! (<_MainThread(MainThread, started 140735195337472)>)
				Hello world! (<_MainThread(MainThread, started 140735195337472)>)
				(暂停约1秒)
				Hello again! (<_MainThread(MainThread, started 140735195337472)>)
				Hello again! (<_MainThread(MainThread, started 140735195337472)>)
		小结：
			asyncio 提供了完善的异步 IO 支持；
			异步操作需要在 coroutine 中通过 yield from 完成；
			多个 coroutine 可以封装成一组 Task 然后并发执行。
			
	async/await：
		用 asyncio 提供的 @asyncio.coroutine 可以把一个 generator 标记为 coroutine 类型，
			然后在 coroutine 内部用 yield from 调用另一个 coroutine 实现异步操作。
		为了简化并更好地标识异步 IO，从 Python 3.5开始引入了新的语法 async 和 await，
			可以让 coroutine 的代码更简洁易读。
		async 和 await 是针对 coroutine 的新语法，要使用新的语法，只需要做两步简单的替换：
			把 @asyncio.coroutine 替换为 async；
			把 yield from 替换为 await。
		上一节的代码：
			@asyncio.coroutine
			def hello():
				print("Hello world!")
				r = yield from asyncio.sleep(1)
				print("Hello again!")
		用新语法重新编写如下：
			async def hello():
				print("Hello world!")
				r = await asyncio.sleep(1)
				print("Hello again!")
		小结：
			Python 从3.5版本开始为 asyncio 提供了 async 和 await 的新语法；
			
	aiohttp：
		asyncio 可以实现单线程并发 IO 操作。
			如果仅用在客户端，发挥的威力不大。
			如果把 asyncio 用在服务器端，例如 Web 服务器，
				由于 HTTP 连接就是 IO 操作，因此可以用单线程 +coroutine 实现多用户的高并发支持。
		asyncio 实现了 TCP、UDP、SSL 等协议，aiohttp 则是基于 asyncio 实现的 HTTP 框架。
		注意：
			aiohttp 的初始化函数 init()也是一个 coroutine，loop.create_server()则利用 asyncio 创建 TCP 服务。
			
			
			
			
			
			
格式：
	定义类：
		class ClassName(object):
	定义类中的方法：
		def fuc_name(self):
	定义方法：
		def fuc_name():	
	创建实例：
		instance_name = ClassName()
			
		
			
			
			
			
			
			
			
			
			
			
	可变对象：
		list；
		
		
	不可变对象：
		str；
		int；
		None；
		tuple；
	
	
	
	
	
	Introduction
		comments：注释；
			# 单行注释 
		
	Variables：变量；
		variable definition：变量定义；
			链式赋值：a = b = 2；chained assignment；
			变量名：不能以数字开头；
			
		Variable types：变量类型；
			numbers: 
				int：
				floats：
				bool：
				complex：
				
		Type conversion：类型转换；
			int(x)：转成整数类形；
			float(x)：转成浮点类型；
			str(b)：转成字符串类型；
		
		Arithmetic operators：算术操作；
			addition (+)
			subtraction (-)
			multiplication (*)
			division (/)
			power (**)：指数；
			modulo (%)：求模；
			
		Augmented assignment：增量赋值；
			+= ：
			-= ：
			
		Boolean operators：布尔运算；
			== ：
			!= ：
		
		Comparison operators：
			链式比较：chained comparison
				one < two < three
			>= ：
			<= ：
			> :
			< :
		
	Strings：字符串；
			''
			""
			"""
				多行注释 
			"""
			
		Concatenation：连接符；
			+ ：
			
		String multiplication：字符串乘法；
			string-by-number multiplication：
			hello * 10
			
		String indexing：字符串索引取值；
			str[index]：索引处的元素；
			
		String negative indexing：字符串负索引取值；
			str[-1]：从末尾开始；
		
		String slicing：字符串切片；
			slicing：切片；可用于字符串、数组、List 等类型；
			str[start:end]：起始(包含)，结束(不包含)
			str[start:]：
			str[:end]：
			str[:]：全部；
			
		In operator：包含；
			keyword in String：
			
		String length：字符串长度；
			len()：String 长度；
			
		Character escaping：字符转义；
			\ ：转义符；
			'\n'：换行；
		
		Basic string methods：字符串操作方法；
			lower()：
			upper()：
		
		String formatting：字符串格式化；
			% ：占位符；
			%s ：字符串占位符；
				% %s ：% 后面的变量会替换掉 String 中的 %s；
			%d ：数字占位符；
		
	Data structures：数据结构；
		Lists introduction：列表；
			slicing：切片；可用于字符串、数组、List、元组等类型；
			lst[start:end]：起始(包含)，结束(不包含)
			lst[start:end:stride]：起始(包含)，结束(不包含)，跨度(每几个取一个，为负则会从最末往前取)；
		
		Lists operations：列表操作；
			+= ：增量赋值；
			append()：追加；
		
		List items：列表项；
			animals = ['elephant', 'lion', 'tiger', "giraffe", "monkey", 'dog']
			animals[1:3] = ['cat']
			animals[1:3] = []
			animals[:] = []
		
		Tuples：元组；
			元组内元素无法被增加、修改或者删除；只能进行查询、截取和 + * 等运算操作；
			单元素元组必须以逗号结尾；
			内置函数：
				len()：长度；
				cmp()：比较；
				max()：最大元素；
				min()：最小元素；
		
		Dictionaries：字典；
			键值对；
			dic[key] = value
			keys()：键；
			values()：值；
			str in dic.keys();
			int in dic.values();
			
	Condition expressions：条件表达式；
		Boolean operators：布尔运算；
			not：一级优先；
			and：二级优先；
			or：三级优先；
			== ：
			!= ：
			is：变量和字符串；
			运算顺序：
				not：first；
				and：next；
				or：last。
		
		If statement：条件语句；
			if boolean :
				todo
			elif boolean :
				todo
			else:
				todo
			
	Loops：循环；
		For loop：for 循环；
			for i in range(5):
				print(i)   
		
		For loop using string：字符串 for 循环；
			length = 0
			for ch in hello_world:
				length += 1
		
		While loop：while 循环；
			square = 1
			while square <= 10:
				print(square)
				square += 1 
		
		Break keyword：打断；
			count = 0
			while True:
				print(count)
				count += 1
				if count >= 5:
					break
		
		Continue keyword：略过继续；
			for x in range(10):
				if x % 2 == 0:
					continue
				print(x)
			
	Functions：函数；
		Definition：定义；
			def hello_world():
				print("Hello, World!")
		
		Parameters and call arguments：形参和调用传参；
			def square(x):
				print(x ** 2)
				square(5)
		
		Return value：返回值；
			def fib(n):
				result = []
				a = 1
				b = 1
			while a < n:
				result.append(a)
				tmp_var = b
				b = a + b
				a = tmp_var
			return result
		
		Default parameters：默认参数；
			def multiply_by(a, b=2):
				return a * b
			
	Classes and objects：类和对象；	
		Definition：定义；
			class MyClass:
			my_object = MyClass()
		
		Variable access：变量访问；
			my_object = MyClass()
			my_object.variable1
		
		Self explanation：当前对象；
			self：调用时的类的实例
				类的方法必须有个额外的第一个参数；
				按照 Python 的惯例，它用 self 来表示。
				self 不是关键字；
				self 代表当前对象的地址；
				self 在定义类时不可以省略，在调用时会自动传入。
				self 能避免非限定调用造成的全局变量。
			class Calculator:
				current = 0
				def add(self, amount):
					self.current += amount
				def get_current(self):
					return self.current
		
		Special __init__ method：初始化方法；
			__init__()：
				初始化方法，用于初始化一个类；
				类实例创建之后调用, 对当前对象的实例的一些初始化, 没有返回值；
				__new__()：创建类实例的方法, 创建对象时调用, 返回当前对象的一个实例；
				__str__()：内置方法, 只能返回字符串, 并且只能有一个参数 self；
				__call__()：
					对象通过提供一个 __call__(self, *args, *kwargs) 方法可以模拟函数的行为，
					如果一个对象提供了该方法, 可以向函数一样去调用它
			
	Modules and packages：模块和包；
		Import module：导入模块；
			import my_module
			
		Built-in modules：内置模块；
			import datetime
			print(datetime.datetime.today())
			
		From import：
			from calculator import Calculator：可以直接调用，无需模块名调用；
			
	File input output：文件输入输出；
		Read file：读取文件；
			f = open("output.txt", "r")
			for line in f.readlines():
				print(line)
			f.close()
		Write to file：写入文件；
			f = open("output.txt", "a")
			for i in zoo:
				f.write(i)
			f.close()
			注意：
				f = open("output.txt", "w")：如果存在同名文件，会先删除再新建文件写入；
				f = open("output.txt", "a")：追加写入；
		
		
提高
		
	描述符类：Python 中一种用于储存类属性值的对象；
		通常需要以下几种魔术方法：
			__set__(self, instance, value)
			__get__(self, instance, owner)
			__delete__(self, instance)
			__set_name__(self, owner， name)
		
		
		
		
		
		
		
		
		
		
		
Django
	Django settings：配置；
		settings file contains all the configuration of your Django installation；
		设置文件包含了所有的配置信息。
	
	Models：模板；
		each model maps to a single database table. 
		每个模板对应一张数据库表；
		Each model is a Python class that subclasses django.db.models.Model.
		每个模板都是一个类；继承于 django.db.models.Model；
		Each attribute of the model represents a database field.
		模板的每一个属性，对应数据库表中的一个字段；
		Django gives you an automatically-generated database-access API
		能自动生成访问数据库的 API。
		
	URL dispatcher：资源路径调度器；
		URLconf (URL configuration)：simple mapping between URL patterns (simple regular expressions)；
			To capture a value from the URL, just put parenthesis around it.
			用圆括号获取 URL 中的值；
			There’s no need to add a leading slash, because every URL has that. 
			For example, it’s ^articles, not ^/articles.
			开头不需要斜杠；
			The 'r' in front of each regular expression string is optional but recommended. 
			It tells Python that a string is “raw” – that nothing in the string should be escaped.
			r 代表字符串是原生的，没有转义符。
		regular expressions：正则表达式；
			^ ：开头；
			$ ：结尾；
			[0-9] ：范围内选择；
			{4} ：重复次数；
			() ：允许重复多个字符；
			+ ：软性量词 出现一次或多次(至少一次)。
		
	Writing views：视图；
		def post_list(request):
			return render(request, 'blog/post_list.html', {})
		
	Templates：模板；
		HTML 文件；
		
	Dynamic data in templates：模板中的动态数据；
		def post_list(request):
			posts = Post.objects.order_by('published_date')
			return render(request, 'blog/post_list.html', {posts})
		Example：全部数据；
			Post.objects.all()
		Filter objects：过滤；
			Post.objects.filter(author=me)
		Ordering objects：排序；
			Post.objects.order_by('created_date')
			Post.objects.order_by('-created_date')
		Chaining QuerySets：链接查询集；
			Post.objects.filter(published_date__lte=timezone.now()).order_by('published_date')
		
	Django template language：模板语言；
		Variables are surrounded by {{ and }}
		变量语法：{{ }}
		Tags are surrounded by {% and %}
		标签语法：{% %}
			{% for post in posts %}
				{{ post.author }} {{ post.title }} {{ post.text }} {{ post.created_date }} {{ post.published_date }}
			{% end for %}
		
		
单元测试
	结果类型：
	    def test_success(self):
			pass

		def test_failure(self):
			self.assertEqual(True, False)

		def test_error(self):
			raise Exception
		
		pass 语句：
			空语句，是为了保持程序结构的完整性。
			pass 不做任何事情，一般用做占位语句
			
		raise 关键字：
			用来触发异常；后面是要引发的异常的名称；异常类的名称后面可以添加一个逗号以及指定的参数；
			一旦执行了 raise 语句，raise 后面的语句将不能执行；
			
		format 函数：
			通过 {} 和 : 来代替%。
			例如："Hello, {}!".format(name)
		
		copy 函数：
			复制；
			
	Assertion Types：断言类型；
		the int zero is considered false, while all other ints are considered true. 
		0 代表假；其他整型代表真；
		Most containers are considered false when empty and true when non-empty
		空容器代表假，非空容器代表真。
		
		例如：
			def test_zero(self):
				self.assertFalse(0)

			def test_one(self):
				self.assertTrue(1)
			
			def test_none(self):
				self.assertFalse(None)
		
		    def _test_container_class(self, empty_container, non_empty_container):
				self.assertFalse(empty_container)
				self.assertTrue(non_empty_container)

			def test_list(self):
				self._test_container_class([], [False])

			def test_tuple(self):
				self._test_container_class((), (False, ))

			def test_set(self):
				self._test_container_class(set(), {False})

			def test_dict(self):
				self._test_container_class({}, {False: False})
		
		assertion methods：
			Method						Checks that				New in
			assertEqual(a, b)			a == b	 
			assertNotEqual(a, b)		a != b	 
			assertTrue(x)				bool(x) is True	 
			assertFalse(x)				bool(x) is False	 
			assertIs(a, b)				a is b					3.1
			assertIsNot(a, b)			a is not b				3.1
			assertIsNone(x)				x is None				3.1
			assertIsNotNone(x)			x is not None			3.1
			assertIn(a, b)				a in b					3.1
			assertNotIn(a, b)			a not in b				3.1
			assertIsInstance(a, b)		isinstance(a, b)		3.2
			assertNotIsInstance(a, b)	not isinstance(a, b)	3.2
			assertCountEqual(a, b)		a.len() == b.len()		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		