# MySQL

---

## Content / 目录

---

- [一、基础部分](#一、基础部分)
    - [01、三大范式](#01、三大范式)
- [二、提高部分](#二、提高部分)
    - [01、SQL 优化](#01、SQL-优化)
    - [02、MySQL 高效分页](#02、MySQL-高效分页)
- [三、索引](#三、索引)
    - [01、MySQL 为什么需要索引](#01、MySQL-为什么需要索引)
    - [02、MySQL 的索引分类](#02、MySQL-的索引分类)
    - [03、联合索引 / 组合索引 / 复合索引](#03、联合索引-/-组合索引-/-复合索引)
    - [04、前缀索引](#04、前缀索引)
    - [05、覆盖索引](#05、覆盖索引)
    - [06、索引下推](#06、索引下推)
    - [07、聚簇索引、非聚簇索引的区别](#07、聚簇索引、非聚簇索引的区别)
    - [08、主键索引、非主键索引的区别](#08、主键索引、非主键索引的区别)
    - [09、InnoDB 中的 B+Tree 索引](#09、InnoDB-中的-B+Tree-索引)
    - [10、B 树、B+ 树的区别](#10、B-树、B+-树的区别)
    - [11、hash 索引、B+ 树索引的区别](#11、hash-索引、B+-树索引的区别)
    - [12、有那些解决 hash 冲突的方法](#12、有那些解决-hash-冲突的方法)
    - [13、为什么官方建议使用自增长主键作为主键](#13、为什么官方建议使用自增长主键作为主键)
    - [14、索引失效](#14、索引失效)
    - [15、如何做索引优化](#15、如何做索引优化)
- [四、事务](#四、事务)
    - [01、事务的特性 / ACID](#01、事务的特性-/-ACID)
    - [02、事务的隔离级别](#02、事务的隔离级别)
    - [03、幻读 / Phantom Read](#03、幻读-/-Phantom-Read)
    - [04、MVCC 的快照读和当前读](#04、MVCC-的快照读和当前读)
    - [05、MySQL 的 InnoDB 如何实现 MVCC](#05、MySQL-的-InnoDB-如何实现-MVCC)
    - [06、MySQL 如何实现原子性](#06、MySQL-如何实现原子性)
    - [07、MySQL 如何实现持久性](#07、MySQL-如何实现持久性)
    - [08、MySQL 如何实现隔离性](#08、MySQL-如何实现隔离性)
    - [09、MySQL 如何实现一致性](#09、MySQL-如何实现一致性)
- [五、日志](#五、日志)
    - [01、MySQL 的日志](#01、MySQL-的日志)
    - [02、redo log 与 binlog 的区别](#02、redo log 与 binlog 的区别)
- [六、锁](#六、锁)
    - [01、锁的作用范围分类](#01、锁的作用范围分类)
    - [02、锁的模式分类](#02、锁的模式分类)
    - [03、InnoDB 中的行锁](#03、InnoDB-中的行锁)
    - [04、锁组合](#04、锁组合)
    - [05、悲观锁和乐观锁](#05、悲观锁和乐观锁)

---

## 一、基础部分

---

### 01、三大范式

**1. 第一范式 / 1NF：**

**要保证字段的原子性。**

数据库表中不能出现重复记录，每个字段是原子性的不能再分。

> 比如：在学生表中，联系方式这个字段出现了邮件和电话号码一起存，用逗号连接的情况。一个值里不能同时包含两种数据，因为会违反第一范式。

**2. 第二范式 / 2NF：**

**非主键字段完全依赖主键，不能产生部分依赖。**

第二范式是建立在第一范式基础上的，另外要求所有非主键字段完全依赖主键，不能产生部分依赖。

> 比如：在学生表中，增加老师名字这个字段，但是老师的名字信息不依赖于表的主键，违反了第二范式。

**3. 第三范式 / 3NF：**

**非主键字段和主键字段之间不能产生传递依赖。**

建立在第二范式基础上的，非主键字段不能传递依赖于主键字段。

> 比如：在学生表中，增加班级编号、班级名称这两个字段。班级名称依赖于班级编号，班级编号依赖于学生表的主键，产生了传递依赖。

**4. 逆范式：**

**通过增加冗余或重复的数据来提高数据库的读性能**。


---

## 二、提高部分

---

### 01、SQL 优化

尽量避免子查询。

分页的参数不应过大。

where 字段加索引。

### 02、MySQL 高效分页

普通 LIMIT 的问题：

> 取出 N+M 行，丢弃前 N 行，返回 N ~ N+M 行的记录，如果 N 值非常大，效率极差（表记录 1500w，N=10000000，M=30 需要 9 秒）。

优化方案：

> SELECT id FROM ttl_product_info WHERE id > N LIMIT M。
>
> id 列是索引列，id > N 属于 range 级别，效率自然高，然后从位置开始取 30 条记录，效率极高（表记录 1500w，N=10000000，M=30，需要 0.9 毫秒）

高效分页有三个前提条件：

1. id 是唯一索引，而且单调递增。
2. N 的值是上一次查询的记录的最后一条 id（需要前端保存一下，不能直接用传统的方法获得）。
3. 不支持跨页查询，只能按照第 1，2，3，4 页这样查询逐页查询。

---

## 三、索引

---

### 01、MySQL 为什么需要索引

**索引 / index：**

是帮助 MySQL 高效获取数据的数据结构。

> 数据是以文件的形式存放在磁盘上面的，每一行数据都有它的磁盘地址。如果没有索引的话，要从 500 万行数据里面检索一条数据，只能依次遍历这张表的全部数据，直到找到这条数据。
>
> 有了索引之后，只需要在索引里面去检索这条数据就行了，因为它是一种特殊 的专门用来快速检索的数据结构，我们找到数据存放的磁盘地址以后，就可以拿到数据 了。

### 02、MySQL 的索引分类

**1. 主键索引 / 主索引：**

即主索引，根据主键 pk_clolum（length）建立索引，不允许重复，不允许空值。

**2. 唯一索引：**

用来建立索引的列的值必须是唯一的，允许空值。

**3. 普通索引：**

用表中的普通列构建的索引，没有任何限制。

**4. 全文索引：**

针对比较大的数据，比如我们存放的是消息内容，有几 KB 的数 据的这种情况，如果要解决 like 查询效率低的问题，可以创建全文索引。只有文本类型 的字段才可以创建全文索引，比如
char、varchar、text。

**5. 联合索引：**

用多个列组合构建的索引，这多个列中的值不允许有空值。

### 03、联合索引 / 组合索引 / 复合索引

**联合索引**：

两个或更多个列上的索引。

> 在使用组合索引的时候可能因为列名长度过长而导致索引的 key 太大，导致效率降低，在允许的情况下，可以只取 col1 和 col2 的前几个字符作为索引。

联合索引好处：

> 减少开销：建一个联合索引（col1,col2,col3），实际相当于建了（col1），（col1,col2），（col1,col2,col3）三个索引。减少磁盘空间的开销。
>
> 覆盖索引：对联合索引（col1,col2,col3），如果有如下的 sql: select col1,col2,col3 from test where col1=1 and col2=2。那么 MySQL 可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机 io 操作。覆盖索引是主要的提升性能的优化手段之一。
>
> 效率高：索引列越多，通过索引筛选出的数据越少。

**最左前缀原则：**

> MySQL 建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。
>
> MySQL 会一直向右匹配直到遇到范围查询（>、<、between、like）就停止匹配，比如 a = 1 and b = 2 and c > 3 and d = 4 如果建立（ a,b,c,d）顺序的索引，d 是用不到索引的，如果建立（a,b,d,c）的索引则都可以用到，a,b,d 的顺序可以任意调整。
>
> = 和 in 可以乱序，比如 a = 1 and b = 2 and c = 3 建立（a,b,c）索引可以任意顺序，mysql 的查询优化器会帮你优化成索引可以识别的形式。

所以在建立联合索引的时候要把最常用的列放在最左边。

### 04、前缀索引

**前缀索引：**

对文本的前几个字符（具体是几个字符在创建索引时指定）创建索引，这样创建起来的索引更小。

但是 MySQL 不能在 ORDER BY 或 GROUP BY 中使用前缀索引，也不能把它们用作覆盖索引。

### 05、覆盖索引

**覆盖索引 / covering index：**

在辅助索引里面，不管是单列索引还是联合索引，如果 select 的数据列只用从索引中就能够取得，不必从数据区中读取，这时使用的索引就叫覆盖索引，避免了**回表**。

> 对联合索引（col1,col2,col3），如果有如下的 sql: select col1,col2,col3 from test where col1=1 and col2=2。
>
> 那么 MySQL 可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机 io 操作。覆盖索引是主要的提升性能的优化手段之一。

**回表：**

非主键索引，我们先通过索引找到主键索引的键值，再通过主键值查出索引里面没有的数据，它比基于主键索引的查询多扫描了一棵索引树，这个过程就叫回表。

### 06、索引下推

MySQL 5.6 引入了索引下推优化，默认开启，使用 SET optimizer_switch = ‘index_condition_pushdown=off’; 可以将其关闭。

> 有了索引下推优化，可以在减少**回表**次数。
>
> 在 InnoDB 中只针对二级索引有效。

官方文档中给的例子和解释如下：

> 在 people_table 中有一个二级索引（zipcode，lastname，address），查询是 SELECT * FROM people WHERE zipcode=’95054′ AND lastname LIKE ‘% etrunia%’ AND address LIKE ‘% Main Street%’;
>
> 如果没有使用索引下推技术，则 MySQL 会通过 zipcode=’95054’从存储引擎中查询对应的数据，返回到 MySQL 服务端，然后 MySQL 服务端基于 lastname LIKE ‘% etrunia%’ and address LIKE ‘% Main Street%’来判断数据是否符合条件。
>
> 如果使用了索引下推技术，则 MySQL 首先会返回符合 zipcode=’95054’的索引，然后根据 lastname LIKE ‘% etrunia%’ and address LIKE ‘% Main Street%’来判断索引是否符合条件。如果符合条件，则根据该索引来定位对应的数据，如果不符合，则直接 reject 掉。

### 07、聚簇索引、非聚簇索引的区别

**聚簇索引**：

**聚簇索引的顺序就是数据的物理存储顺序。**

InnoDB 存储引擎采用的是聚簇索引，聚簇索引的数据和主键索引存储在一起。

聚簇索引的主索引的叶子结点存储的是键值对应的数据本身，辅助索引的叶子结点存储的是键值对应的数据的主键键值。因此主键的值长度越小越好，类型越简单越好。

**非聚簇索引**：

**索引顺序与数据物理排列顺序无关。**

MyISAM 存储引擎采用的是非聚簇索引，非聚簇索引的主索引和辅助索引几乎是一样的，只是主索引不允许重复，不允许空值，他们的叶子结点的 key 都存储指向键值对应的数据的物理地址。

非聚簇索引的数据表和索引表是分开存储的。

### 08、主键索引、非主键索引的区别

**非主键索引**的叶子节点存放的是主键的值，而**主键索引**的叶子节点存放的是整行数据，

其中非主键索引也被称为**二级索引**，而主键索引也被称为**聚簇索引**。

### 09、InnoDB 中的 B+Tree 索引

**B+Tree 索引：**

InnoDB 中，表数据文件本身就是按 B+Tree 组织的一个索引结构，叶节点 data 域保存了完整的数据记录。

这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引，所以必须有主键。

如果没有显示定义，自动为生成一个隐含字段作为主键，这个字段长度为 6 个字节，类型为长整型。

B+Tree 索引的特点：

> 它是 B Tree 的变种，B Tree 能解决的问题，它都能解决。B Tree 解决的两大问题是什么？（每个节点存储更多关键字；路数更多）
>
> 扫库、扫表能力更强（如果我们要对表进行全表扫描，只需要遍历叶子节点就可以 了，不需要遍历整棵 B+Tree 拿到所有的数据）
>
> B+Tree 的磁盘读写能力相对于 B Tree 来说更强（根节点和枝节点不保存数据区，所以一个节点可以保存更多的关键字，一次磁盘加载的关键字更多）
>
> 排序能力更强（因为叶子节点上有下一个数据区的指针，数据形成了链表）
>
> 效率更加稳定（B+Tree 永远是在叶子节点拿到数据，所以 IO 次数是稳定的）

### 10、B 树、B+ 树的区别

**B Tree / B 树 / 多路平衡查找树：**

B 树在枝节点和叶子节点存储键值、数据地址、节点引用。

它有一个特点：分叉数（路数）永远比关键字数多 1。

假如树的度为 2d（d>1），高度为 h，那么 B Tree 要满足以一下条件：

1. 每个叶子结点的高度一样，等于 h；
2. 每个非叶子结点由 n-1 个 key 和 n 个指针 point 组成，其中 d<=n<=2d,key 和 point 相互间隔，结点两端一定是 key；
3. 叶子结点指针都为 null；
4. 非叶子结点的 key 都是 [key,data] 二元组，其中 key 表示作为索引的键，data 为键值所在行的数据；

**B+Tree / B+ 树：**

B+Tree 是 BTree 的一个变种，设 d 为树的度数，h 为树的高度，B+Tree 和 BTree 的不同主要在于：

1. B+Tree 中的非叶子结点不存储数据，只存储键值；
2. B+Tree 的叶子结点没有指针，所有键值都会出现在叶子结点上，且 key 存储的键值对应 data 数据的物理地址；
3. B+Tree 的每个非叶子节点由 n 个键值 key 和 n 个指针 point 组成，键值数量和指针数量相同；
4. B+Tree 搜索到键值不会直接返回，会到最后一层的叶子节点；
5. B+Tree 的每个叶子节点增加了一个指向相邻叶子节点的指针，它的最后一个数 据会指向下一个叶子节点的第一个数据，形成了一个有序链表的结构。
6. 它是根据左闭右开的区间[和)来检索数据。

### 11、hash 索引、B+ 树索引的区别

**hash 索引：**

Hash 结构由 Hash 表来实现的，是根据键值 <key, value> 存储数据的结构；Hash 索引可以方便的提供等值查询，对于范围查询就需要全表扫描；Hash 结构在 MySQL
中主要应用在 Memory 原生的 Hash 索引 、InnoDB 自适应哈希索引。

每插入一个元素会把我们的索引字段做一次 hash 计算，把运算的到的结果值和这一行的所在磁盘地址做一个映射。

对索引元素的值做一次 hash 运算就可以在 hash 映射表里快速找到这一行的磁盘文件地址，经过一次 hash 就可以快速定位到索引所在行的磁盘文件地址，hash
这么快，表有一亿个数据按这种算法，那也就可能经历一次 hash 运算就可以快速找到某页任意一行数据元素的所在的磁盘文件地址，那比 B+Tree 快的多啊！就是快的多，为啥 99.99 的都是
B+Tree 不是 hash 呢？

hash 的等值查询比 B+Tree 快，上亿依然很快，为啥很快却不使用？最主要的原因是，如果使用范围查找，hash 就没有用武之地了。范围查找很常用，所以基本就不怎么用 hash 这种数据结构。

**B+Tree 索引：**

B+Tree 可以很好的支撑范围查找。

### 12、有那些解决 hash 冲突的方法

**1. 链地址法 / 拉链法：**

为每个 hash 值建立一个单链表，当发生冲突时，将记录插入到链表中。

实际的哈希表实现中，使用最多的是链地址法。

**2. 再哈希法：**

同时构造多个哈希函数，当产生冲突时，计算另一个哈希函数的值，直到冲突不再产生。

这种方法不易产生聚集，但增加了计算时间。

**3. 建立公共溢出区：**

将哈希表分为基本表和溢出表两部分，为所有发生 hash 冲突的关键字记录一个公共的溢出区来存放。

**4. 开放定址法：**

使用某种探测算法在散列表中寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到。

- 开放定址法实现方式：

> 线性探查：发生 hash 冲突时，顺序查找下一个位置，直到找到一个空位置（固定步长 1 探测）。
>
> 二次探查：在发生 hash 冲突时，在表的左右位置进行按一定步长跳跃式探测（固定步长 n 探测）。
>
> 伪随机探测：在发生 hash 冲突时，根据公式生成一个随机数，作为此次探测空位置的步长（随机步长 n 探测）。

### 13、为什么官方建议使用自增长主键作为主键

索引树只能定位到某一页，每一页内的插入还是需要通过比较、移动插入的，所以有序主键可以提升插入效率。

结合 B+Tree 的特点，自增主键是连续的，在插入过程中尽量减少页分裂，即使要进行页分裂，也只会分裂很少一部分。并且能减少数据的移动，每次插入都是插入到最后。总之就是减少分裂和移动的频率。

### 14、索引失效

1. 索引遇到范围查询就会失效，比如：>、<、between、like。
2. where 语句中包含 or 时，可能会导致索引失效
3. where 语句中索引列使用了负向查询，可能会导致索引失效
4. 索引字段可以为 null，使用 is null 或 is not null 时，可能会导致索引失效
5. 在索引列上使用内置函数，一定会导致索引失效 4.1 隐式类型转换导致的索引失效 4.2 隐式字符编码转换导致的索引失效
6. 对索引列进行运算，一定会导致索引失效
7. like 通配符可能会导致索引失效
8. 联合索引中，where 中索引列违背最左匹配原则，一定会导致索引失效
9. MySQL 优化器的最终选择，不走索引

### 15、如何做索引优化

1. 选择唯一性索引。唯一索引可以更快速的通过该索引来确定某条记录。
2. 为经常需要排序、分组和联合操作的字段建立索引。排序操作会浪费很多时间。
3. 为常作为查询条件的字段建立索引。
4. 限制索引的数目。越多的索引，会使更新表变得很浪费时间。
5. 尽量使用数据量少的索引。如果索引的值很长，那么查询的速度会受到影响。
6. 尽量使用前缀来索引。如果索引字段的值很长，最好使用值的前缀来索引。
7. 删除不再使用或者很少使用的索引，从而减少索引对更新操作的影响。
8. 建立组合索引，必须把区分度高的字段放在前面。

---

## 四、事务

---

### 01、事务的特性 / ACID

**1. 原子性 / Atomicity：**

保证每个事务都被视为一个单独的单元，要么完全成功，要么完全失败。一个事务中的所有操作，**要么全部执行成功，要么全部不执行**。

**2. 一致性 / Consistency：**

事务执行结束后，**数据库的完整性约束**没有被破坏，**事务执行的前后都是合法的数据状态**。

数据库的完整性约束包括但不限于：实体完整性（如行的主键存在且唯一）、列完整性（如字段的类型、大小、长度要符合要求）、外键约束、用户自定义完整性（如转账前后，两个账户余额的和应该不变）。

**3. 隔离性 / Isolation：**

事务内部的操作及使用的数据对正在进行的其他事务是隔离的，**并发执行的各个事务之间不能互相干扰**。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。

**4. 持久性 / Durability：**

事务一旦提交，**对数据库的改变就应该是永久性的**。接下来的其他操作或故障不应该对其有任何影响。

### 02、事务的隔离级别

**1. 读未提交 / Read Uncommitted：**

可以读取到其他会话中未提交事务修改的数据。读未提交可能出现脏读。

**脏读：在事务中读到了其他会话未提交的数据。**

**2. 读已提交 / Read Committed（RC）：**

只能读取到已经提交的数据。Oracle 等多数数据库默认都是该级别。读已提交可能出现不可重复读。

**不可重复读：在事务中读到了其他会话已经提交的数据。**

**3. 可重复读 / Repeated Read（RR）：**

在同一个事务内的**查询**都是事务开始时刻一致的，InnoDB 默认级别。在 SQL 标准中，该隔离级别消除了不可重复读。可重复读可能出现幻读。

**幻读：在事务中使用当前读，读到了其他会话提交的新数据。**

**4. 串行化 / Serializable：**

完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。串行化没有幻读，但实际中因为性能等原因不会采用这种级别。

### 03、幻读 / Phantom Read

**幻读**：是幻影行 / Phantom Rows 产生的负面结果，快照读和当前读一起使用就能复现。

幻读典型场景复现：

> 事务 A 按条件读取数据时，事务 B 插入了相同条件的新数据，事务 A 再次按原先条件进行读取操作**修改**时，读取到了事务 B 插入的新数据。
>
> 事务 C 查不出事务 D 新增的记录，但是自身插入相同主键的记录会报主键冲突。

出现的原因：

> 如果事务中都是用快照读，就不会产生幻读，**快照读和当前读一起使用的时候可能产生幻读**。

解决办法：

> 为了防止幻读，InnoDB 采用了 **Next-Key Lock** 算法，将记录锁与间隙锁相结合。

### 04、MVCC 的快照读和当前读

**快照读 / 非加锁读 / 一致性读：**

读取开启事务时的版本数据。

> 例如：使用普通的 select 语句，这种情况下使用 MVCC 避免了脏读、不可重复读、幻读，保证了隔离性。

InnoDB 提供的非锁定读，不需要等待访问行上的锁释放，读取行的一个快照。

**当前读 / 加锁读：**

读取数据库当前版本数据。

加锁读在查询时会对查询的数据加锁（共享锁或排它锁）。

由于锁的特性，当某事务对数据进行加锁读后，其他事务无法对数据进行写操作，因此可以避免脏读和不可重复读。而避免幻读，则需要通过 next-key lock。

因此，加锁读同样可以避免脏读、不可重复读和幻读，保证隔离性。

共享锁读取的查询语句：select...lock in share mode 排它锁读取的查询语句：select...for update

所以，select 执行的是快照读（某个版本的数据，Read View），而 update 执行的是当前读（最新的数据，即最新的 Read View）。

### 05、MySQL 的 InnoDB 如何实现 MVCC

**MVCC / Multiversion concurrency control / 多版本并发控制：**

MVCC 的实现没有固定的规范，每个数据库都会有不同的实现方式，这里讨论的是 InnoDB 的 MVCC。

在 InnoDB 中，会在每行数据后添加两个额外的隐藏的值来实现 MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。
在实际操作中，存储的并不是时间，而是事务的版本号。

**每开启一个新事务，事务的版本号就会递增。**

**通过 MVCC，虽然每行记录都需要额外的存储空间，更多的行检查工作以及一些额外的维护工作，但可以减少锁的使用。**
大多数读操作都不用加锁，读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行，也只锁住必要行。

根据 MVCC 的定义，并发提交数据时会出现冲突。

在可重复读级别中，通过 MVCC 机制，虽然让数据变得可重复读，但我们读到的数据可能是历史数据，是不及时的数据，不是数据库当前的数据。

事务的隔离级别实际上都是定义了当前读的级别，MySQL 为了减少锁处理（包括等待其它锁）的时间，提升并发能力，引入了快照读的概念，使得 select 不用加锁。

而 update、insert 这些当前读，就需要另外的模块来解决了。为了解决当前读中的幻读问题，MySQL 事务使用了 Next-Key Lock。

### 06、MySQL 如何实现原子性

InnoDB 实现回滚，靠的是 undo log，回滚日志是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的 sql 语句，。。

**回滚日志 / undo log：**

当事务对数据库进行修改时，InnoDB 会生成对应的 undo log；如果事务执行失败或调用了 rollback，导致事务需要回滚，便可以利用 undo log 中的信息将数据回滚到修改之前的样子。

例如：

1. 当你 delete 一条数据的时候，就需要记录这条数据的信息，回滚的时候，insert 这条旧数据
2. 当你 update 一条数据的时候，就需要记录之前的旧值，回滚的时候，根据旧值执行 update 操作
3. 当年 insert 一条数据的时候，就需要这条记录的主键，回滚的时候，根据主键执行 delete 操

### 07、MySQL 如何实现持久性

InnoDB 作为 MySQL 的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘 IO，效率会很低。

为此，InnoDB 提供了缓存（Buffer Pool），Buffer Pool 中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：

当从数据库读取数据时，会首先从 Buffer Pool 中读取，如果 Buffer Pool 中没有，则从磁盘读取后放入 Buffer Pool； 当向数据库写入数据时，会首先写入 Buffer
Pool，Buffer Pool 中修改的数据会定期刷新到磁盘中（这一过程称为刷脏）。

Buffer Pool 的使用大大提高了读写数据的效率，但是也带了新的问题：如果 MySQL 宕机，而此时 Buffer Pool
中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。

于是，redo log 被引入来解决这个问题：当数据修改时，除了修改 Buffer Pool 中的数据，还会在 redo log 记录这次操作；当事务提交时，会调用 fsync 接口对 redo
log 进行刷盘。如果 MySQL 宕机，重启时可以读取 redo log 中的数据，对数据库进行恢复。redo log 采用的是 WAL（Write-ahead
logging，预写式日志），所有修改先写入日志，再更新到 Buffer Pool，保证了数据不会因 MySQL 宕机而丢失，从而满足了持久性要求。

既然 redo log 也需要在事务提交时将日志写入磁盘，为什么它比直接将 Buffer Pool 中修改的数据写入磁盘（即刷脏）要快呢？主要有以下两方面的原因：

> 刷脏是随机 IO，因为每次修改的数据位置随机，但写 redo log 是追加操作，属于顺序 IO。
>
> 刷脏是以数据页（Page）为单位的，MySQL 默认页大小是 16KB，一个 Page 上一个小修改都要整页写入；而 redo log 中只包含真正需要写入的部分，无效 IO 大大减少。

### 08、MySQL 如何实现隔离性

隔离性要求同一时刻只能有一个事务对数据进行写操作，InnoDB 通过锁机制来保证这一点。

锁机制的基本原理可以概括为：

> 事务在修改数据之前，需要先获得相应的锁；获得锁之后，事务便可以修改数据；该事务操作期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁。

InnoDB 实现的 RR，通过锁机制（包含 next-key lock）、MVCC（包括数据的隐藏列、基于 undo log
的版本链、ReadView）等，实现了一定程度的隔离性，可以满足大多数场景的需要。

RR 虽然避免了幻读问题，但是毕竟不是 Serializable，不能保证完全的隔离。

如果在事务中第一次读取采用非加锁读，第二次读取采用加锁读，则如果在两次读取之间数据发生了变化，两次读取到的结果不一样，因为加锁读时不会采用 MVCC。

### 09、MySQL 如何实现一致性

一致性是事务追求的最终目标。原子性、持久性和隔离性，都是为了保证数据库状态的一致性。

此外，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。

实现一致性的措施包括：

> 保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证。
>
> 数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等。
>
> 应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致。


---

## 五、日志

---

### 01、MySQL 的日志

MySQL 的日志有很多种，如：binlog / 二进制日志、error log / 错误日志、查询日志、慢查询日志等。

此外 InnoDB 存储引擎还提供了两种事务日志：**redo log（重做日志）**、**undo log（回滚日志）**。

其中 **redo log 用于保证事务持久性；undo log 则是事务原子性和隔离性实现的基础**。

### 02、redo log 与 binlog 的区别

都可以记录写操作并用于数据的恢复。

**1. 作用不同：**

redo log 是用于 crash recovery 的，保证 MySQL 宕机也不会影响持久性；

binlog 是用于 point-in-time recovery 的，保证服务器可以基于时间点恢复数据，此外 binlog 还用于主从复制。

**2. 层次不同：**

redo log 是 InnoDB 存储引擎实现的；

binlog 是 MySQL 的服务器层（可以参考文章前面对 MySQL 逻辑架构的介绍）实现的，同时支持 InnoDB 和其他存储引擎。

**3. 内容不同：**

redo log 是物理日志，内容基于磁盘的 Page；

binlog 的内容是二进制的，根据 binlog_format 参数的不同，可能基于 sql 语句、基于数据本身或者二者的混合。

**4. 写入时机不同：**

binlog 在事务提交时写入；

redo log 的写入时机相对多元：

> 当事务提交时会调用 fsync 对 redo log 进行刷盘，这是默认情况下的策略，修改 innodb_flush_log_at_trx_commit 参数可以改变该策略，但事务的持久性将无法保证。
>
> 除了事务提交时，还有其他刷盘时机：如 master thread 每秒刷盘一次 redo log 等，这样的好处是不一定要等到 commit 时刷盘，commit 速度大大加快。

---

## 六、锁

---

### 01、锁的作用范围分类

由于加锁本身需要消耗资源（获得锁、检查锁、释放锁等都需要消耗资源），因此在锁定数据较多情况下使用表锁可以节省大量资源。

MySQL 中不同的存储引擎支持的锁是不一样的，例如 MyIsam 只支持表锁，而 InnoDB 同时支持表锁和行锁，且出于性能考虑，绝大多数情况下使用的都是行锁。

**1. 全局锁：**

在 DB 级别对整个数据库实例加锁。

- 加锁表现：

> 数据库处于只读状态。
>
> 阻塞对数据的增删改以及 DDL。

- 加锁方式：lock Flush tables with read lock

- 释放锁：unlock tables（发生异常时会自动释放）

- 作用场景：

> 全局锁主要用于做全库的逻辑备份，和设置数据库只读（set global readonly=true）相比，全局锁在发生异常时会自动释放

**2. 表锁：**

表级别对操作的整张表加锁，锁定颗粒度大，资源消耗少，不会出现死锁，但并发度低。

分为表共享锁和表排他锁，注意：意向锁为表锁，但是由存储引擎自己维护，无需用户手工命令干预。

- 显示加锁方式：lock tables {tb_name} read/write

- 释放锁：unlock table {tb_name}（连接中断也会自动释放）

**3. 行锁：**

InnoDB 支持行级别锁，锁粒度小并发度高，但是加锁开销大也很可能会出现死锁

innodb 行锁住的是索引项，注意当回表时，主键的聚簇索引也会加上锁。

- 加锁方式：

> 普通 select… 查询（不加锁）。
> 普通 insert、update、delete…（隐式加写锁）。
> select…lock in share mode（加读锁）。
> select…for update（加写锁）。

- 解锁：

> 提交 / 回滚事务（commit/rollback） kill 阻塞进程

行锁用的最多且更容易出现死锁问题。

### 02、锁的模式分类

我们常规理解的锁分为 2 大类：**读锁 / 共享锁（S）、写锁 / 排他锁（X）。**

两把锁之间的兼容性说明如下表：

| 兼容性 | X | S |
| :---: | :---: | :---: |
| X | 0 | 0 |
| S | 0 | 1 |

横轴表示已持有的锁，纵轴表示尝试获取的锁。

1 表示成功（即兼容，表现为正常进行下一步操作），0 表示失败（即冲突，表现为阻塞住当前操作）

排他锁和任何锁均不兼容。

数据库识别锁的冲突，最容易想到的识别方案就是遍历：

> step1：判断表是否已被其他事务用表锁锁住。
>
> step2: 判断表中的每一行是否已被行锁锁住。
>
> 其中 step2 需要遍历整个表，效率在数据库是没法接受的，因此 innodb 使用意向锁来解决这个问题。

Innodb 实现方案：

> T1 需要先申请表的意向共享锁 IS，成功后再申请一行的行锁 S。
>
> 注意：**意向共享锁是表级锁，由存储引擎自己维护，无需用户命手工命令干预**
>
> 在意向锁存在的情况下，上面的判断可以改为：
>
> step1：判断表是否已被其他事务用表锁锁住。
>
> step2: 发现表上有意向共享锁，说明表中行被共享行锁锁住了，因此，事务 B 申请表的写锁被阻塞。

此时就引入的意向锁，加入意向锁后，锁的兼容性分析如下表：

| 兼容性 | IX | IS | X | S |
| :---: | :---: | :---: | :---: | :---: |
| IX | 1 | 1 | 0 | 0 |
| IS | 1 | 1 | 0 | 1 |
| X | 0 | 0 | 0 | 0 |
| S | 0 | 1 | 0 | 1 |

### 03、InnoDB 中的行锁

**1. Record Lock / 记录锁**：

**行锁，单行记录上的锁，作用于索引记录。**

例如：SELECT id FROM t WHERE id=1 FOR UPDATE

**2. Gap Lock / 间隙锁**：

**锁定一个范围，但不包括记录本身。**
间隙锁是为了防止同一事务的两次当前读，出现幻读。

间隙锁是一种加在两个索引之间的锁（众所周知索引是有序的），或者加在第一个索引之前，或最后一个索引之后的间隙。

间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。

间隙锁只阻止其他事务插入到间隙中，他们不阻止其他事务在同一个间隙上获得间隙锁，所以 gap x lock 和 gap s lock 有相同的作用。

**3. Next-Key Lock / 下键锁**：

**相当于 Record Lock 加上 Gap Lock。不仅会锁定记录本身，还会锁定一个范围。**
对于行的查询，都是采用该方法，主要目的是解决幻读的问题。

**4. Insert Intention / 插入意向锁：**

该锁只会出现在 insert 操作执行前（并不是所有 insert 操作都会出现），目的是为了提高并发插入能力，注意虽有意向二字，但插入意向锁是行锁。

插入意向锁是在插入一行记录操作之前设置的一种特殊的间隙锁，这个锁释放了一种插入方式的信号，

亦即多个事务在相同的索引间隙插入时，如果不是插入间隙中相同的位置就不需要互相等待。

> 普通的 Gap Lock **不允许在**（上一条记录，本记录） 范围内插入数据
>
> 插入意向锁 Gap Lock **允许在**上一条记录，本记录） 范围内插入数据

假设有索引值 4，7，几个不同的事务准备插入 5，6，每个锁都在获得插入行的独占锁之前用插入意向锁各自锁住了 4，7 之间的间隙，但是不阻塞对方不冲突的插入行。

锁类型兼容矩阵，横轴表示已持有的锁，纵轴表示尝试获取的锁。1 表示成功（即兼容，表现为正常进行下一步操作），0 表示失败（即冲突，表现为阻塞住当前操作）：

| 兼容性 | Gap | Insert Intention | Record | Next-Key |
| :---: | :---: | :---: | :---: | :---: |
| Gap | 1 | 1 | 1 | 1 |
| Insert Intention | 0 | 1 | 1 | 0 |
| Record | 1 | 1 | 0 | 0 |
| Next-Key | 1 | 1 | 0 | 0 |

### 04、锁组合

锁的模式：

> lock_s / 读锁，共享锁。
>
> lock_x / 写锁，排它锁。

锁的类型：

> Record_Lock ：锁记录。
>
> Gap_Lock ：锁记录前的 GAP。
>
> Next-Key Lock ：同时锁记录 + 记录前的 GAP。
>
> insert_Intention_Lock ：插入意向锁，其实是特殊的 GAP 锁。

锁模型可以和锁类型任意组合，如：

> locks gap before rec，表示为 gap 锁：lock->type_mode & LOCK_GAP
>
> locks rec but not gap，表示为记录锁，非 gap 锁：lock->type_mode & LOCK_REC_NOT_GAP
>
> insert intention，表示为插入意向锁：lock->type_mode & LOCK_INSERT_INTENTION
>
> waiting，表示锁等待：lock->type_mode & LOCK_WAIT

在 mysql 源码中使用了 uint32 类型来表示锁，最低的 4 个 bit 表示 lock_mode，5-8 bit 表示 lock_type（目前只用了 5 和 6 位，大小为 16 和 32
，表示 LOCK_TABLE 和 LOCK_REC），剩下的高位 bit 表示行锁的类型 record_lock_type。

### 05、悲观锁和乐观锁

**悲观锁**：

指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。

悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。

在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。**读取数据时给加锁**，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。

悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。

**乐观锁**：

乐观锁机制采取了更加宽松的加锁机制。**大多是基于数据版本（Version）记录机制实现**。

数据版本：

> 为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。

实现过程：

> 读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。

---

## 参考链接

---

- [MySQL 官方文档——幻影行](https://dev.mysql.com/doc/refman/8.0/en/innodb-next-key-locking.html)
- [深入学习 MySQL 事务：ACID 特性的实现原理](https://www.cnblogs.com/kismetv/p/10331633.html)
- [mysql 锁机制的再研究 ](https://mp.weixin.qq.com/s/FJKRUyGUNgDYRvPAy20x3w)
- [MySQL 中幻读出现的原因及解决方案](https://blog.csdn.net/nandao158/article/details/116007366)
- [Innodb 锁机制：Next-Key Lock 浅谈](https://www.cnblogs.com/zhoujinyi/p/3435982.html)
- [MySQL next-key lock 加锁范围是什么？](https://segmentfault.com/a/1190000040129107)
- [间隙锁和 next-key lock](https://www.jianshu.com/p/d1aba64b5c03)
- [MySQL 教程（十）---MySQL ACID 实现原理](https://www.lixueduan.com/post/mysql/10-acid/)
- [Innodb 中的事务隔离级别和锁的关系](https://tech.meituan.com/2014/08/20/innodb-lock.html)
- [MySQL 设计之三范式](https://segmentfault.com/a/1190000022843792)
- [MySQL 是如何保证一致性、原子性和持久性的](https://cloud.tencent.com/developer/article/1600883)
- [MySQL 索引那些事：什么是索引？为什么加索引就查得快了？](http://blog.itpub.net/70000181/viewspace-2776159/)
- [MySQL 索引类型、索引原理、索引分析与优化、慢查询优化](http://fishleap.top/pages/c62f50/)
- [MySQL 探秘（三）MySQL 索引原理](https://princeli.com/mysql%E6%8E%A2%E7%A7%98%E4%B8%89mysql%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86/)
- [MySql 创建索引原则](https://developer.aliyun.com/article/6719)
- [mysql 索引失效的场景](https://blog.csdn.net/vtopqx/article/details/112176732)
- [MySQL 索引连环 18 问](https://www.dockone.io/article/2434410)
- [解决 hash 冲突的三个方法](https://www.cnblogs.com/wuchaodzxx/p/7396599.html)
- [解决哈希冲突的常用方法分析](https://cloud.tencent.com/developer/article/1672781)
- []()

---












