# MySQL

---

## Content / 目录

---

- [一、基础部分](#基础部分)
    - [01、三大范式：列原子性、部分依赖、循环依赖](#三大范式)
    - [02、查询语句执行流程](#查询语句执行流程)
    - [03、更新语句执行过程](#更新语句执行过程)
- [二、提高部分](#提高部分)
    - [01、SQL 优化](#SQL-优化)
    - [02、MySQL 高效分页：索引自增，用 id 做范围查询](#MySQL-高效分页)
- [三、索引](#索引)
    - [01、为什么需要索引：磁盘的遍历性能太低](#为什么需要索引)
    - [02、索引的优点](#索引的优点)
    - [03、索引的缺点](#索引的缺点)
    - [04、什么情况下需要建索引](#什么情况下需要建索引)
    - [05、什么情况下不建索引](#什么情况下不建索引)
    - [06、索引的分类：主键、普通索引、唯一、全文索引](#索引的分类)
    - [07、联合索引 / 组合索引 / 复合索引：最左前缀原则](#联合索引-/-组合索引-/-复合索引)
    - [08、前缀索引：前部分字符做索引](#前缀索引)
    - [09、覆盖索引：避免回表](#覆盖索引)
    - [10、索引下推：对二级索引有效](#索引下推)
    - [11、聚簇索引、非聚簇索引的区别：数据和主键索引是否存储在一起](#聚簇索引、非聚簇索引的区别)
    - [12、主键索引、非主键索引的区别：叶子节点存放存放的是否是数据](#主键索引、非主键索引的区别)
    - [13、MyISAM 和 InnoDB 的区别](#MyISAM-和-InnoDB-的区别)
    - [14、InnoDB 中的 B+Tree 索引](#InnoDB-中的-B+Tree-索引)
    - [15、B 树、B+ 树的区别](#B-树、B+-树的区别)
    - [16、Hash 索引](#Hash-索引)
    - [17、Hash 索引、B+ 树索引的区别](#Hash-索引、B+-树索引的区别)
    - [18、有那些解决 hash 冲突的方法](#有那些解决-hash-冲突的方法)
    - [19、为什么官方建议使用自增长主键](#为什么官方建议使用自增长主键)
    - [20、索引失效](#索引失效)
    - [21、如何做索引优化](#如何做索引优化)
    - [22、索引的设计原则](#索引的设计原则)
- [四、事务](#事务)
    - [01、事务的特性 / ACID：独立单元、合法完整、互不干扰、永久改变](#事务的特性-/-ACID)
    - [02、**事务的隔离级别**：读未提交、读已提交、可重复读、串行化](#事务的隔离级别（重点）)
    - [03、**幻读** / Phantom Read：快照读和当前读一起使用](#幻读-/-Phantom-Read（重点）)
    - [04、MVCC 的实现原理：read view 和版本链](#MVCC-的实现原理)
    - [05、**快照读和当前读**](#快照读和当前读（重点）)
    - [06、MySQL 如何避免幻读](#MySQL-如何避免幻读（重点）)
    - [07、MySQL 的 InnoDB 如何实现 MVCC：事务的版本号](#MySQL-的-InnoDB-如何实现-MVCC)
    - [08、MySQL 如何实现原子性：undo log](#MySQL-如何实现原子性)
    - [09、MySQL 如何实现持久性：redo log](#MySQL-如何实现持久性)
    - [10、MySQL 如何实现隔离性：锁机制](#MySQL-如何实现隔离性)
    - [11、MySQL 如何实现一致性：数据库层面、应用层面](#MySQL-如何实现一致性)
- [五、日志](#日志)
    - [01、MySQL 的日志：redo log、undo log](#MySQL-的日志)
    - [02、redo log 与 binlog 的区别](#redo-log-与-binlog-的区别)
- [六、锁](#锁)
    - [01、锁的作用范围分类](#锁的作用范围分类)
    - [02、锁的模式分类：共享锁、排他锁](#锁的模式分类)
    - [03、**InnoDB 中的行锁**：记录锁、间隙锁、临键锁、插入意向锁](#InnoDB-中的行锁（重点）)
    - [04、**间隙锁产生的条件**](#间隙锁产生的条件（重点）)
    - [05、**临键锁产生的条件**](#临键锁产生的条件（重点）)
    - [06、锁组合](#锁组合)
    - [07、悲观锁和乐观锁：读数据加锁、读版本号后更新时再比对](#悲观锁和乐观锁)
- [七、MySQL 架构](#MySQL-架构)
    - [01、MySQL 核心架构](#MySQL-核心架构)
    - [02、分库分表：垂直划分、水平划分](#分库分表)
    - [03、什么是 MySQL 主从同步](#什么是-MySQL-主从同步)
    - [04、为什么要做主从同步](#为什么要做主从同步)

---

## 基础部分

---

### 三大范式

**1. 第一范式 / 1NF：**

**要保证字段的原子性。**

数据库表中不能出现重复记录，每个字段是原子性的不能再分。

> 比如：在学生表中，联系方式这个字段出现了邮件和电话号码一起存，用逗号连接的情况。一个值里不能同时包含两种数据，因为会违反第一范式。

**2. 第二范式 / 2NF：**

**非主键字段完全依赖主键，不能产生部分依赖。**

第二范式是建立在第一范式基础上的，另外要求所有非主键字段完全依赖主键，不能产生部分依赖。

> 比如：在学生表中，增加老师名字这个字段，但是老师的名字信息不依赖于表的主键，违反了第二范式。

**3. 第三范式 / 3NF：**

**非主键字段和主键字段之间不能产生传递依赖。**

建立在第二范式基础上的，非主键字段不能传递依赖于主键字段。

> 比如：在学生表中，增加班级编号、班级名称这两个字段。班级名称依赖于班级编号，班级编号依赖于学生表的主键，产生了传递依赖。

**4. 逆范式：**

**通过增加冗余或重复的数据来提高数据库的读性能**。

### 什么是分区表

分区表是一个独立的逻辑表，但是底层由多个物理子表组成。

当查询条件的数据分布在某一个分区的时候，查询引擎只会去某一个分区查询，而不是遍历整个表。

在管理层面，如果需要删除某一个分区的数据，只需要删除对应的分区即可。

### 分区表类型

按照范围分区。

在 /var/lib/mysql/data/ 可以找到对应的数据文件，每个分区表都有一个使用 #分隔命名的表文件。

list 分区：

> 对于 List 分区，分区字段必须是已知的，如果插入的字段不在分区时枚举值中，将无法插入。

hash 分区：

> 可以将数据均匀地分布到预先定义的分区中。

### 查询语句执行流程

查询语句的执行流程如下：权限校验、查询缓存、分析器、优化器、权限校验、执行器、引擎。

举个例子，查询语句如下：

select * from user where id > 1 and name = '条件';

1、首先检查权限，没有权限则返回错误；

2、MySQL8.0 以前会查询缓存，缓存命中则直接返回，没有则执行下一步；

3、词法分析和语法分析。提取表名、查询条件，检查语法是否有错误；

4、两种执行方案，先查 id > 1 还是 name = '条件'，优化器根据自己的优化算法选择执行效率最好的方案；

5、校验权限，有权限就调用数据库引擎接口，返回引擎的执行结果。

### 更新语句执行过程

更新语句执行流程如下：分析器、权限校验、执行器、引擎、redo log（prepare 状态）、binlog、redo log（commit 状态）

举个例子，更新语句如下：

update user set name = '条件' where id = 1;

1、先查询到 id 为 1 的记录，有缓存会使用缓存。

2、拿到查询结果，将 name 更新为条件，然后调用引擎接口，写入更新数据，innodb 引擎将数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态。

3、执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为 commit 状态。

4、更新完成。

为什么记录完 redo log，不直接提交，而是先进入 prepare 状态：

> 假设先写 redo log 直接提交，然后写 binlog，写完 redo log 后，机器挂了，binlog 日志没有被写入，
>
> 那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 binlog 并没有记录该数据，
>
> 后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。

### exist 和 in 的区别

exists 用于对外表记录做筛选。exists 会遍历外表，将外查询表的每一行，代入内查询进行判断。当 exists 里的条件语句能够返回记录行时，条件就为真，返回外表当前记录。反之如果
exists 里的条件语句不能返回记录行，条件为假，则外表当前记录被丢弃。

select a.* from A awhere exists(select 1 from B b where a.id=b.id)

in 是先把后边的语句查出来放到临时表中，然后遍历临时表，将临时表的每一行，代入外查询去查找。

select * from Awhere id in(select id from B)

子查询的表比较大的时候，使用 exists 可以有效减少总的循环次数来提升速度；当外查询的表比较大的时候，使用 in 可以有效减少对外查询表循环遍历来提升速度。

### MySQL 中使用 IN 会不会走索引

如果你 source 字段是一个 unique，in 肯定会用到索引。

如果 source 字段来来去去就那么十几个值，这种情况下影响结果集巨大，就会全表扫描。这种情况全表扫描还要快于利用索引，只要理解索引的本质不难明白 MySQL 为何不使用索引。

### truncate、delete 与 drop 区别

相同点：

> truncate 和不带 where 子句的 delete、以及 drop 都会删除表内的数据。
>
> drop、truncate 都是 DDL 语句（数据定义语言），执行后会自动提交。

不同点：

> truncate 和 delete 只删除数据不删除表的结构；drop 语句将删除表的结构被依赖的约束、触发器、索引；
>
> 一般来说，执行速度: drop > truncate > delete。

### having 和 where 的区别

二者作用的对象不同，where 子句作用于表和视图，having 作用于组。

where 在数据分组前进行过滤，having 在数据分组后进行过滤。

### 用过 processlist 吗

show processlist 或 show full processlist 可以查看当前 MySQL 是否有压力，正在运行的 SQL，有没有慢 SQL 正在执行。

返回参数如下：

> id：线程 ID，可以用 kill id 杀死某个线程。
>
> db：数据库名称。
>
> user：数据库用户。
>
> host：数据库实例的 IP。
>
> command：当前执行的命令，比如 Sleep，Query，Connect 等。
>
> time：消耗时间，单位秒。
>
> state：执行状态，主要有以下状态：
>
> > Sleep，线程正在等待客户端发送新的请求。
> >
> > Locked，线程正在等待锁。
> >
> > Sending data，正在处理 SELECT 查询的记录，同时把结果发送给客户端。
> >
> > Kill，正在执行 kill 语句，杀死指定线程。
> >
> > Connect，一个从节点连上了主节点。
> >
> > Quit，线程正在退出。
> >
> > Sorting for group，正在为 GROUP BY 做排序。
> >
> > Sorting for order，正在为 ORDER BY 做排序。
>
> info：正在执行的 SQL 语句。

---

## 提高部分

---

### 怎么优化大表

某个表有近千万数据，查询比较慢，如何优化？

当 MySQL 单表记录数过大时，数据库的性能会明显下降，一些常见的优化措施如下：

> 限定数据的范围。比如：用户在查询历史信息的时候，可以控制在一个月的时间范围内；
>
> 读写分离。经典的数据库拆分方案，主库负责写，从库负责读；
>
> 通过分库分表的方式进行优化，主要有垂直拆分和水平拆分。

### SQL 优化

尽量避免子查询。

分页的参数不应过大。

where 字段加索引。

不要使用 select *。

### MySQL 高效分页

普通 LIMIT 的问题：

> 取出 N+M 行，丢弃前 N 行，返回 N ~ N+M 行的记录，如果 N 值非常大，效率极差（表记录 1500w，N=10000000，M=30 需要 9 秒）。

优化方案：

> SELECT id FROM ttl_product_info WHERE id > N LIMIT M。
>
> id 列是索引列，id > N 属于 range 级别，效率自然高，然后从位置开始取 30 条记录，效率极高（表记录 1500w，N=10000000，M=30，需要 0.9 毫秒）

高效分页有三个前提条件：

1. id 是唯一索引，而且单调递增。
2. N 的值是上一次查询的记录的最后一条 id（需要前端保存一下，不能直接用传统的方法获得）。
3. 不支持跨页查询，只能按照第 1，2，3，4 页这样查询逐页查询。

---

## 索引

---

### 索引是什么

**索引 / index：**

帮助 MySQL 高效获取数据的数据结构。

### 索引的作用

数据是以文件的形式存放在磁盘上面的，每一行数据都有它的磁盘地址。如果没有索引的话，要从 500 万行数据里面检索一条数据，只能依次遍历这张表的全部数据，直到找到这条数据。

有了索引之后，只需要在索引里面去检索这条数据就行了，因为它是一种特殊的专门用来快速检索的数据结构，我们找到数据存放的磁盘地址以后，就可以拿到数据了。

### 为什么需要索引

数据是存储在磁盘上的，查询数据时，如果没有索引，会加载所有的数据到内存，依次进行检索，读取磁盘次数较多。

有了索引，就不需要加载所有数据，因为 B + 树的高度一般在 2-4 层，最多只需要读取 2-4 次磁盘，查询速度大大提升。

### 索引的优点

1、加快数据查找的速度。

2、为用来排序或者是分组的字段添加索引，可以加快分组和排序的速度。

3、加快表与表之间连接的速度。

### 索引的缺点

1、建立索引需要占用物理空间。

2、会降低表的增删改的效率，因为每次对表记录进行增删改，需要进行动态维护索引，导致增删改时间变长。

### 什么情况下需要建索引

1、经常用于查询的字段。

2、经常用于连接的字段建立索引，可以加快连接的速度。

3、经常需要排序的字段建立索引，因为索引已经排好序，可以加快排序查询速度。

### 什么情况下不建索引

1、where 条件中用不到的字段不适合建立索引。

2、表记录较少。

3、需要经常增删改。

4、参与列计算的列不适合建索引。

5、区分度不高的字段不适合建立索引，如性别等。

### 索引的分类

**1. 主键索引 / 主索引：**

即主索引，根据主键 pk_clolum（length）建立索引，不允许重复，不允许空值。

**2. 普通索引：**

用表中的普通列构建的索引，没有任何限制。

**3. 唯一索引：**

用来建立索引的列的值必须是唯一的，允许空值。

**4. 全文索引：**

针对比较大的数据，比如我们存放的是消息内容，有几 KB 的数 据的这种情况，如果要解决 like 查询效率低的问题，可以创建全文索引。只有文本类型 的字段才可以创建全文索引，比如
char、varchar、text。

**5. 联合索引：**

用多个列组合构建的索引，这多个列中的值不允许有空值。

### 联合索引 / 组合索引 / 复合索引

**联合索引**：

两个或更多个列上的索引。

> 在使用组合索引的时候可能因为列名长度过长而导致索引的 key 太大，导致效率降低，在允许的情况下，可以只取 col1 和 col2 的前几个字符作为索引。

联合索引好处：

> 减少开销：建一个联合索引（col1,col2,col3），实际相当于建了（col1），（col1,col2），（col1,col2,col3）三个索引。减少磁盘空间的开销。
>
> 覆盖索引：对联合索引（col1,col2,col3），如果有如下的 sql: select col1,col2,col3 from test where col1=1 and col2=2。那么 MySQL 可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机 io 操作。覆盖索引是主要的提升性能的优化手段之一。
>
> 效率高：索引列越多，通过索引筛选出的数据越少。

**最左前缀原则：**

> MySQL 建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。
>
> MySQL 会一直向右匹配直到遇到范围查询（>、<、between、like）就停止匹配，比如 a = 1 and b = 2 and c > 3 and d = 4 如果建立（ a,b,c,d）顺序的索引，d 是用不到索引的，如果建立（a,b,d,c）的索引则都可以用到，a,b,d 的顺序可以任意调整。
>
> = 和 in 可以乱序，比如 a = 1 and b = 2 and c = 3 建立（a,b,c）索引可以任意顺序，mysql 的查询优化器会帮你优化成索引可以识别的形式。

所以在建立联合索引的时候要把最常用的列放在最左边。

### 前缀索引

**前缀索引：**

对文本或者字符串的前几个字符建立索引，这样索引的长度更短，查询速度更快。

创建前缀索引的关键在于选择足够长的前缀以保证较高的索引选择性。索引选择性越高查询效率就越高，因为选择性高的索引可以让 MySQL 在查找时过滤掉更多的数据行。

但是 MySQL 不能在 ORDER BY 或 GROUP BY 中使用前缀索引，也不能把它们用作覆盖索引。

### 覆盖索引

**覆盖索引 / covering index：**

在覆盖索引里面，不管是单列索引还是联合索引，如果 select 的数据列只用从索引中就能够取得，不必从数据区中读取，这时使用的索引就叫覆盖索引，避免了**回表**。

> 对联合索引（col1,col2,col3），如果有如下的 sql: select col1,col2,col3 from test where col1=1 and col2=2。
>
> 那么 MySQL 可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机 io 操作。覆盖索引是主要的提升性能的优化手段之一。

**回表：**

非主键索引，我们先通过索引找到主键索引的键值，再通过主键值查出索引里面没有的数据，它比基于主键索引的查询多扫描了一棵索引树，这个过程就叫回表。

### 索引下推

MySQL 服务层负责 SQL 语法解析、生成执行计划等，并调用存储引擎层去执行数据的存储和检索。

索引下推的下推其实就是指将部分上层（服务层）负责的事情，交给了下层（引擎层）去处理。

我们来具体看一下，在没有使用 ICP 的情况下，MySQL 的查询：

> 存储引擎读取索引记录；
>
> 根据索引中的主键值，定位并读取完整的行记录；
>
> 存储引擎把记录交给 Server 层去检测该记录是否满足 WHERE 条件。

使用 ICP 的情况下，查询过程：

> 存储引擎读取索引记录（不是完整的行记录）；
>
> 判断 WHERE 条件部分能否用索引中的列来做检查，条件不满足，则处理下一行索引记录；
>
> 条件满足，使用索引中的主键去定位并读取完整的行记录（就是所谓的回表）；
>
> 存储引擎把记录交给 Server 层，Server 层检测该记录是否满足 WHERE 条件的其余部分。

MySQL 5.6 引入了索引下推优化，默认开启，使用 SET optimizer_switch = ‘index_condition_pushdown=off’; 可以将其关闭。

> 有了索引下推优化，可以在减少**回表**次数。
>
> 在 InnoDB 中只针对二级索引有效。

官方文档中给的例子和解释如下：

> 在 people_table 中有一个二级索引（zipcode，lastname，address），查询是 SELECT * FROM people WHERE zipcode=’95054′ AND lastname LIKE ‘% etrunia%’ AND address LIKE ‘% Main Street%’;
>
> 如果没有使用索引下推技术，则 MySQL 会通过 zipcode=’95054’**从存储引擎中查询对应的数据，返回到 MySQL 服务端**，然后 MySQL 服务端基于 lastname LIKE ‘% etrunia%’ and address LIKE ‘% Main Street%’来判断数据是否符合条件。
>
> 如果使用了索引下推技术，则 MySQL 首先会返回符合 zipcode=’95054’的索引，然后根据 lastname LIKE ‘% etrunia%’ and address LIKE ‘% Main Street%’来判断索引是否符合条件。如果符合条件，则根据该索引来定位对应的数据，如果不符合，则直接 reject 掉。

总结：索引下推产生的条件有两个，index_condition_pushdown 不关，查询条件中的字段必须都在二级索引中。

### 聚簇索引、非聚簇索引的区别

**聚簇索引**：

聚集索引的叶子节点就是整张表的行记录。InnoDB 主键使用的是聚簇索引。聚集索引要比非聚集索引查询效率高很多

InnoDB 存储引擎采用的是聚簇索引，聚簇索引的数据和主键索引存储在一起。

聚簇索引的主索引的叶子结点存储的是键值对应的数据本身，辅助索引的叶子结点存储的是键值对应的数据的主键键值。因此主键的值长度越小越好，类型越简单越好。

**非聚簇索引**：

非聚簇索引的数据表和索引表是分开存储的。

MyISAM 存储引擎采用的是非聚簇索引，非聚簇索引的主索引和辅助索引几乎是一样的，只是主索引不允许重复，不允许空值，他们的叶子结点的 key 都存储指向键值对应的数据的物理地址。

### 主键索引、非主键索引的区别

**非主键索引**的叶子节点存放的是主键的值，而**主键索引**的叶子节点存放的是整行数据，

其中非主键索引也被称为**二级索引**，而主键索引也被称为**聚簇索引**。

### 常见的存储引擎

**InnoDB：**

InnoDB 是 MySQL 默认的事务型存储引擎，使用最广泛，基于聚簇索引建立的。InnoDB 内部做了很多优化，如能够自动在内存中创建自适应 hash 索引，以加速读操作。

优点：支持事务和崩溃修复能力；引入了行级锁和外键约束。

缺点：占用的数据空间相对较大。

适用场景：需要事务支持，并且有较高的并发读写频率。

**MyISAM：**

数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，可以使用 MyISAM 引擎。MyISAM 会将表存储在两个文件中，数据文件.MYD 和索引文件.MYI。

优点：访问速度快。

缺点：MyISAM 不支持事务和行级锁，不支持崩溃后的安全恢复，也不支持外键。

适用场景：对事务完整性没有要求；表的数据都会只读的。

### MyISAM 和 InnoDB 的区别

是否支持行级锁 : MyISAM 只有表级锁，而 InnoDB 支持行级锁和表级锁，默认为行级锁。

是否支持事务和崩溃后的安全恢复：MyISAM 不提供事务支持。而 InnoDB 提供事务支持，具有事务、回滚和崩溃修复能力。

是否支持外键： MyISAM 不支持，而 InnoDB 支持。

是否支持 MVCC ：MyISAM 不支持，InnoDB 支持。应对高并发事务，MVCC 比单纯的加锁更高效。

MyISAM 不支持聚集索引，InnoDB 支持聚集索引。

### InnoDB 中的 B+Tree 索引

**B+Tree 索引：**

B+ 树是基于 B 树和叶子节点顺序访问指针进行实现，它具有 B 树的平衡性，并且通过顺序访问指针来提高区间查询的性能。

在 B+ 树中，节点中的 key 从左到右递增排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。

进行查找操作时，首先在根节点进行二分查找，找到 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的数据项。

MySQL 数据库使用最多的索引类型是 BTREE 索引，底层基于 B + 树数据结构来实现。

InnoDB 中，表数据文件本身就是按 B+Tree 组织的一个索引结构，叶节点 data 域保存了完整的数据记录。

这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引，所以必须有主键。

如果没有显示定义，自动为生成一个隐含字段作为主键，这个字段长度为 6 个字节，类型为长整型。

B+Tree 索引的特点：

> 它是 B Tree 的变种，B Tree 能解决的问题，它都能解决。B Tree 解决的两大问题是什么？（每个节点存储更多关键字；路数更多）
>
> 扫库、扫表能力更强（如果我们要对表进行全表扫描，只需要遍历叶子节点就可以 了，不需要遍历整棵 B+Tree 拿到所有的数据）
>
> B+Tree 的磁盘读写能力相对于 B Tree 来说更强（根节点和枝节点不保存数据区，所以一个节点可以保存更多的关键字，一次磁盘加载的关键字更多）
>
> 排序能力更强（因为叶子节点上有下一个数据区的指针，数据形成了链表）
>
> 效率更加稳定（B+Tree 永远是在叶子节点拿到数据，所以 IO 次数是稳定的）

### B 树、B+ 树的区别

视频讲解：[1. mysql 面试题 - 深入理解 B + 树原理](https://www.bilibili.com/video/BV15V411p7pi)

区别：

1、B 树的叶子节点是不相连的。B+ 树的叶子节点是通过链表串联的。

2、B 树因为节点存的是主键的地址，查找的过程过，在非叶子节点查到匹配的数据，不会继续查子节点。B+ 树的非叶子节点不存数据，只存值。

3、B 树的叶子节点存的全是地址。B+ 树的叶子节点存有字段和值，叶子节点的 key 还存了数据的物理地址。

**B Tree / B 树 / 多路平衡查找树：**

B 树在枝节点和叶子节点存储键值、数据地址、节点引用。

它有一个特点：分叉数（路数）永远比关键字数多 1。

假如树的度为 2d（d>1），高度为 h，那么 B Tree 要满足以下条件：

1. 每个叶子结点的高度一样，等于 h；
2. 每个非叶子结点由 n-1 个 key 和 n 个指针 point 组成，其中 d<=n<=2d,key 和 point 相互间隔，结点两端一定是 key；
3. 叶子结点指针都为 null；
4. 非叶子结点的 key 都是 [key,data] 二元组，其中 key 表示作为索引的键，data 为键值所在行的数据；

**B+Tree / B+ 树：**

B+Tree 是 BTree 的一个变种，设 d 为树的度数，h 为树的高度，B+Tree 和 BTree 的不同主要在于：

1. B+Tree 中的非叶子结点不存储数据，只存储键值；
2. B+Tree 的叶子结点没有指针，所有键值都会出现在叶子结点上，且 key 存储的键值对应 data 数据的物理地址；
3. B+Tree 的每个非叶子节点由 n 个键值 key 和 n 个指针 point 组成，键值数量和指针数量相同；
4. B+Tree 搜索到键值不会直接返回，会到最后一层的叶子节点；
5. B+Tree 的每个叶子节点增加了一个指向相邻叶子节点的指针，它的最后一个数 据会指向下一个叶子节点的第一个数据，形成了一个有序链表的结构。
6. 它是根据左闭右开的区间[和)来检索数据。

### InnoDB 为什么用 B+ 树不用跳表

视频讲解：[为什么 MySQL 要用 B + 树而不是用跳表呢](https://www.bilibili.com/video/BV1eY411p7bo)

1、B+ 树检索效率更高，数据分布更均匀。跳表的索引层级太深

2、B+ 树查多条记录的磁盘 IO 更少。B+ 树的叶子节点可以存储多条数据，所有的叶子节点构成了单向链表。

### Hash 索引

**Hash 索引：**

哈希索引是基于哈希表实现的，对于每一行数据，存储引擎会对索引列进行哈希计算得到哈希码，并且哈希算法要尽量保证不同的列值计算出的哈希码值是不同的，将哈希码的值作为哈希表的 key
值，将指向数据行的指针作为哈希表的 value 值。这样查找一个数据的时间复杂度就是 O (1)，一般多用于精确查找。

Hash 结构由 Hash 表来实现的，是根据键值 <key，value> 存储数据的结构；Hash 索引可以方便的提供等值查询，对于范围查询就需要全表扫描；Hash 结构在 MySQL 中主要应用在
Memory 原生的 Hash 索引 、InnoDB 自适应哈希索引。

每插入一个元素会把我们的索引字段做一次 hash 计算，把运算的到的结果值和这一行的所在磁盘地址做一个映射。

对索引元素的值做一次 hash 运算就可以在 hash 映射表里快速找到这一行的磁盘文件地址，经过一次 hash 就可以快速定位到索引所在行的磁盘文件地址，hash
这么快，表有一亿个数据按这种算法，那也就可能经历一次 hash 运算就可以快速找到某页任意一行数据元素的所在的磁盘文件地址，那比 B+Tree 快的多啊。就是快的多，为啥 99.99 的都是
B+Tree 不是 hash 呢？

hash 的等值查询比 B+Tree 快，上亿依然很快，为啥很快却不使用？最主要的原因是，如果使用范围查找，hash 就没有用武之地了。

范围查找很常用，况且 B+Tree 还支持排序，所以基本就不怎么用 hash 这种数据结构做索引了。

### Hash 索引、B+ 树索引的区别

1、哈希索引不支持排序，因为哈希表是无序的。

2、哈希索引不支持范围查找。

3、哈希索引不支持模糊查询及多列索引的最左前缀匹配。

4、因为哈希表中会存在哈希冲突，所以哈希索引的性能是不稳定的，而 B + 树索引的性能是相对稳定的，每次查询都是从根节点到叶子节点。

### 有那些解决 Hash 冲突的方法

**1. 链地址法 / 拉链法：**

为每个 Hash 值建立一个单链表，当发生冲突时，将记录插入到链表中。

实际的哈希表实现中，使用最多的是链地址法。

**2. 再哈希法：**

同时构造多个哈希函数，当产生冲突时，计算另一个哈希函数的值，直到冲突不再产生。

这种方法不易产生聚集，但增加了计算时间。

**3. 建立公共溢出区：**

将哈希表分为基本表和溢出表两部分，为所有发生 hash 冲突的关键字记录一个公共的溢出区来存放。

**4. 开放定址法：**

使用某种探测算法在散列表中寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到。

- 开放定址法实现方式：

> 线性探查：发生 hash 冲突时，顺序查找下一个位置，直到找到一个空位置（固定步长 1 探测）。
>
> 二次探查：在发生 hash 冲突时，在表的左右位置进行按一定步长跳跃式探测（固定步长 n 探测）。
>
> 伪随机探测：在发生 hash 冲突时，根据公式生成一个随机数，作为此次探测空位置的步长（随机步长 n 探测）。

### 为什么官方建议使用自增长主键

索引树只能定位到某一页，每一页内的插入还是需要通过比较、移动插入的，**所以有序主键可以提升插入效率**。

结合 B+Tree 的特点，自增主键是连续的，在插入过程中尽量减少页分裂，即使要进行页分裂，也只会分裂很少一部分。

并且能减少数据的移动，每次插入都是插入到最后。**总之就是减少分裂和移动的频率**。

### 索引失效

1. 对于组合索引，不是使用组合索引最左边的字段，则不会使用索引。
2. 以 % 开头的 like 查询如 %abc，无法使用索引；非 % 开头的 like 查询如 abc%，相当于范围查询，会使用索引。
3. 查询条件中列类型是字符串，没有使用引号，可能会因为类型不同发生隐式转换，使索引失效。
4. 判断索引列是否不等于某个值时。
5. 对索引列进行运算。
6. 查询条件使用 or 连接，也会导致索引失效。


1. 索引遇到范围查询就会失效，比如：>、<、between、like。
2. where 语句中包含 or 时，可能会导致索引失效
3. where 语句中索引列使用了负向查询，可能会导致索引失效
4. 索引字段可以为 null，使用 is null 或 is not null 时，可能会导致索引失效
5. 在索引列上使用内置函数，一定会导致索引失效 4.1 隐式类型转换导致的索引失效 4.2 隐式字符编码转换导致的索引失效
6. 对索引列进行运算，一定会导致索引失效
7. like 通配符可能会导致索引失效
8. 联合索引中，where 中索引列违背最左前缀原则，一定会导致索引失效
9. **MySQL 优化器**的最终选择，不走索引

### 如何做索引优化

1. 选择唯一性索引。唯一索引可以更快速的通过该索引来确定某条记录。
2. 为经常需要排序、分组和联合操作的字段建立索引。排序操作会浪费很多时间。
3. 为常作为查询条件的字段建立索引。
4. 限制索引的数目。越多的索引，会使更新表变得很浪费时间。
5. 尽量使用数据量少的索引。如果索引的值很长，那么查询的速度会受到影响。
6. 尽量使用前缀来索引。如果索引字段的值很长，最好使用值的前缀来索引。
7. 删除不再使用或者很少使用的索引，从而减少索引对更新操作的影响。
8. 建立组合索引，必须把区分度高的字段放在前面。

### 索引的设计原则

索引列的区分度越高，索引的效果越好。比如使用性别这种区分度很低的列作为索引，效果就会很差。

尽量使用短索引，对于较长的字符串进行索引时应该指定一个较短的前缀长度，因为较小的索引涉及到的磁盘 I/O 较少，查询速度更快。

索引不是越多越好，每个索引都需要额外的物理空间，维护也需要花费时间。

利用最左前缀原则。

---

## 事务

---

### 事务的特性 / ACID

**1. 原子性 / Atomicity：**

保证每个事务都被视为一个单独的单元，要么完全成功，要么完全失败。一个事务中的所有操作，**要么全部执行成功，要么全部不执行**。

**2. 一致性 / Consistency：**

事务执行结束后，**数据库的完整性约束**没有被破坏，**事务执行的前后都是合法的数据状态**。

数据库的完整性约束包括但不限于：实体完整性（如行的主键存在且唯一）、列完整性（如字段的类型、大小、长度要符合要求）、外键约束、用户自定义完整性（如转账前后，两个账户余额的和应该不变）。

**3. 隔离性 / Isolation：**

事务内部的操作及使用的数据对正在进行的其他事务是隔离的，**并发执行的各个事务之间不能互相干扰**。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。

**4. 持久性 / Durability：**

事务一旦提交，**对数据库的改变就应该是永久性的**。接下来的其他操作或故障不应该对其有任何影响。

### 事务的隔离级别（重点）

**1. 读未提交 / Read Uncommitted：**

可以读取到其他会话中未提交事务修改的数据。读未提交可能出现脏读。

**脏读：在事务中读到了其他会话未提交的数据。**

**2. 读已提交 / Read Committed（RC）：**

只能读取到已经提交的数据。Oracle 等多数数据库默认都是该级别。读已提交可能出现不可重复读。

**不可重复读：在事务中读到了其他会话已经提交的数据。**

**3. 可重复读 / Repeated Read（RR）：**

在同一个事务内的**查询**都是事务开始时刻一致的，InnoDB 默认级别。在 SQL 标准中，该隔离级别消除了不可重复读。可重复读可能出现幻读。

**幻读：在事务中使用当前读，读到了其他会话提交的新数据。**

**4. 串行化 / Serializable：**

完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。串行化没有幻读，但实际中因为性能等原因不会采用这种级别。

### 幻读 / Phantom Read（重点）

**幻读**：是幻影行 / Phantom Rows 产生的负面结果，快照读和当前读一起使用就能复现。

幻读典型场景复现：

> 事务 A 按条件读取数据时，事务 B 插入了相同条件的新数据，事务 A 再次按原先条件进行读取操作**修改**时，读取到了事务 B 插入的新数据。
>
> 事务 C 查不出事务 D 新增的记录，但是自身插入相同主键的记录会报主键冲突。

出现的原因：

> 如果事务中都是用快照读，就不会产生幻读，**快照读和当前读一起使用的时候可能产生幻读**。

解决办法：

> 为了防止幻读，InnoDB 采用了 **Next-Key Lock** 算法，将记录锁与间隙锁相结合。

### MVCC 的实现原理

**MVCC / Multiversion concurrency control / 多版本并发控制：**

同一份数据保留多版本的一种方式，进而实现并发控制。在查询的时候，通过 read view 和版本链找到对应版本的数据。

作用：

**提升并发性能。对于高并发场景，MVCC 比行级锁开销更小。**

MVCC 的实现依赖于版本链，版本链是通过表的三个隐藏字段实现。

> DB_TRX_ID：当前事务 id，通过事务 id 的大小判断事务的时间顺序。
>
> DB_ROLL_PRT：回滚指针，指向当前行记录的上一个版本，通过这个指针将数据的多个版本连接在一起构成 undo log 版本链。
>
> DB_ROLL_ID：主键，如果数据表没有主键，InnoDB 会自动生成主键。

使用事务更新行记录的时候，就会生成版本链，执行过程如下：

> 用排他锁锁住该行；
>
> 将该行原本的值拷贝到 undo log，作为旧版本用于回滚；
>
> 修改当前行的值，生成一个新版本，更新事务 id，使回滚指针指向旧版本的记录，这样就形成一条版本链。

read view 可以理解成将数据在每个时刻的状态拍成 “照片” 记录下来。在获取某时刻 t 的数据时，到 t 时间点拍的 “照片” 上取数据。

在 read view 内部维护一个活跃事务链表，表示生成 read view 的时候还在活跃的事务。这个链表包含在创建 read view 之前还未提交的事务，不包含创建 read view
之后提交的事务。

不同隔离级别创建 read view 的时机不同：

> read committed：每次执行 select 都会创建新的 read_view，保证能读取到其他事务已经提交的修改。
>
> repeatable read：在一个事务范围内，第一次 select 时更新这个 read_view，以后不会再更新，后续所有的 select 都是复用之前的 read_view。这样可以保证事务范围内每次读取的内容都一样，即可重复读。

read view 的记录筛选方式：

前提：DATA_TRX_ID 表示每个数据行的最新的事务 ID；up_limit_id 表示当前快照中的最先开始的事务；low_limit_id 表示当前快照中的最慢开始的事务，即最后一个事务。

> 如果 DATA_TRX_ID < up_limit_id：说明在创建 read view 时，修改该数据行的事务已提交，该版本的记录可被当前事务读取到。
>
> 如果 DATA_TRX_ID >= low_limit_id：说明当前版本的记录的事务是在创建 read view 之后生成的，该版本的数据行不可以被当前事务访问。
>
> 此时需要通过版本链找到上一个版本，然后重新判断该版本的记录对当前事务的可见性。
>
> 如果 up_limit_id <= DATA_TRX_ID < low_limit_i：
>
> > 需要在活跃事务链表中查找是否存在 ID 为 DATA_TRX_ID 的值的事务。
> >
> > 如果存在，因为在活跃事务链表中的事务是未提交的，所以该记录是不可见的。此时需要通过版本链找到上一个版本，然后重新判断该版本的可见性。
> >
> > 如果不存在，说明事务 trx_id 已经提交了，这行记录是可见的。

总结：

**InnoDB 的 MVCC 是通过 read view 和版本链实现的，版本链保存有历史版本记录，通过 read view 判断当前版本的数据是否可见，**

**如果不可见，再从版本链中找到上一个版本，继续进行判断，直到找到一个可见的版本。**

### 快照读和当前读（重点）

**快照读 / 非加锁读 / 一致性读：**

读取开启事务时的版本数据。

> 例如：使用普通的 select 语句，这种情况下使用 MVCC 避免了脏读、不可重复读、幻读，保证了隔离性。

InnoDB 提供的非锁定读，不需要等待访问行上的锁释放，读取行的一个快照。

快照读情况下，InnoDB 通过 mvcc 机制避免了幻读现象。

而 mvcc 机制无法避免当前读情况下出现的幻读现象。因为当前读每次读取的都是最新数据，这时如果两次查询中间有其它事务插入数据，就会产生幻读。

**当前读 / 加锁读：**

读取数据库当前版本数据。

**加锁读在查询时会对查询的数据加锁**（共享锁或排它锁）。

由于锁的特性，当某事务对数据进行加锁读后，其他事务无法对数据进行写操作，因此可以避免脏读和不可重复读。而避免幻读，则需要通过 next-key lock。

因此，加锁读同样可以避免脏读、不可重复读和幻读，保证隔离性。

**共享锁读取的查询语句：select...lock in share mode**

**排它锁读取的查询语句：select...for update**

所以，select 执行的是快照读（某个版本的数据，Read View），而 update 执行的是当前读（最新的数据，即最新的 Read View）。

### MySQL 如何避免幻读

在快照读情况下，MySQL 通过 mvcc 来避免幻读。

在当前读情况下，MySQL 通过 next-key 来避免幻读（加行锁和间隙锁来实现的）。

> next-key 包括两部分：行锁和间隙锁。行锁是加在索引上的锁，间隙锁是加在索引之间的。
>
> Serializable 隔离级别也可以避免幻读，会锁住整张表，并发性极低，一般不会使用。

### MySQL 的 InnoDB 如何实现 MVCC

在 InnoDB 中，会在每行数据后添加两个额外的隐藏的值来实现 MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。

在实际操作中，存储的并不是时间，而是事务的版本号。

**每开启一个新事务，事务的版本号就会递增。**

**通过 MVCC，虽然每行记录都需要额外的存储空间，更多的行检查工作以及一些额外的维护工作，但可以减少锁的使用。**
大多数读操作都不用加锁，读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行，也只锁住必要行。

根据 MVCC 的定义，并发提交数据时会出现冲突。

在可重复读级别中，通过 MVCC 机制，虽然让数据变得可重复读，但我们读到的数据可能是历史数据，是不及时的数据，不是数据库当前的数据。

事务的隔离级别实际上都是定义了当前读的级别，MySQL 为了减少锁处理（包括等待其它锁）的时间，提升并发能力，引入了快照读的概念，使得 select 不用加锁。

而 update、insert 这些当前读，就需要另外的模块来解决了。为了解决当前读中的幻读问题，MySQL 事务使用了 Next-Key Lock。

### MySQL 如何实现原子性

InnoDB 实现回滚，靠的是 undo log，回滚日志是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的 sql 语句，。。

**回滚日志 / undo log：**

当事务对数据库进行修改时，InnoDB 会生成对应的 undo log；如果事务执行失败或调用了 rollback，导致事务需要回滚，便可以利用 undo log 中的信息将数据回滚到修改之前的样子。

例如：

1. 当你 delete 一条数据的时候，就需要记录这条数据的信息，回滚的时候，insert 这条旧数据
2. 当你 update 一条数据的时候，就需要记录之前的旧值，回滚的时候，根据旧值执行 update 操作
3. 当年 insert 一条数据的时候，就需要这条记录的主键，回滚的时候，根据主键执行 delete 操

### MySQL 如何实现持久性

InnoDB 作为 MySQL 的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘 IO，效率会很低。

为此，InnoDB 提供了**缓存（Buffer Pool）**，Buffer Pool 中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：

当从数据库读取数据时，会首先从 Buffer Pool 中读取，如果 Buffer Pool 中没有，则从磁盘读取后放入 Buffer Pool； 当向数据库写入数据时，会首先写入 Buffer
Pool，Buffer Pool 中修改的数据会定期刷新到磁盘中（这一过程称为刷脏）。

Buffer Pool 的使用大大提高了读写数据的效率，但是也带了新的问题：如果 MySQL 宕机，而此时 Buffer Pool
中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。

于是，**redo log** 被引入来解决这个问题：当数据修改时，除了修改 Buffer Pool 中的数据，还会在 redo log 记录这次操作；当事务提交时，会调用 fsync 接口对
redo log 进行刷盘。如果 MySQL 宕机，重启时可以读取 redo log 中的数据，对数据库进行恢复。redo log 采用的是 WAL（Write-ahead
logging，预写式日志），所有修改先写入日志，再更新到 Buffer Pool，保证了数据不会因 MySQL 宕机而丢失，从而满足了持久性要求。

既然 redo log 也需要在事务提交时将日志写入磁盘，为什么它比直接将 Buffer Pool 中修改的数据写入磁盘（即刷脏）要快呢？主要有以下两方面的原因：

> 刷脏是随机 IO，因为每次修改的数据位置随机，但写 redo log 是追加操作，属于顺序 IO。
>
> 刷脏是以数据页（Page）为单位的，MySQL 默认页大小是 16KB，一个 Page 上一个小修改都要整页写入；而 redo log 中只包含真正需要写入的部分，无效 IO 大大减少。

### MySQL 如何实现隔离性

隔离性要求同一时刻只能有一个事务对数据进行写操作，InnoDB 通过**锁机制**来保证这一点。

锁机制的基本原理可以概括为：

> 事务在修改数据之前，需要先获得相应的锁；获得锁之后，事务便可以修改数据；该事务操作期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁。

InnoDB 实现的 RR，通过锁机制（包含 next-key lock）、MVCC（包括数据的隐藏列、基于 undo log
的版本链、ReadView）等，实现了一定程度的隔离性，可以满足大多数场景的需要。

RR 虽然避免了幻读问题，但是毕竟不是 Serializable，不能保证完全的隔离。

如果在事务中第一次读取采用非加锁读，第二次读取采用加锁读，则如果在两次读取之间数据发生了变化，两次读取到的结果不一样，因为加锁读时不会采用 MVCC。

### MySQL 如何实现一致性

一致性是事务追求的最终目标。原子性、持久性和隔离性，都是为了保证数据库状态的一致性，即数据库的完整性约束。

此外，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。

实现一致性的措施包括：

> 保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证。
>
> **数据库本身提供保障**，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等。
>
> **应用层面进行保障**，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致。


---

## 日志

---

### MySQL 的日志

MySQL 的日志有很多种，如：binlog / 二进制日志、error log / 错误日志、查询日志、慢查询日志等。

此外 InnoDB 存储引擎还提供了两种事务日志：**redo log（重做日志）**、**undo log（回滚日志）**。

其中 **redo log 用于保证事务持久性；undo log 则是事务原子性和隔离性实现的基础**。

bin log：

bin log 是 MySQL 数据库级别的文件，记录对 MySQL 数据库执行修改的所有操作，不会记录 select 和 show 语句，主要用于恢复数据库和同步数据库。

redo log：

redo log 是 innodb 引擎级别，用来记录 innodb 存储引擎的事务日志，不管事务是否提交都会记录下来，用于数据恢复。当数据库发生故障，innoDB 存储引擎会使用 redo log
恢复到发生故障前的时刻，以此来保证数据的完整性。将参数 innodb_flush_log_at_tx_commit 设置为 1，那么在执行 commit 时会将 redo log 同步写到磁盘。

undo log：

除了记录 redo log 外，当进行数据修改时还会记录 undo log，undo log 用于数据的撤回操作，它保留了记录修改前的内容。通过 undo log 可以实现事务回滚，并且可以根据
undo log 回溯到某个特定的版本的数据，实现 MVCC。

### redo log 与 binlog 的区别

都可以记录写操作并用于数据的恢复。

**1. 作用不同：**

redo log 是用于 crash recovery 的，保证 MySQL 宕机也不会影响持久性；

binlog 是用于 point-in-time recovery 的，保证服务器可以基于时间点恢复数据，此外 binlog 还用于主从复制。

**2. 层次不同：**

redo log 是 InnoDB 存储引擎实现的；

binlog 是 MySQL 的服务器层（可以参考文章前面对 MySQL 逻辑架构的介绍）实现的，同时支持 InnoDB 和其他存储引擎。

**3. 内容不同：**

redo log 是物理日志，内容基于磁盘的 Page；

binlog 的内容是二进制的，根据 binlog_format 参数的不同，可能基于 sql 语句、基于数据本身或者二者的混合。

**4. 写入时机不同：**

binlog 在事务提交时写入；

redo log 的写入时机相对多元：

> 当事务提交时会调用 fsync 对 redo log 进行刷盘，这是默认情况下的策略，修改 innodb_flush_log_at_trx_commit 参数可以改变该策略，但事务的持久性将无法保证。
>
> 除了事务提交时，还有其他刷盘时机：如 master thread 每秒刷盘一次 redo log 等，这样的好处是不一定要等到 commit 时刷盘，commit 速度大大加快。

---

## 锁

---

### 锁的作用范围分类

由于加锁本身需要消耗资源（获得锁、检查锁、释放锁等都需要消耗资源），因此在锁定数据较多情况下使用表锁可以节省大量资源。

MySQL 中不同的存储引擎支持的锁是不一样的，例如 MyIsam 只支持表锁，而 InnoDB 同时支持表锁和行锁，且出于性能考虑，绝大多数情况下使用的都是行锁。

**1. 全局锁：**

在 DB 级别对整个数据库实例加锁。

- 加锁表现：

> 数据库处于只读状态。
>
> 阻塞对数据的增删改以及 DDL。

- 加锁方式：lock Flush tables with read lock

- 释放锁：unlock tables（发生异常时会自动释放）

- 作用场景：

> 全局锁主要用于做全库的逻辑备份，和设置数据库只读（set global readonly=true）相比，全局锁在发生异常时会自动释放

**2. 表锁：**

表级别对操作的整张表加锁，锁定颗粒度大，资源消耗少，不会出现死锁，但并发度低。

分为表共享锁和表排他锁，注意：意向锁为表锁，但是由存储引擎自己维护，无需用户手工命令干预。

- 显示加锁方式：lock tables {tb_name} read/write

- 释放锁：unlock table {tb_name}（连接中断也会自动释放）

**3. 行锁：**

InnoDB 支持行级别锁，锁粒度小并发度高，但是加锁开销大也很可能会出现死锁

innodb 行锁住的是索引项，注意当回表时，主键的聚簇索引也会加上锁。

- 加锁方式：

> 普通 select… 查询（不加锁）。
>
> 普通 insert、update、delete…（隐式加写锁）。
>
> select…lock in share mode（加读锁）。
>
> select…for update（加写锁）。

- 解锁：

> 提交 / 回滚事务（commit/rollback） kill 阻塞进程

行锁用的最多且更容易出现死锁问题。

### 锁的模式分类

我们常规理解的锁分为 2 大类：**读锁 / 共享锁（S）、写锁 / 排他锁（X）。**

两把锁之间的兼容性说明如下表：

| 兼容性 | X | S |
| :---: | :---: | :---: |
| X | 0 | 0 |
| S | 0 | 1 |

横轴表示已持有的锁，纵轴表示尝试获取的锁。

1 表示成功（即兼容，表现为正常进行下一步操作），0 表示失败（即冲突，表现为阻塞住当前操作）

排他锁和任何锁均不兼容。

数据库识别锁的冲突，最容易想到的识别方案就是遍历：

> step1：判断表是否已被其他事务用表锁锁住。
>
> step2: 判断表中的每一行是否已被行锁锁住。
>
> 其中 step2 需要遍历整个表，效率在数据库是没法接受的，因此 innodb 使用意向锁来解决这个问题。

Innodb 实现方案：

> T1 需要先申请表的意向共享锁 IS，成功后再申请一行的行锁 S。
>
> 注意：**意向共享锁是表级锁，由存储引擎自己维护，无需用户命手工命令干预**
>
> 在意向锁存在的情况下，上面的判断可以改为：
>
> step1：判断表是否已被其他事务用表锁锁住。
>
> step2: 发现表上有意向共享锁，说明表中行被共享行锁锁住了，因此，事务 B 申请表的写锁被阻塞。

此时就引入的意向锁，加入意向锁后，锁的兼容性分析如下表：

| 兼容性 | IX | IS | X | S |
| :---: | :---: | :---: | :---: | :---: |
| IX | 1 | 1 | 0 | 0 |
| IS | 1 | 1 | 0 | 1 |
| X | 0 | 0 | 0 | 0 |
| S | 0 | 1 | 0 | 1 |

### 共享锁和排他锁

SELECT 的读取锁定主要分为两种方式：共享锁和排他锁。

共享锁：

select * from table where id<6 **lock in share mode**;

排他锁：

select * from table where id<6 **for update**;

这两种方式主要的不同在于 **LOCK IN SHARE MODE** 多个事务同时更新同一个表单时很容易造成死锁。

申请排他锁的前提是，没有线程对该结果集的任何行数据使用排它锁或者共享锁，否则申请会受到阻塞。在进行事务操作时，MySQL
会对查询结果集的每行数据添加排它锁，其他线程对这些数据的更改或删除操作会被阻塞（只能读操作），直到该语句的事务被 commit 语句或 rollback 语句结束为止。

SELECT... FOR UPDATE 使用注意事项：

> for update 仅适用于 innodb，且必须在事务范围内才能生效。
>
> 根据主键进行查询，查询条件为 like 或者不等于，主键字段产生表锁。
>
> 根据非索引字段进行查询，会产生表锁。

### InnoDB 中的行锁（重点）

**1. Record Lock / 记录锁**：

**行锁，单行记录上的锁，作用于索引记录。**

例如：SELECT id FROM t WHERE id=1 FOR UPDATE

**2. Gap Lock / 间隙锁**：

**锁定一个范围，但不包括记录本身。**
间隙锁是为了防止同一事务的两次当前读，出现幻读。

间隙锁是一种加在两个索引之间的锁（众所周知索引是有序的），或者加在第一个索引之前，或最后一个索引之后的间隙。

间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。

间隙锁只阻止其他事务插入到间隙中，他们不阻止其他事务在同一个间隙上获得间隙锁，所以 gap x lock 和 gap s lock 有相同的作用。

**3. Next-Key Lock / 临键锁**：

**相当于 Record Lock 加上 Gap Lock。不仅会锁定记录本身，还会锁定一个范围。**
对于行的查询，都是采用该方法，主要目的是解决幻读的问题。

**4. Insert Intention / 插入意向锁：**

该锁只会出现在 insert 操作执行前（并不是所有 insert 操作都会出现），目的是为了提高并发插入能力，注意虽有意向二字，但插入意向锁是行锁。

**插入意向锁是在插入一行记录操作之前设置的一种特殊的间隙锁，这个锁释放了一种插入方式的信号，**

**亦即多个事务在相同的索引间隙插入时，如果不是插入间隙中相同的位置就不需要互相等待。**

> 普通的 Gap Lock **不允许在**（上一条记录，本记录） 范围内插入数据
>
> 插入意向锁 Gap Lock **允许在**上一条记录，本记录） 范围内插入数据

假设有索引值 4，7，几个不同的事务准备插入 5，6，每个锁都在获得插入行的独占锁之前用插入意向锁各自锁住了 4，7 之间的间隙，但是不阻塞对方不冲突的插入行。

锁类型兼容矩阵，横轴表示已持有的锁，纵轴表示尝试获取的锁。1 表示成功（即兼容，表现为正常进行下一步操作），0 表示失败（即冲突，表现为阻塞住当前操作）：

| 兼容性 | Gap | Insert Intention | Record | Next-Key |
| :---: | :---: | :---: | :---: | :---: |
| Gap | 1 | 1 | 1 | 1 |
| Insert Intention | 0 | 1 | 1 | 0 |
| Record | 1 | 1 | 0 | 0 |
| Next-Key | 1 | 1 | 0 | 0 |

### 间隙锁产生的条件（重点）

1、间隙锁只有在事务隔离级别 RR 中才会产生；

2、唯一索引只有锁住多条记录或者一条不存在的记录的时候，才会产生间隙锁，指定给某条存在的记录加锁的时候，只会加记录锁，不会产生间隙锁；

3、普通索引不管是锁住单条，还是多条记录，都会产生间隙锁；

RR 事务隔离级别下：

1、使用普通索引锁定；

2、使用多列唯一索引；

3、使用唯一索引锁定多行记录。

对于使用唯一索引来搜索并给某一行记录加锁的语句，不会产生间隙锁。（这不包括搜索条件仅包括多列唯一索引的一些列的情况；在这种情况下，会产生间隙锁。）例如，如果id列具有唯一索引，则下面的语句仅对具有id值100的行使用记录锁，并不会产生间隙锁：

innodb_locks_unsafe_for_binlog：默认值为OFF，即启用间隙锁。

因为此参数是只读模式，如果想要禁用间隙锁，需要修改 my.cnf（windows是my.ini） 重新启动才行。

### 临键锁产生的条件（重点）

临键锁的主要目的，也是为了避免幻读（Phantom Read）。如果把事务的隔离级别降级为RC，临键锁则也会失效。

### 锁组合

锁的模式：

> lock_s / 读锁，共享锁。
>
> lock_x / 写锁，排它锁。

锁的类型：

> Record_Lock ：锁记录。
>
> Gap_Lock ：锁记录前的 GAP。
>
> Next-Key Lock ：同时锁记录 + 记录前的 GAP。
>
> insert_Intention_Lock ：插入意向锁，其实是特殊的 GAP 锁。

锁模型可以和锁类型任意组合，如：

> locks gap before rec，表示为 gap 锁：lock->type_mode & LOCK_GAP
>
> locks rec but not gap，表示为记录锁，非 gap 锁：lock->type_mode & LOCK_REC_NOT_GAP
>
> insert intention，表示为插入意向锁：lock->type_mode & LOCK_INSERT_INTENTION
>
> waiting，表示锁等待：lock->type_mode & LOCK_WAIT

在 mysql 源码中使用了 uint32 类型来表示锁，最低的 4 个 bit 表示 lock_mode，5-8 bit 表示 lock_type（目前只用了 5 和 6 位，大小为 16 和 32
，表示 LOCK_TABLE 和 LOCK_REC），剩下的高位 bit 表示行锁的类型 record_lock_type。

### 悲观锁和乐观锁

**悲观锁**：

指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。

悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。

在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。**读取数据时给加锁**，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。

悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。

**乐观锁**：

乐观锁机制采取了更加宽松的加锁机制。**大多是基于数据版本（Version）记录机制实现**。

数据版本：

> 为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。

实现过程：

> 读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。

---

## MySQL 架构

---

### MySQL 核心架构

MySQL 主要分为 Server 层和存储引擎层：

1、**Server** 层：

主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。

2、**存储引擎**：

主要负责数据的存储和读取。server 层通过 api 与存储引擎进行通信。

Server 层基本组件：

1、**连接器**： 当客户端连接 MySQL 时，server 层会对其进行身份认证和权限校验。

2、**查询缓存**: 执行查询语句的时候，会先查询缓存，先校验这个 sql 是否执行过，如果有缓存这个 sql，就会直接返回给客户端，如果没有命中，就会执行后续的操作。

3、**分析器**: 没有命中缓存的话，SQL 语句就会经过分析器，主要分为两步，词法分析和语法分析，先看 SQL 语句要做什么，再检查 SQL 语句语法是否正确。

4、**优化器**： 优化器对查询进行优化，包括重写查询、决定表的读写顺序以及选择合适的索引等，生成执行计划。

5、**执行器**： 首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会根据执行计划去调用引擎的接口，返回结果。

### 分库分表

当单表的数据量达到 1000W 或 100G 以后，优化索引、添加从库等可能对数据库性能提升效果不明显，此时就要考虑对其进行切分了。切分的目的就在于减少数据库的负担，缩短查询的时间。

数据切分可以分为两种方式：垂直划分和水平划分。

**垂直划分：**

**根据业务进行划分**。

例如购物场景，可以将库中涉及商品、订单、用户的表分别划分出成一个库，通过降低单库的大小来提高性能。

同样的，分表的情况就是将一个大表根据业务功能拆分成一个个子表，例如商品基本信息和商品描述，商品基本信息一般会展示在商品列表，商品描述在商品详情页，可以将商品基本信息和商品描述拆分成两张表。

优点：行记录变小，数据页可以存放更多记录，在查询时减少 I/O 次数。

缺点：

> 主键出现冗余，需要管理冗余列；
>
> 会引起表连接 JOIN 操作，可以通过在业务服务器上进行 join 来减少数据库压力；
>
> 依然存在单表数据量过大的问题。

**水平划分：**

水平划分是根据一定规则，例如时间或 id 序列值等进行数据的拆分。比如根据年份来拆分不同的数据库。每个数据库结构一致，但是数据得以拆分，从而提升性能。

优点：单库（表）的数据量得以减少，提高性能；切分出的表结构相同，程序改动较少。

缺点：

> 分片事务一致性难以解决
>
> 跨节点 join 性能差，逻辑复杂
>
> 数据分片在扩容时需要迁移

### 什么是 MySQL 主从同步

主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。

因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。

### 为什么要做主从同步

> 读写分离，使数据库能支撑更大的并发。
>
> 在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能。
>
> 数据备份，保证数据的安全。

---

## MySQL 执行计划

---

### 执行计划

SQL 在数据库中执行时的表现情况，通常用于 SQL 性能分析，优化等场景。预先估计查询究竟要涉及多少行、使用哪些索引、运行时间。

> 存储引擎在执行 sql 的时候，把一条 sql 分解，列出来每一步需要干什么，并按照步骤依次执行，这样我们就能看出来哪个步骤耽误了时间

| # | 名称 | 简介 | 值 |
|:---:|:---|:---|:---:|
| 01 | id | select查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序 | simple、primary、union  |
| 02 | select_type | 查询类型 |  |
| 03 | table | 正在访问哪个表 |  |
| 04 | partitions | 匹配的分区 |  |
| 05 | **type** | 访问的类型 | All、index、range、ref、eq_ref、const、system、Null  |
| 06 | **possible_keys** | 显示可能应用在这张表中的索引，一个或多个，但不一定实际使用到 |  |
| 07 | key | 实际使用到的索引，如果为 NULL，则没有使用索引 |  |
| 08 | key_len | 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度 |  |
| 09 | **ref** | 显示索引的哪一列被使用了，如果可能的话，是一个常数，哪些列或常量被用于查找索引列上的值 |  |
| 10 | **rows** | 根据表统计信息及索引选用情况，大致估算出找到所需的记录所需读取的行数 |  |
| 11 | **filtered** | 查询的表行占表的百分比 |  |
| 12 | **Extra** | 包含不适合在其它列中显示但十分重要的额外信息 |  |
|<img width=50px/>|<img width=150px/>|<img width=300px/>|<img width=200px/>|

1、id

> 表示查询中 select 操作表的顺序，按顺序从大到依次执行（不是表中的自增主键）
>
> id 值相同执行顺序从上到下。 id 值不同时 id 值大的先执行。

2、select_type

> 这一列显示了对应行是简单还是复杂。
>
> SIMPLE 值意味着查询不包括子查询和 UNION。
>
> 查询有任何复杂的子部分，则最外层标记为 PRIMARY

**3、type**

> 该属性表示访问类型，有很多种访问类型。
>
> 最常见的其中包括以下几种: ALL (全表扫描)，index (索引扫描)，range (范围扫描)，ref (非唯一索引扫描)，eq_ref (唯一索引扫描，)，(const) 常数引用，访问速度依次由慢到快。
>
> 提示：慢 SQL 是否走索引，走了什么索引，也就可以通过该属性查看了。

4、table

> 输出数据行所在的表的名称

**5、possible_keys**

> 指出 MySQL 能使用哪些索引来优化查询，查询所涉及的列上的索引都会被列出，但不一定会被使用，算是个提示作用。

6、key

> 显示 MySQL 实际使用的索引，其中就包括主键索引 (PRIMARY)，或者自建索引的名字。
>
> 如果没有可用的索引，则显示为 NULL。

7、key_len

> 表示索引字段的最大可能长度，KEY_LEN 的长度由字段定义计算而来，并非数据的实际长度，
>
> 当 key 字段的值为 null 时，索引的长度就是 null。注意，key_len 的值可以告诉你在联合索引中 MySQL 会真正使用了哪些索引。

**8、ref**

> 表示哪些列或常量被用于查找索引列上的值。
>
> 连接匹配条件。如果走主键索引的话，该值为: const；全表扫描的话，为 null 值。

**9、rows**

> 扫描行数，也就是说，需要扫描多少行，才能获取目标行数，一般情况下会大于返回行数。
>
> 通常情况下，rows 越小，效率越高，也就有大部分 SQL 优化，都是在减少这个值的大小。
>
> 注意：理想情况下扫描的行数与实际返回行数理论上是一致的，但这种情况及其少，如关联查询，扫描的行数就会比返回行数大大增加)

**10、Extra**

> 这个属性非常重要，该属性中包括执行 SQL 时的真实情况信息，如上面所属，使用到的是”using where”，表示使用 where 筛选得到的值。
>
> 常用的有：“Using temporary”: 使用临时表 “using filesort”: 使用文件排序

---

## MySQL 调优

---

### 优化 SQL

通过慢查询日志、EXPLAIN 分析查询、show profile 分析、以及 show 命令查询系统状态及系统变量。


### 如何定位性能瓶颈

先分析数据库系统资源是否达到瓶颈，如：平均负载、CPU、I/O 次数、连接数、QPS 吞吐量。

如果是查询性能问题，则优先看是否有慢查询，频繁查询的字段是否有建立索引，是否索引实效导致全表扫描，索引是否过大导致查询效率降低，表数据量是否过大 (需要分库分表) 等等


### MySQL 如何对大表 (千万 / 亿级) 做优化

优化顺序：

优化 SQL 语句和索引

对频繁查询的数据进行缓存

对数据库进行主从复制，读写分离，从库可以使用 MyISAM，查询效率会更高

对表进行分区，SQL 条件中需要带上做分区的列，可以使查询定位到少量的分区上，查询会比较快，如果每用到分区的列会扫描全部分区

垂直拆分，对大表拆分成小表

水平拆分，将数据分片，拆分到其他表或数据库上



---

## 参考链接

---

- [MySQL 官方文档——幻影行](https://dev.mysql.com/doc/refman/8.0/en/innodb-next-key-locking.html)
- [深入学习 MySQL 事务：ACID 特性的实现原理](https://www.cnblogs.com/kismetv/p/10331633.html)
- [mysql 锁机制的再研究 ](https://mp.weixin.qq.com/s/FJKRUyGUNgDYRvPAy20x3w)
- [MySQL 中幻读出现的原因及解决方案](https://blog.csdn.net/nandao158/article/details/116007366)
- [MySQL的锁机制 - 记录锁、间隙锁、临键锁](https://zhuanlan.zhihu.com/p/48269420)
- [Innodb 锁机制：Next-Key Lock 浅谈](https://www.cnblogs.com/zhoujinyi/p/3435982.html)
- [MySQL next-key lock 加锁范围是什么？](https://segmentfault.com/a/1190000040129107)
- [间隙锁和 next-key lock](https://www.jianshu.com/p/d1aba64b5c03)
- [MySQL 教程（十）---MySQL ACID 实现原理](https://www.lixueduan.com/post/mysql/10-acid/)
- [Innodb 中的事务隔离级别和锁的关系](https://tech.meituan.com/2014/08/20/innodb-lock.html)
- [MySQL 设计之三范式](https://segmentfault.com/a/1190000022843792)
- [MySQL 是如何保证一致性、原子性和持久性的](https://cloud.tencent.com/developer/article/1600883)
- [MySQL 索引那些事：什么是索引？为什么加索引就查得快了？](http://blog.itpub.net/70000181/viewspace-2776159/)
- [MySQL 索引类型、索引原理、索引分析与优化、慢查询优化](http://fishleap.top/pages/c62f50/)
- [MySQL 探秘（三）MySQL 索引原理](https://princeli.com/mysql%E6%8E%A2%E7%A7%98%E4%B8%89mysql%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86/)
- [MySql 创建索引原则](https://developer.aliyun.com/article/6719)
- [mysql 索引失效的场景](https://blog.csdn.net/vtopqx/article/details/112176732)
- [MySQL 索引连环 18 问](https://www.dockone.io/article/2434410)
- [解决 hash 冲突的三个方法](https://www.cnblogs.com/wuchaodzxx/p/7396599.html)
- [解决哈希冲突的常用方法分析](https://cloud.tencent.com/developer/article/1672781)
- [MySQL 经典 36 问](https://mp.weixin.qq.com/s/UYytwy46FZz3HWZmhC_X4g)
- [B + 树叶子结点到底存储了什么？](https://blog.csdn.net/Alice_8899/article/details/105357902)
- [五分钟搞懂 MySQL 索引下推](https://juejin.cn/post/7005794550862053412)
- [Sql 执行计划，优化 sql 必备](https://blog.csdn.net/choath/article/details/80779129)
- [MySQL EXPLAIN 详解](https://www.cnblogs.com/aspirant/p/16166821.html)
- [一张图彻底搞懂 MySQL 的 explain](https://segmentfault.com/a/1190000021458117)
- [mysql 数据库调优](https://blog.csdn.net/weixin_39564831/article/details/113457726)
- []()
- []()
- []()
- []()
- []()

---












